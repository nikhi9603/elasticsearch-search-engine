{
    "url": "https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence",
    "title": "Ethics of artificial intelligence",
    "html": "<!DOCTYPE html>\n<html class=\"client-nojs\" dir=\"ltr\" lang=\"en\">\n<head>\n<meta charset=\"utf-8\"/>\n<title>Ethics of artificial intelligence - Wikipedia</title>\n<script>document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"5c605458-2ed8-45dd-8546-0b255a9a3d31\",\"wgCSPNonce\":false,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Ethics_of_artificial_intelligence\",\"wgTitle\":\"Ethics of artificial intelligence\",\"wgCurRevisionId\":1117062413,\"wgRevisionId\":1117062413,\"wgArticleId\":13659583,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Webarchive template wayback links\",\"CS1 errors: generic name\",\"Articles with Russian-language sources (ru)\",\"Articles with short description\",\"Short description is different from Wikidata\",\"All articles with vague or ambiguous time\",\n\"Vague or ambiguous time from November 2020\",\"All articles with failed verification\",\"Articles with failed verification from November 2020\",\"Philosophy of artificial intelligence\",\"Ethics of science and technology\",\"Regulation of robots\"],\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgRelevantPageName\":\"Ethics_of_artificial_intelligence\",\"wgRelevantArticleId\":13659583,\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgFlaggedRevsParams\":{\"tags\":{\"status\":{\"levels\":1}}},\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\"},\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"watchlist\":true,\"tagline\":false,\"nearby\":true},\"wgWMESchemaEditAttemptStepOversample\":false,\"wgWMEPageLength\":100000,\"wgNoticeProject\":\"wikipedia\",\"wgVector2022PreviewPages\":[],\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsFlags\":10,\"wgULSCurrentAutonym\":\"English\",\n\"wgEditSubmitButtonLabelPublish\":true,\"wgCentralAuthMobileDomain\":false,\"wgULSPosition\":\"interlanguage\",\"wgULSisCompactLinksEnabled\":true,\"wgWikibaseItemId\":\"Q12727779\",\"GEHomepageSuggestedEditsEnableTopics\":true,\"wgGETopicsMatchModeEnabled\":false,\"wgGEStructuredTaskRejectionReasonTextInputEnabled\":false};RLSTATE={\"ext.globalCssJs.user.styles\":\"ready\",\"site.styles\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"user\":\"ready\",\"user.options\":\"loading\",\"ext.cite.styles\":\"ready\",\"ext.tmh.player.styles\":\"ready\",\"skins.vector.styles.legacy\":\"ready\",\"jquery.makeCollapsible.styles\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.wikimediaBadges\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"wikibase.client.init\":\"ready\"};RLPAGEMODULES=[\"ext.cite.ux-enhancements\",\"ext.tmh.player\",\"ext.scribunto.logs\",\"site\",\"mediawiki.page.ready\",\"jquery.makeCollapsible\",\"mediawiki.toc\",\"skins.vector.legacy.js\",\"mmv.head\",\"mmv.bootstrap.autostart\",\n\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visualEditor.targetLoader\",\"ext.eventLogging\",\"ext.wikimediaEvents\",\"ext.navigationTiming\",\"ext.cx.eventlogging.campaigns\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.charinsert\",\"ext.gadget.extra-toolbar-buttons\",\"ext.gadget.switcher\",\"ext.centralauth.centralautologin\",\"ext.popups\",\"ext.uls.compactlinks\",\"ext.uls.interface\",\"ext.growthExperiments.SuggestedEditSession\"];</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement(\"user.options@12s5i\",function($,jQuery,require,module){mw.user.tokens.set({\"patrolToken\":\"+\\\\\",\"watchToken\":\"+\\\\\",\"csrfToken\":\"+\\\\\"});});});</script>\n<link href=\"/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.tmh.player.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cjquery.makeCollapsible.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<script async=\"\" src=\"/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector\"></script>\n<meta content=\"\" name=\"ResourceLoaderDynamicStyles\"/>\n<link href=\"/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector\" rel=\"stylesheet\"/>\n<meta content=\"MediaWiki 1.40.0-wmf.8\" name=\"generator\"/>\n<meta content=\"origin\" name=\"referrer\"/>\n<meta content=\"origin-when-crossorigin\" name=\"referrer\"/>\n<meta content=\"origin-when-cross-origin\" name=\"referrer\"/>\n<meta content=\"max-image-preview:standard\" name=\"robots\"/>\n<meta content=\"telephone=no\" name=\"format-detection\"/>\n<meta content=\"width=1000\" name=\"viewport\"/>\n<meta content=\"Ethics of artificial intelligence - Wikipedia\" property=\"og:title\"/>\n<meta content=\"website\" property=\"og:type\"/>\n<link href=\"//upload.wikimedia.org\" rel=\"preconnect\"/>\n<link href=\"//en.m.wikipedia.org/wiki/Ethics_of_artificial_intelligence\" media=\"only screen and (max-width: 720px)\" rel=\"alternate\"/>\n<link href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit\" rel=\"alternate\" title=\"Edit this page\" type=\"application/x-wiki\"/>\n<link href=\"/static/apple-touch/wikipedia.png\" rel=\"apple-touch-icon\"/>\n<link href=\"/static/favicon/wikipedia.ico\" rel=\"icon\"/>\n<link href=\"/w/opensearch_desc.php\" rel=\"search\" title=\"Wikipedia (en)\" type=\"application/opensearchdescription+xml\"/>\n<link href=\"//en.wikipedia.org/w/api.php?action=rsd\" rel=\"EditURI\" type=\"application/rsd+xml\"/>\n<link href=\"https://creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\"/>\n<link href=\"https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence\" rel=\"canonical\"/>\n<link href=\"//meta.wikimedia.org\" rel=\"dns-prefetch\"/>\n<link href=\"//login.wikimedia.org\" rel=\"dns-prefetch\"/>\n</head>\n<body class=\"skin-vector-legacy mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Ethics_of_artificial_intelligence rootpage-Ethics_of_artificial_intelligence skin-vector action-view vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-language-alert-in-sidebar-enabled vector-feature-sticky-header-disabled vector-feature-sticky-header-edit-disabled vector-feature-table-of-contents-legacy-toc-disabled vector-feature-visual-enhancement-next-disabled vector-feature-page-tools-disabled vector-feature-limited-width-enabled vector-feature-limited-width-content-enabled\"><div class=\"noprint\" id=\"mw-page-base\"></div>\n<div class=\"noprint\" id=\"mw-head-base\"></div>\n<div class=\"mw-body\" id=\"content\" role=\"main\">\n<a id=\"top\"></a>\n<div id=\"siteNotice\"><!-- CentralNotice --><!--esi <esi:include src=\"/esitest-fa8a495983347898/content\" /> --> </div>\n<div class=\"mw-indicators\">\n</div>\n<h1 class=\"firstHeading mw-first-heading\" id=\"firstHeading\"><span class=\"mw-page-title-main\">Ethics of artificial intelligence</span></h1>\n<div class=\"vector-body\" id=\"bodyContent\">\n<div class=\"noprint\" id=\"siteSub\">From Wikipedia, the free encyclopedia</div>\n<div id=\"contentSub\"></div>\n<div id=\"contentSub2\"></div>\n<div id=\"jump-to-nav\"></div>\n<a class=\"mw-jump-link\" href=\"#mw-head\">Jump to navigation</a>\n<a class=\"mw-jump-link\" href=\"#searchInput\">Jump to search</a>\n<div class=\"mw-body-content mw-content-ltr\" dir=\"ltr\" id=\"mw-content-text\" lang=\"en\"><div class=\"mw-parser-output\"><div class=\"shortdescription nomobile noexcerpt noprint searchaux\" style=\"display:none\">Ethical issues specific to AI</div>\n<style data-mw-deduplicate=\"TemplateStyles:r1045330069\">.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}</style><table class=\"sidebar sidebar-collapse nomobile nowraplinks hlist\"><tbody><tr><td class=\"sidebar-pretitle\">Part of a series on</td></tr><tr><th class=\"sidebar-title-with-pretitle\"><a href=\"/wiki/Outline_of_artificial_intelligence\" title=\"Outline of artificial intelligence\">Artificial intelligence</a></th></tr><tr><td class=\"sidebar-image\"><div class=\"center\"><div class=\"floatnone\"><a class=\"image\" href=\"/wiki/File:Anatomy-1751201_1280.png\"><img alt=\"Anatomy-1751201 1280.png\" data-file-height=\"1088\" data-file-width=\"1280\" decoding=\"async\" height=\"85\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Anatomy-1751201_1280.png/100px-Anatomy-1751201_1280.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Anatomy-1751201_1280.png/150px-Anatomy-1751201_1280.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Anatomy-1751201_1280.png/200px-Anatomy-1751201_1280.png 2x\" width=\"100\"/></a></div></div></td></tr><tr><td class=\"sidebar-content\">\n<div class=\"sidebar-list mw-collapsible mw-collapsed\"><div class=\"sidebar-list-title\" style=\"text-align:center\"><a href=\"/wiki/Artificial_intelligence#Goals\" title=\"Artificial intelligence\">Major goals</a></div><div class=\"sidebar-list-content mw-collapsible-content\">\n<ul><li><a href=\"/wiki/Artificial_general_intelligence\" title=\"Artificial general intelligence\">Artificial general intelligence</a></li>\n<li><a href=\"/wiki/Automated_planning_and_scheduling\" title=\"Automated planning and scheduling\">Planning</a></li>\n<li><a href=\"/wiki/Computer_vision\" title=\"Computer vision\">Computer vision</a></li>\n<li><a href=\"/wiki/General_game_playing\" title=\"General game playing\">General game playing</a></li>\n<li><a href=\"/wiki/Knowledge_representation_and_reasoning\" title=\"Knowledge representation and reasoning\">Knowledge reasoning</a></li>\n<li><a href=\"/wiki/Machine_learning\" title=\"Machine learning\">Machine learning</a></li>\n<li><a href=\"/wiki/Natural_language_processing\" title=\"Natural language processing\">Natural language processing</a></li>\n<li><a href=\"/wiki/Robotics\" title=\"Robotics\">Robotics</a></li></ul></div></div></td>\n</tr><tr><td class=\"sidebar-content\">\n<div class=\"sidebar-list mw-collapsible mw-collapsed\"><div class=\"sidebar-list-title\" style=\"text-align:center\">Approaches</div><div class=\"sidebar-list-content mw-collapsible-content\">\n<ul><li><a href=\"/wiki/Symbolic_artificial_intelligence\" title=\"Symbolic artificial intelligence\">Symbolic</a></li>\n<li><a href=\"/wiki/Deep_learning\" title=\"Deep learning\">Deep learning</a></li>\n<li><a href=\"/wiki/Bayesian_network\" title=\"Bayesian network\">Bayesian networks</a></li>\n<li><a href=\"/wiki/Evolutionary_algorithm\" title=\"Evolutionary algorithm\">Evolutionary algorithms</a></li></ul></div></div></td>\n</tr><tr><td class=\"sidebar-content\">\n<div class=\"sidebar-list mw-collapsible mw-collapsed\"><div class=\"sidebar-list-title\" style=\"text-align:center\"><a href=\"/wiki/Philosophy_of_artificial_intelligence\" title=\"Philosophy of artificial intelligence\">Philosophy</a></div><div class=\"sidebar-list-content mw-collapsible-content\">\n<ul><li><a href=\"/wiki/Chinese_room\" title=\"Chinese room\">Chinese room</a></li>\n<li><a href=\"/wiki/Friendly_artificial_intelligence\" title=\"Friendly artificial intelligence\">Friendly AI</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/AI_control_problem\" title=\"AI control problem\">Control problem</a>/<a href=\"/wiki/AI_takeover\" title=\"AI takeover\">Takeover</a></li>\n<li><a class=\"mw-selflink selflink\">Ethics</a></li>\n<li><a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">Existential risk</a></li>\n<li><a href=\"/wiki/Turing_test\" title=\"Turing test\">Turing test</a></li></ul></div></div></td>\n</tr><tr><td class=\"sidebar-content\">\n<div class=\"sidebar-list mw-collapsible mw-collapsed\"><div class=\"sidebar-list-title\" style=\"text-align:center\"><a href=\"/wiki/History_of_artificial_intelligence\" title=\"History of artificial intelligence\">History</a></div><div class=\"sidebar-list-content mw-collapsible-content\">\n<ul><li><a href=\"/wiki/Timeline_of_artificial_intelligence\" title=\"Timeline of artificial intelligence\">Timeline</a></li>\n<li><a href=\"/wiki/Progress_in_artificial_intelligence\" title=\"Progress in artificial intelligence\">Progress</a></li>\n<li><a href=\"/wiki/AI_winter\" title=\"AI winter\">AI winter</a></li></ul></div></div></td>\n</tr><tr><td class=\"sidebar-content\">\n<div class=\"sidebar-list mw-collapsible mw-collapsed\"><div class=\"sidebar-list-title\" style=\"text-align:center\">Technology</div><div class=\"sidebar-list-content mw-collapsible-content\">\n<ul><li><a href=\"/wiki/Applications_of_artificial_intelligence\" title=\"Applications of artificial intelligence\">Applications</a></li>\n<li><a href=\"/wiki/List_of_artificial_intelligence_projects\" title=\"List of artificial intelligence projects\">Projects</a></li>\n<li><a href=\"/wiki/List_of_programming_languages_for_artificial_intelligence\" title=\"List of programming languages for artificial intelligence\">Programming languages</a></li></ul></div></div></td>\n</tr><tr><td class=\"sidebar-content\">\n<div class=\"sidebar-list mw-collapsible mw-collapsed\"><div class=\"sidebar-list-title\" style=\"text-align:center\">Glossary</div><div class=\"sidebar-list-content mw-collapsible-content\">\n<ul><li><a href=\"/wiki/Glossary_of_artificial_intelligence\" title=\"Glossary of artificial intelligence\">Glossary</a></li></ul></div></div></td>\n</tr><tr><td class=\"sidebar-navbar\"><style data-mw-deduplicate=\"TemplateStyles:r1063604349\">.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}</style><div class=\"navbar plainlinks hlist navbar-mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Artificial_intelligence\" title=\"Template:Artificial intelligence\"><abbr title=\"View this template\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Artificial_intelligence\" title=\"Template talk:Artificial intelligence\"><abbr title=\"Discuss this template\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"https://en.wikipedia.org/w/index.php?title=Template:Artificial_intelligence&amp;action=edit\"><abbr title=\"Edit this template\">e</abbr></a></li></ul></div></td></tr></tbody></table>\n<p>The <b>ethics of artificial intelligence</b> is the branch of the <a href=\"/wiki/Ethics_of_technology\" title=\"Ethics of technology\">ethics of technology</a> specific to <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificially intelligent</a> systems.<sup class=\"reference\" id=\"cite_ref-1\"><a href=\"#cite_note-1\">[1]</a></sup> It is sometimes divided into a concern with the moral behavior of <i>humans</i> as they design, make, use and treat artificially intelligent systems, and a concern with the behavior of <i>machines,</i> in <a href=\"/wiki/Machine_ethics\" title=\"Machine ethics\">machine ethics</a>. It also includes the issue of a possible <a href=\"/wiki/Technological_singularity\" title=\"Technological singularity\">singularity</a> due to <a href=\"/wiki/Superintelligence\" title=\"Superintelligence\">superintelligent AI</a>.\n</p>\n<div aria-labelledby=\"mw-toc-heading\" class=\"toc\" id=\"toc\" role=\"navigation\"><input class=\"toctogglecheckbox\" id=\"toctogglecheckbox\" role=\"button\" style=\"display:none\" type=\"checkbox\"/><div class=\"toctitle\" dir=\"ltr\" lang=\"en\"><h2 id=\"mw-toc-heading\">Contents</h2><span class=\"toctogglespan\"><label class=\"toctogglelabel\" for=\"toctogglecheckbox\"></label></span></div>\n<ul>\n<li class=\"toclevel-1 tocsection-1\"><a href=\"#Ethics_fields'_approaches\"><span class=\"tocnumber\">1</span> <span class=\"toctext\">Ethics fields' approaches</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-2\"><a href=\"#Robot_ethics\"><span class=\"tocnumber\">1.1</span> <span class=\"toctext\">Robot ethics</span></a></li>\n<li class=\"toclevel-2 tocsection-3\"><a href=\"#Machine_ethics\"><span class=\"tocnumber\">1.2</span> <span class=\"toctext\">Machine ethics</span></a></li>\n<li class=\"toclevel-2 tocsection-4\"><a href=\"#Ethics_principles_of_artificial_intelligence\"><span class=\"tocnumber\">1.3</span> <span class=\"toctext\">Ethics principles of artificial intelligence</span></a>\n<ul>\n<li class=\"toclevel-3 tocsection-5\"><a href=\"#Transparency,_accountability,_and_open_source\"><span class=\"tocnumber\">1.3.1</span> <span class=\"toctext\">Transparency, accountability, and open source</span></a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-6\"><a href=\"#Ethical_challenges\"><span class=\"tocnumber\">2</span> <span class=\"toctext\">Ethical challenges</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-7\"><a href=\"#Biases_in_AI_systems\"><span class=\"tocnumber\">2.1</span> <span class=\"toctext\">Biases in AI systems</span></a></li>\n<li class=\"toclevel-2 tocsection-8\"><a href=\"#Robot_rights\"><span class=\"tocnumber\">2.2</span> <span class=\"toctext\">Robot rights</span></a></li>\n<li class=\"toclevel-2 tocsection-9\"><a href=\"#Threat_to_human_dignity\"><span class=\"tocnumber\">2.3</span> <span class=\"toctext\">Threat to human dignity</span></a></li>\n<li class=\"toclevel-2 tocsection-10\"><a href=\"#Liability_for_self-driving_cars\"><span class=\"tocnumber\">2.4</span> <span class=\"toctext\">Liability for self-driving cars</span></a></li>\n<li class=\"toclevel-2 tocsection-11\"><a href=\"#Weaponization_of_artificial_intelligence\"><span class=\"tocnumber\">2.5</span> <span class=\"toctext\">Weaponization of artificial intelligence</span></a></li>\n<li class=\"toclevel-2 tocsection-12\"><a href=\"#Opaque_algorithms\"><span class=\"tocnumber\">2.6</span> <span class=\"toctext\">Opaque algorithms</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-13\"><a href=\"#Singularity\"><span class=\"tocnumber\">3</span> <span class=\"toctext\">Singularity</span></a></li>\n<li class=\"toclevel-1 tocsection-14\"><a href=\"#Actors_in_AI_ethics\"><span class=\"tocnumber\">4</span> <span class=\"toctext\">Actors in AI ethics</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-15\"><a href=\"#Intergovernmental_initiatives\"><span class=\"tocnumber\">4.1</span> <span class=\"toctext\">Intergovernmental initiatives</span></a></li>\n<li class=\"toclevel-2 tocsection-16\"><a href=\"#Governmental_initiatives\"><span class=\"tocnumber\">4.2</span> <span class=\"toctext\">Governmental initiatives</span></a></li>\n<li class=\"toclevel-2 tocsection-17\"><a href=\"#Academic_initiatives\"><span class=\"tocnumber\">4.3</span> <span class=\"toctext\">Academic initiatives</span></a></li>\n<li class=\"toclevel-2 tocsection-18\"><a href=\"#Private_organizations\"><span class=\"tocnumber\">4.4</span> <span class=\"toctext\">Private organizations</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-19\"><a href=\"#Role_and_impact_of_fiction\"><span class=\"tocnumber\">5</span> <span class=\"toctext\">Role and impact of fiction</span></a>\n<ul>\n<li class=\"toclevel-2 tocsection-20\"><a href=\"#History\"><span class=\"tocnumber\">5.1</span> <span class=\"toctext\">History</span></a></li>\n<li class=\"toclevel-2 tocsection-21\"><a href=\"#Impact_on_technological_development\"><span class=\"tocnumber\">5.2</span> <span class=\"toctext\">Impact on technological development</span></a></li>\n<li class=\"toclevel-2 tocsection-22\"><a href=\"#TV_series\"><span class=\"tocnumber\">5.3</span> <span class=\"toctext\">TV series</span></a></li>\n<li class=\"toclevel-2 tocsection-23\"><a href=\"#Future_visions_in_fiction_and_games\"><span class=\"tocnumber\">5.4</span> <span class=\"toctext\">Future visions in fiction and games</span></a></li>\n</ul>\n</li>\n<li class=\"toclevel-1 tocsection-24\"><a href=\"#See_also\"><span class=\"tocnumber\">6</span> <span class=\"toctext\">See also</span></a></li>\n<li class=\"toclevel-1 tocsection-25\"><a href=\"#Notes\"><span class=\"tocnumber\">7</span> <span class=\"toctext\">Notes</span></a></li>\n<li class=\"toclevel-1 tocsection-26\"><a href=\"#External_links\"><span class=\"tocnumber\">8</span> <span class=\"toctext\">External links</span></a></li>\n</ul>\n</div>\n<h2><span id=\"Ethics_fields.27_approaches\"></span><span class=\"mw-headline\" id=\"Ethics_fields'_approaches\">Ethics fields' approaches</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=1\" title=\"Edit section: Ethics fields' approaches\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span class=\"mw-headline\" id=\"Robot_ethics\">Robot ethics</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=2\" title=\"Edit section: Robot ethics\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<style data-mw-deduplicate=\"TemplateStyles:r1033289096\">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}</style><div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Robot_ethics\" title=\"Robot ethics\">Robot ethics</a></div>\n<p>The term \"robot ethics\" (sometimes \"roboethics\") refers to the morality of how humans design, construct, use and treat robots.<sup class=\"reference\" id=\"cite_ref-Veruggio2002_2-0\"><a href=\"#cite_note-Veruggio2002-2\">[2]</a></sup> Robot ethics intersect with the ethics of AI. Robots are physical machines whereas AI can be only software.<sup class=\"reference\" id=\"cite_ref-3\"><a href=\"#cite_note-3\">[3]</a></sup> Not all robots function through AI systems and not all AI systems are robots. Robot ethics considers how machines may be used to harm or benefit humans, their impact on individual autonomy, and their effects on social justice.\n</p>\n<h3><span class=\"mw-headline\" id=\"Machine_ethics\">Machine ethics</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=3\" title=\"Edit section: Machine ethics\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<link href=\"mw-data:TemplateStyles:r1033289096\" rel=\"mw-deduplicated-inline-style\"/><div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Machine_ethics\" title=\"Machine ethics\">Machine ethics</a></div>\n<p>Machine ethics (or machine morality) is the field of research concerned with designing <a href=\"/wiki/Moral_agency#Artificial_moral_agents\" title=\"Moral agency\">Artificial Moral Agents</a> (AMAs), robots or artificially intelligent computers that behave morally or as though moral.<sup class=\"reference\" id=\"cite_ref-Andersonweb_4-0\"><a href=\"#cite_note-Andersonweb-4\">[4]</a></sup><sup class=\"reference\" id=\"cite_ref-Anderson2011_5-0\"><a href=\"#cite_note-Anderson2011-5\">[5]</a></sup><sup class=\"reference\" id=\"cite_ref-Anderson2006_6-0\"><a href=\"#cite_note-Anderson2006-6\">[6]</a></sup><sup class=\"reference\" id=\"cite_ref-Anderson2007_7-0\"><a href=\"#cite_note-Anderson2007-7\">[7]</a></sup> To account for the nature of these agents, it has been suggested to consider certain philosophical ideas, like the standard characterizations of <a href=\"/wiki/Agency_(philosophy)\" title=\"Agency (philosophy)\">agency</a>, <a href=\"/wiki/Rational_agent\" title=\"Rational agent\">rational agency</a>, <a href=\"/wiki/Moral_agency\" title=\"Moral agency\">moral agency</a>, and artificial agency, which are related to the concept of AMAs.<sup class=\"reference\" id=\"cite_ref-8\"><a href=\"#cite_note-8\">[8]</a></sup>\n</p><p><a href=\"/wiki/Isaac_Asimov\" title=\"Isaac Asimov\">Isaac Asimov</a> considered the issue in the 1950s in his <i><a href=\"/wiki/I,_Robot\" title=\"I, Robot\">I, Robot</a></i>.  At the insistence of his editor <a class=\"mw-redirect\" href=\"/wiki/John_W._Campbell_Jr.\" title=\"John W. Campbell Jr.\">John W. Campbell Jr.</a>, he proposed the <a href=\"/wiki/Three_Laws_of_Robotics\" title=\"Three Laws of Robotics\">Three Laws of Robotics</a> to govern artificially intelligent systems.  Much of his work was then spent testing the boundaries of his three laws to see where they would break down, or where they would create paradoxical or unanticipated behavior. His work suggests that no set of fixed laws can sufficiently anticipate all possible circumstances.<sup class=\"reference\" id=\"cite_ref-Asimov2008_9-0\"><a href=\"#cite_note-Asimov2008-9\">[9]</a></sup> More recently, academics and many governments have challenged the idea that AI can itself be held accountable.<sup class=\"reference\" id=\"cite_ref-lacuna_10-0\"><a href=\"#cite_note-lacuna-10\">[10]</a></sup> A panel convened by the <a href=\"/wiki/United_Kingdom\" title=\"United Kingdom\">United Kingdom</a> in 2010 revised Asimov's laws to clarify that AI is the responsibility either of its manufacturers, or of its owner/operator.<sup class=\"reference\" id=\"cite_ref-principles_11-0\"><a href=\"#cite_note-principles-11\">[11]</a></sup>\n</p><p>In 2009, during an experiment at the Laboratory of Intelligent Systems in the Ecole Polytechnique Fédérale of <a href=\"/wiki/Lausanne\" title=\"Lausanne\">Lausanne</a>, Switzerland, robots that were programmed to cooperate with each other (in searching out a beneficial resource and avoiding a poisonous one) eventually learned to lie to each other in an attempt to hoard the beneficial resource.<sup class=\"reference\" id=\"cite_ref-12\"><a href=\"#cite_note-12\">[12]</a></sup>\n</p><p>Some experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions.<sup class=\"reference\" id=\"cite_ref-Call_for_debate_on_killer_robots_13-0\"><a href=\"#cite_note-Call_for_debate_on_killer_robots-13\">[13]</a></sup> The US Navy has funded a report which indicates that as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions.<sup class=\"reference\" id=\"cite_ref-14\"><a href=\"#cite_note-14\">[14]</a></sup><sup class=\"reference\" id=\"cite_ref-engadget.com_15-0\"><a href=\"#cite_note-engadget.com-15\">[15]</a></sup> The President of the <a href=\"/wiki/Association_for_the_Advancement_of_Artificial_Intelligence\" title=\"Association for the Advancement of Artificial Intelligence\">Association for the Advancement of Artificial Intelligence</a> has commissioned a study to look at this issue.<sup class=\"reference\" id=\"cite_ref-16\"><a href=\"#cite_note-16\">[16]</a></sup> They point to programs like the Language Acquisition Device which can emulate human interaction.\n</p><p><a href=\"/wiki/Vernor_Vinge\" title=\"Vernor Vinge\">Vernor Vinge</a> has suggested that a moment may come when some computers are smarter than humans. He calls this \"<a href=\"/wiki/Technological_singularity\" title=\"Technological singularity\">the Singularity</a>\".<sup class=\"reference\" id=\"cite_ref-nytimes_july09_17-0\"><a href=\"#cite_note-nytimes_july09-17\">[17]</a></sup>  He suggests that it may be somewhat or possibly very dangerous for humans.<sup class=\"reference\" id=\"cite_ref-18\"><a href=\"#cite_note-18\">[18]</a></sup> This is discussed by a philosophy called <a href=\"/wiki/Singularitarianism\" title=\"Singularitarianism\">Singularitarianism</a>. The <a href=\"/wiki/Machine_Intelligence_Research_Institute\" title=\"Machine Intelligence Research Institute\">Machine Intelligence Research Institute</a> has suggested a need to build \"<a class=\"mw-redirect\" href=\"/wiki/Friendly_AI\" title=\"Friendly AI\">Friendly AI</a>\", meaning that the advances which are already occurring with AI should also include an effort to make AI intrinsically friendly and humane.<sup class=\"reference\" id=\"cite_ref-19\"><a href=\"#cite_note-19\">[19]</a></sup>\n</p><p>There are discussion on creating tests to see if an AI is capable of making <a href=\"/wiki/Ethical_decision\" title=\"Ethical decision\">ethical decisions</a>. Alan Winfield concludes that the <a href=\"/wiki/Turing_test\" title=\"Turing test\">Turing test</a> is flawed and the requirement for an AI to pass the test is too low.<sup class=\"reference\" id=\"cite_ref-:0_20-0\"><a href=\"#cite_note-:0-20\">[20]</a></sup> A proposed alternative test is one called the Ethical Turing Test, which would improve on the current test by having multiple judges decide if the AI's decision is ethical or unethical.<sup class=\"reference\" id=\"cite_ref-:0_20-1\"><a href=\"#cite_note-:0-20\">[20]</a></sup>\n</p><p>In 2009, academics and technical experts attended a conference organized by the <a href=\"/wiki/Association_for_the_Advancement_of_Artificial_Intelligence\" title=\"Association for the Advancement of Artificial Intelligence\">Association for the Advancement of Artificial Intelligence</a> to discuss the potential impact of robots and computers and the impact of the hypothetical possibility that they could become self-sufficient and able to make their own decisions. They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy, and to what degree they could use such abilities to possibly pose any threat or hazard. They noted that some machines have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They also noted that some computer viruses can evade elimination and have achieved \"cockroach intelligence\". They noted that self-awareness as depicted in science-fiction is probably unlikely, but that there were other potential hazards and pitfalls.<sup class=\"reference\" id=\"cite_ref-nytimes_july09_17-1\"><a href=\"#cite_note-nytimes_july09-17\">[17]</a></sup>\n</p><p>However, there is one technology in particular that could truly bring the possibility of robots with moral competence to reality. In a paper on the acquisition of moral values by robots, <a href=\"/wiki/Nayef_Al-Rodhan\" title=\"Nayef Al-Rodhan\">Nayef Al-Rodhan</a> mentions the case of <a href=\"/wiki/Neuromorphic_engineering\" title=\"Neuromorphic engineering\">neuromorphic</a> chips, which aim to process information similarly to humans, nonlinearly and with millions of interconnected artificial neurons.<sup class=\"reference\" id=\"cite_ref-21\"><a href=\"#cite_note-21\">[21]</a></sup> Robots embedded with neuromorphic technology could learn and develop knowledge in a uniquely humanlike way. Inevitably, this raises the question of the environment in which such robots would learn about the world and whose morality they would inherit – or if they end up developing human 'weaknesses' as well: selfishness, a pro-survival attitude, hesitation etc.\n</p><p>In <i>Moral Machines: Teaching Robots Right from Wrong</i>,<sup class=\"reference\" id=\"cite_ref-Wallach2008_22-0\"><a href=\"#cite_note-Wallach2008-22\">[22]</a></sup> Wendell Wallach and Colin Allen conclude that attempts to teach robots right from wrong will likely advance understanding of human ethics by motivating humans to address gaps in modern <a href=\"/wiki/Normative_ethics\" title=\"Normative ethics\">normative theory</a> and by providing a platform for experimental investigation. As one example, it has introduced normative ethicists to the controversial issue of which specific <a class=\"mw-redirect\" href=\"/wiki/List_of_machine_learning_algorithms\" title=\"List of machine learning algorithms\">learning algorithms</a> to use in machines. <a href=\"/wiki/Nick_Bostrom\" title=\"Nick Bostrom\">Nick Bostrom</a> and <a href=\"/wiki/Eliezer_Yudkowsky\" title=\"Eliezer Yudkowsky\">Eliezer Yudkowsky</a> have argued for <a href=\"/wiki/Decision_tree\" title=\"Decision tree\">decision trees</a> (such as <a href=\"/wiki/ID3_algorithm\" title=\"ID3 algorithm\">ID3</a>) over <a href=\"/wiki/Artificial_neural_network\" title=\"Artificial neural network\">neural networks</a> and <a href=\"/wiki/Genetic_algorithm\" title=\"Genetic algorithm\">genetic algorithms</a> on the grounds that decision trees obey modern social norms of transparency and predictability (e.g. <i><a class=\"mw-redirect\" href=\"/wiki/Stare_decisis\" title=\"Stare decisis\">stare decisis</a></i>),<sup class=\"reference\" id=\"cite_ref-23\"><a href=\"#cite_note-23\">[23]</a></sup> while Chris Santos-Lang argued in the opposite direction on the grounds that the norms of any age must be allowed to change and that natural failure to fully satisfy these particular norms has been essential in making humans less vulnerable to criminal \"<a href=\"/wiki/Hacker_culture\" title=\"Hacker culture\">hackers</a>\".<sup class=\"reference\" id=\"cite_ref-SantosLang2002_24-0\"><a href=\"#cite_note-SantosLang2002-24\">[24]</a></sup>\n</p><p>According to a 2019 report from the Center for the Governance of AI at the University of Oxford, 82% of Americans believe that robots and AI should be carefully managed. Concerns cited ranged from how AI is used in surveillance and in spreading fake content online (known as deep fakes when they include doctored video images and audio generated with help from AI) to cyberattacks, infringements on data privacy, hiring bias, autonomous vehicles, and drones that do not require a human controller.<sup class=\"reference\" id=\"cite_ref-25\"><a href=\"#cite_note-25\">[25]</a></sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"Ethics_principles_of_artificial_intelligence\">Ethics principles of artificial intelligence</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=4\" title=\"Edit section: Ethics principles of artificial intelligence\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>In the review of 84<sup class=\"reference\" id=\"cite_ref-auto_26-0\"><a href=\"#cite_note-auto-26\">[26]</a></sup> ethics guidelines for AI 11 clusters of principles were found: transparency, justice and fairness, non-maleficence, responsibility, privacy, beneficence, freedom and autonomy, trust, sustainability, dignity, solidarity.<sup class=\"reference\" id=\"cite_ref-auto_26-1\"><a href=\"#cite_note-auto-26\">[26]</a></sup>\n</p><p><a href=\"/wiki/Luciano_Floridi\" title=\"Luciano Floridi\">Luciano Floridi</a> and Josh Cowls created an ethical framework of AI principles set by four principles of <a href=\"/wiki/Bioethics\" title=\"Bioethics\">bioethics</a> (<a href=\"/wiki/Beneficence_(ethics)\" title=\"Beneficence (ethics)\">beneficence</a>, <a class=\"mw-redirect\" href=\"/wiki/Non-maleficence\" title=\"Non-maleficence\">non-maleficence</a>, <a href=\"/wiki/Autonomy\" title=\"Autonomy\">autonomy</a> and <a href=\"/wiki/Justice\" title=\"Justice\">justice</a>) and an additional AI enabling principle – explicability.<sup class=\"reference\" id=\"cite_ref-27\"><a href=\"#cite_note-27\">[27]</a></sup>\n</p>\n<h4><span id=\"Transparency.2C_accountability.2C_and_open_source\"></span><span class=\"mw-headline\" id=\"Transparency,_accountability,_and_open_source\">Transparency, accountability, and open source</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=5\" title=\"Edit section: Transparency, accountability, and open source\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h4>\n<p><a href=\"/wiki/Bill_Hibbard\" title=\"Bill Hibbard\">Bill Hibbard</a> argues that because AI will have such a profound effect on humanity, AI developers are representatives of future humanity and thus have an ethical obligation to be transparent in their efforts.<sup class=\"reference\" id=\"cite_ref-AGI-08a_28-0\"><a href=\"#cite_note-AGI-08a-28\">[28]</a></sup> <a href=\"/wiki/Ben_Goertzel\" title=\"Ben Goertzel\">Ben Goertzel</a> and David Hart created <a href=\"/wiki/OpenCog\" title=\"OpenCog\">OpenCog</a> as an <a href=\"/wiki/Open-source_software\" title=\"Open-source software\">open source</a> framework for AI development.<sup class=\"reference\" id=\"cite_ref-AGI-08b_29-0\"><a href=\"#cite_note-AGI-08b-29\">[29]</a></sup> <a href=\"/wiki/OpenAI\" title=\"OpenAI\">OpenAI</a> is a non-profit AI research company created by <a href=\"/wiki/Elon_Musk\" title=\"Elon Musk\">Elon Musk</a>, <a href=\"/wiki/Sam_Altman\" title=\"Sam Altman\">Sam Altman</a> and others to develop open-source AI beneficial to humanity.<sup class=\"reference\" id=\"cite_ref-OpenAI_30-0\"><a href=\"#cite_note-OpenAI-30\">[30]</a></sup> There are numerous other open-source AI developments.\n</p><p>Unfortunately, making code open source does not make it comprehensible, which by many definitions means that the AI code is not transparent. The <a class=\"mw-redirect\" href=\"/wiki/IEEE\" title=\"IEEE\">IEEE</a> has a <a class=\"mw-redirect\" href=\"/wiki/Technical_standards\" title=\"Technical standards\">standardisation effort</a> on AI transparency.<sup class=\"reference\" id=\"cite_ref-p7001_31-0\"><a href=\"#cite_note-p7001-31\">[31]</a></sup> The IEEE effort identifies multiple scales of transparency for different users. Further, there is concern that releasing the full capacity of contemporary AI to some organizations may be a public bad, that is, do more damage than good. For example, Microsoft has expressed concern about allowing universal access to its face recognition software, even for those who can pay for it. Microsoft posted an extraordinary blog on this topic, asking for government regulation to help determine the right thing to do.<sup class=\"reference\" id=\"cite_ref-WiredMS_32-0\"><a href=\"#cite_note-WiredMS-32\">[32]</a></sup>\n</p><p>Not only companies, but many other researchers and citizen advocates recommend government regulation as a means of ensuring transparency, and through it, human accountability. This strategy has proven controversial, as some worry that it will slow the rate of innovation. Others argue that regulation leads to systemic stability more able to support innovation in the long term.<sup class=\"reference\" id=\"cite_ref-DeloitteGDPR_33-0\"><a href=\"#cite_note-DeloitteGDPR-33\">[33]</a></sup> The <a href=\"/wiki/OECD\" title=\"OECD\">OECD</a>, <a class=\"mw-redirect\" href=\"/wiki/UN\" title=\"UN\">UN</a>, <a class=\"mw-redirect\" href=\"/wiki/EU\" title=\"EU\">EU</a>, and many countries are presently working on strategies for regulating AI, and finding appropriate legal frameworks.<sup class=\"reference\" id=\"cite_ref-34\"><a href=\"#cite_note-34\">[34]</a></sup><sup class=\"reference\" id=\"cite_ref-35\"><a href=\"#cite_note-35\">[35]</a></sup><sup class=\"reference\" id=\"cite_ref-36\"><a href=\"#cite_note-36\">[36]</a></sup>\n</p><p>On June 26, 2019, the European Commission High-Level Expert Group on Artificial Intelligence (AI HLEG) published its \"Policy and investment recommendations for trustworthy Artificial Intelligence\".<sup class=\"reference\" id=\"cite_ref-37\"><a href=\"#cite_note-37\">[37]</a></sup> This is the AI HLEG's second deliverable, after the April 2019 publication of the \"Ethics Guidelines for Trustworthy AI\". The June AI HLEG recommendations cover four principal subjects: humans and society at large, research and academia, the private sector, and the public sector. The European Commission claims that \"HLEG's recommendations reflect an appreciation of both the opportunities for AI technologies to drive economic growth, prosperity and innovation, as well as the potential risks involved\" and states that the EU aims to lead on the framing of policies governing AI internationally.<sup class=\"reference\" id=\"cite_ref-38\"><a href=\"#cite_note-38\">[38]</a></sup> To prevent harm, in addition to regulation, AI-deploying organizations need to play a central role in creating and deploying trustworthy AI in line with the principles of trustworthy AI, and take accountability to mitigate the risks.<sup class=\"reference\" id=\"cite_ref-39\"><a href=\"#cite_note-39\">[39]</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Ethical_challenges\">Ethical challenges</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=6\" title=\"Edit section: Ethical challenges\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<h3><span class=\"mw-headline\" id=\"Biases_in_AI_systems\">Biases in AI systems</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=7\" title=\"Edit section: Biases in AI systems\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<link href=\"mw-data:TemplateStyles:r1033289096\" rel=\"mw-deduplicated-inline-style\"/><div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Algorithmic_bias\" title=\"Algorithmic bias\">Algorithmic bias</a></div>\n<div class=\"thumb tright\"><div class=\"thumbinner\" style=\"width:222px;\"><video class=\"thumbimage\" controls=\"\" data-durationhint=\"56\" data-mwprovider=\"wikimediacommons\" data-mwtitle=\"Kamala_Harris_speaks_about_racial_bias_in_artificial_intelligence_-_2020-04-23.ogv\" height=\"220\" id=\"mwe_player_0\" poster=\"//upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Kamala_Harris_speaks_about_racial_bias_in_artificial_intelligence_-_2020-04-23.ogv/220px--Kamala_Harris_speaks_about_racial_bias_in_artificial_intelligence_-_2020-04-23.ogv.jpg\" preload=\"none\" width=\"220\"><source data-bandwidth=\"2458550\" data-framerate=\"29.97002997003\" data-height=\"720\" data-shorttitle=\"Ogg source\" data-title=\"Original Ogg file, 720 × 720 (2.46 Mbps)\" data-width=\"720\" src=\"//upload.wikimedia.org/wikipedia/commons/5/5b/Kamala_Harris_speaks_about_racial_bias_in_artificial_intelligence_-_2020-04-23.ogv\" type='video/ogg; codecs=\"theora, vorbis\"'/></video> <div class=\"thumbcaption\"><div class=\"magnify\"><a class=\"internal\" href=\"/wiki/File:Kamala_Harris_speaks_about_racial_bias_in_artificial_intelligence_-_2020-04-23.ogv\" title=\"Enlarge\"></a></div>Then-US Senator <a href=\"/wiki/Kamala_Harris\" title=\"Kamala Harris\">Kamala Harris</a> speaking about racial bias in artificial intelligence in 2020</div></div></div>\n<p>AI has become increasingly inherent in facial and <a href=\"/wiki/Speech_recognition\" title=\"Speech recognition\">voice recognition</a> systems. Some of these systems have real business applications and directly impact people. These systems are vulnerable to biases and errors introduced by its human creators. Also, the data used to train these AI systems itself can have biases.<sup class=\"reference\" id=\"cite_ref-40\"><a href=\"#cite_note-40\">[40]</a></sup><sup class=\"reference\" id=\"cite_ref-41\"><a href=\"#cite_note-41\">[41]</a></sup><sup class=\"reference\" id=\"cite_ref-42\"><a href=\"#cite_note-42\">[42]</a></sup><sup class=\"reference\" id=\"cite_ref-43\"><a href=\"#cite_note-43\">[43]</a></sup> For instance, <a href=\"/wiki/Facial_recognition_system\" title=\"Facial recognition system\">facial recognition</a> algorithms made by Microsoft, IBM and Face++ all had biases when it came to detecting people's gender;<sup class=\"reference\" id=\"cite_ref-44\"><a href=\"#cite_note-44\">[44]</a></sup> these AI systems were able to detect gender of white men more accurately than gender of darker skin men. Further, a 2020 study reviewed voice recognition systems from Amazon, Apple, Google, IBM, and Microsoft found that they have higher error rates when transcribing black people's voices than white people's.<sup class=\"reference\" id=\"cite_ref-45\"><a href=\"#cite_note-45\">[45]</a></sup> Furthermore, <a href=\"/wiki/Amazon_(company)\" title=\"Amazon (company)\">Amazon</a> terminated their use of <a href=\"/wiki/Artificial_intelligence_in_hiring\" title=\"Artificial intelligence in hiring\">AI hiring and recruitment</a> because the algorithm favored male candidates over female ones. This was because Amazon's system was trained with data collected over 10-year period that came mostly from male candidates.<sup class=\"reference\" id=\"cite_ref-46\"><a href=\"#cite_note-46\">[46]</a></sup>\n</p><p>Bias can creep into algorithms in many ways. The most predominant view on how bias is introduced into AI systems is that it is embedded within the historical data used to train the system. For instance, Amazon's AI-powered recruitment tool was trained with its own recruitment data accumulated over the years, during which time the candidates that successfully got the job were mostly white males. Consequently, the algorithms learned the (biased) pattern from the historical data and generated predictions for the present/future that these types of candidates are mostly like to succeed in getting the job. Therefore, the recruitment decisions made by the AI system turn out to be biased against female and minority candidates. Friedman and Nissenbaum identify three categories of bias in computer systems: existing bias, technical bias, and emergent bias.<sup class=\"reference\" id=\"cite_ref-47\"><a href=\"#cite_note-47\">[47]</a></sup> In <a href=\"/wiki/Natural_language_processing\" title=\"Natural language processing\">natural language processing</a>, problems can arise from the <a href=\"/wiki/Text_corpus\" title=\"Text corpus\">text corpus</a> — the source material the algorithm uses to learn about the relationships between different words.<sup class=\"reference\" id=\"cite_ref-48\"><a href=\"#cite_note-48\">[48]</a></sup>\n</p><p>Large companies such as IBM, Google, etc. have made efforts to research and address these biases.<sup class=\"reference\" id=\"cite_ref-49\"><a href=\"#cite_note-49\">[49]</a></sup><sup class=\"reference\" id=\"cite_ref-50\"><a href=\"#cite_note-50\">[50]</a></sup><sup class=\"reference\" id=\"cite_ref-51\"><a href=\"#cite_note-51\">[51]</a></sup> One solution for addressing bias is to create documentation for the data used to train AI systems.<sup class=\"reference\" id=\"cite_ref-52\"><a href=\"#cite_note-52\">[52]</a></sup><sup class=\"reference\" id=\"cite_ref-53\"><a href=\"#cite_note-53\">[53]</a></sup> <a href=\"/wiki/Process_mining\" title=\"Process mining\">Process mining</a> can be an important tool for organizations to achieve compliance with proposed AI regulations by identifying errors, monitoring processes, identifying potential root causes for improper execution, and other functions.<sup class=\"reference\" id=\"cite_ref-54\"><a href=\"#cite_note-54\">[54]</a></sup>\n</p><p>The problem of bias in machine learning is likely to become more significant as the technology spreads to critical areas like medicine and law, and as more people without a deep technical understanding are tasked with deploying it. Some experts warn that <a href=\"/wiki/Algorithmic_bias\" title=\"Algorithmic bias\">algorithmic bias</a> is already pervasive in many industries and that almost no one is making an effort to identify or correct it.<sup class=\"reference\" id=\"cite_ref-55\"><a href=\"#cite_note-55\">[55]</a></sup> There are some open-sourced tools <sup class=\"reference\" id=\"cite_ref-56\"><a href=\"#cite_note-56\">[56]</a></sup> by civil societies that are looking to bring more awareness to biased AI.\n</p>\n<h3><span class=\"mw-headline\" id=\"Robot_rights\">Robot rights</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=8\" title=\"Edit section: Robot rights\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>\"Robot rights\" is the concept that people should have moral obligations towards their machines, akin to <a href=\"/wiki/Human_rights\" title=\"Human rights\">human rights</a> or <a href=\"/wiki/Animal_rights\" title=\"Animal rights\">animal rights</a>.<sup class=\"reference\" id=\"cite_ref-57\"><a href=\"#cite_note-57\">[57]</a></sup> It has been suggested that robot rights (such as a right to exist and perform its own mission) could be linked to robot duty to serve humanity, analogous to linking human rights with human duties before society.<sup class=\"reference\" id=\"cite_ref-58\"><a href=\"#cite_note-58\">[58]</a></sup> These could include the right to life and liberty, freedom of thought and expression, and equality before the law.<sup class=\"reference\" id=\"cite_ref-59\"><a href=\"#cite_note-59\">[59]</a></sup> The issue has been considered by the <a href=\"/wiki/Institute_for_the_Future\" title=\"Institute for the Future\">Institute for the Future</a><sup class=\"reference\" id=\"cite_ref-60\"><a href=\"#cite_note-60\">[60]</a></sup> and by the <a href=\"/wiki/Department_of_Trade_and_Industry_(United_Kingdom)\" title=\"Department of Trade and Industry (United Kingdom)\">U.K. Department of Trade and Industry</a>.<sup class=\"reference\" id=\"cite_ref-TimesOnline_61-0\"><a href=\"#cite_note-TimesOnline-61\">[61]</a></sup>\n</p><p>Experts disagree on how soon specific and detailed laws on the subject will be necessary.<sup class=\"reference\" id=\"cite_ref-TimesOnline_61-1\"><a href=\"#cite_note-TimesOnline-61\">[61]</a></sup> Glenn McGee reported that sufficiently humanoid robots might appear by 2020,<sup class=\"reference\" id=\"cite_ref-62\"><a href=\"#cite_note-62\">[62]</a></sup> while <a href=\"/wiki/Ray_Kurzweil\" title=\"Ray Kurzweil\">Ray Kurzweil</a> sets the date at 2029.<sup class=\"reference\" id=\"cite_ref-63\"><a href=\"#cite_note-63\">[63]</a></sup> Another group of scientists meeting in 2007 supposed that at least 50 years had to pass before any sufficiently advanced system would exist.<sup class=\"reference\" id=\"cite_ref-64\"><a href=\"#cite_note-64\">[64]</a></sup>\n</p><p>The rules for the 2003 <a href=\"/wiki/Loebner_Prize\" title=\"Loebner Prize\">Loebner Prize</a> competition envisioned the possibility of robots having rights of their own:\n</p>\n<blockquote><p>61. If in any given year, a publicly available open-source Entry entered by the University of Surrey or the Cambridge Center wins the Silver Medal or the Gold Medal, then the Medal and the Cash Award will be awarded to the body responsible for the development of that Entry. If no such body can be identified, or if there is disagreement among two or more claimants, the Medal and the Cash Award will be held in trust until such time as the Entry may legally possess, either in the United States of America or in the venue of the contest, the Cash Award and Gold Medal in its own right.<sup class=\"reference\" id=\"cite_ref-65\"><a href=\"#cite_note-65\">[65]</a></sup> </p></blockquote>\n<p>In October 2017, the android <a href=\"/wiki/Sophia_(robot)\" title=\"Sophia (robot)\">Sophia</a> was granted \"honorary\" citizenship in <a href=\"/wiki/Saudi_Arabia\" title=\"Saudi Arabia\">Saudi Arabia</a>, though some considered this to be more of a publicity stunt than a meaningful legal recognition.<sup class=\"reference\" id=\"cite_ref-66\"><a href=\"#cite_note-66\">[66]</a></sup> Some saw this gesture as openly denigrating of <a href=\"/wiki/Human_rights\" title=\"Human rights\">human rights</a> and the <a href=\"/wiki/Rule_of_law\" title=\"Rule of law\">rule of law</a>.<sup class=\"reference\" id=\"cite_ref-bs_67-0\"><a href=\"#cite_note-bs-67\">[67]</a></sup>\n</p><p>The philosophy of <a class=\"mw-redirect\" href=\"/wiki/Sentientism\" title=\"Sentientism\">Sentientism</a> grants degrees of moral consideration to all sentient beings, primarily humans and most non-human animals. If artificial or alien intelligence show evidence of being <a href=\"/wiki/Sentience\" title=\"Sentience\">sentient</a>, this philosophy holds that they should be shown compassion and granted rights.\n</p><p><a href=\"/wiki/Joanna_Bryson\" title=\"Joanna Bryson\">Joanna Bryson</a> has argued that creating AI that requires rights is both avoidable, and would in itself be unethical, both as a burden to the AI agents and to human society.<sup class=\"reference\" id=\"cite_ref-68\"><a href=\"#cite_note-68\">[68]</a></sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"Threat_to_human_dignity\">Threat to human dignity</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=9\" title=\"Edit section: Threat to human dignity\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<link href=\"mw-data:TemplateStyles:r1033289096\" rel=\"mw-deduplicated-inline-style\"/><div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Computer_Power_and_Human_Reason\" title=\"Computer Power and Human Reason\">Computer Power and Human Reason</a></div>\n<p><a href=\"/wiki/Joseph_Weizenbaum\" title=\"Joseph Weizenbaum\">Joseph Weizenbaum</a><sup class=\"reference\" id=\"cite_ref-Weizenbaum's_critique_69-0\"><a href=\"#cite_note-Weizenbaum's_critique-69\">[69]</a></sup> argued in 1976 that AI technology should not be used to replace people in positions that require respect and care, such as:\n</p>\n<ul><li>A customer service representative (AI technology is already used today for telephone-based <a href=\"/wiki/Interactive_voice_response\" title=\"Interactive voice response\">interactive voice response</a> systems)</li>\n<li>A nursemaid for the elderly (as was reported by <a href=\"/wiki/Pamela_McCorduck\" title=\"Pamela McCorduck\">Pamela McCorduck</a> in her book <i>The Fifth Generation</i>)</li>\n<li>A soldier</li>\n<li>A judge</li>\n<li>A police officer</li>\n<li>A therapist (as was proposed by <a href=\"/wiki/Kenneth_Colby\" title=\"Kenneth Colby\">Kenneth Colby</a> in the 70s)</li></ul>\n<p>Weizenbaum explains that we require authentic feelings of <a href=\"/wiki/Empathy\" title=\"Empathy\">empathy</a> from people in these positions. If machines replace them, we will find ourselves alienated, devalued and frustrated, for the artificially intelligent system would not be able to simulate empathy. Artificial intelligence, if used in this way, represents a threat to human dignity. Weizenbaum argues that the fact that we are entertaining the possibility of machines in these positions suggests that we have experienced an \"atrophy of the human spirit that comes from thinking of ourselves as computers.\"<sup class=\"reference\" id=\"cite_ref-MWZ_70-0\"><a href=\"#cite_note-MWZ-70\">[70]</a></sup>\n</p><p><a href=\"/wiki/Pamela_McCorduck\" title=\"Pamela McCorduck\">Pamela McCorduck</a> counters that, speaking for women and minorities \"I'd rather take my chances with an impartial computer\", pointing out that there are conditions where we would prefer to have automated judges and police that have no personal agenda at all.<sup class=\"reference\" id=\"cite_ref-MWZ_70-1\"><a href=\"#cite_note-MWZ-70\">[70]</a></sup> However, <a href=\"/wiki/Andreas_Kaplan\" title=\"Andreas Kaplan\">Kaplan</a> and Haenlein stress that AI systems are only as smart as the data used to train them since they are, in their essence, nothing more than fancy curve-fitting machines; Using AI to support a court ruling can be highly problematic if past rulings show bias toward certain groups since those biases get formalized and engrained, which makes them even more difficult to spot and fight against.<sup class=\"reference\" id=\"cite_ref-71\"><a href=\"#cite_note-71\">[71]</a></sup>\n</p><p>Weizenbaum was also bothered that AI researchers (and some philosophers) were willing to view the human mind as nothing more than a computer program (a position now known as <a class=\"mw-redirect\" href=\"/wiki/Computationalism\" title=\"Computationalism\">computationalism</a>). To Weizenbaum, these points suggest that AI research devalues human life.<sup class=\"reference\" id=\"cite_ref-Weizenbaum's_critique_69-1\"><a href=\"#cite_note-Weizenbaum's_critique-69\">[69]</a></sup>\n</p><p>AI founder <a href=\"/wiki/John_McCarthy_(computer_scientist)\" title=\"John McCarthy (computer scientist)\">John McCarthy</a> objects to the moralizing tone of Weizenbaum's critique. \"When moralizing is both vehement and vague, it invites authoritarian abuse,\" he writes. <a href=\"/wiki/Bill_Hibbard\" title=\"Bill Hibbard\">Bill Hibbard</a><sup class=\"reference\" id=\"cite_ref-hibbard_2014_72-0\"><a href=\"#cite_note-hibbard_2014-72\">[72]</a></sup> writes that \"Human dignity requires that we strive to remove our ignorance of the nature of existence, and AI is necessary for that striving.\"\n</p>\n<h3><span class=\"mw-headline\" id=\"Liability_for_self-driving_cars\">Liability for self-driving cars</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=10\" title=\"Edit section: Liability for self-driving cars\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<link href=\"mw-data:TemplateStyles:r1033289096\" rel=\"mw-deduplicated-inline-style\"/><div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Self-driving_car_liability\" title=\"Self-driving car liability\">Self-driving car liability</a></div>\n<p>As the widespread use of <a href=\"/wiki/Self-driving_car\" title=\"Self-driving car\">autonomous cars</a> becomes increasingly imminent, new challenges raised by fully autonomous vehicles must be addressed.<sup class=\"reference\" id=\"cite_ref-73\"><a href=\"#cite_note-73\">[73]</a></sup><sup class=\"reference\" id=\"cite_ref-74\"><a href=\"#cite_note-74\">[74]</a></sup> Recently,<sup class=\"noprint Inline-Template\" style=\"white-space:nowrap;\">[<i><a href=\"/wiki/Wikipedia:Manual_of_Style/Dates_and_numbers#Chronological_items\" title=\"Wikipedia:Manual of Style/Dates and numbers\"><span title=\"The time period mentioned near this tag is ambiguous. (November 2020)\">when?</span></a></i>]</sup> there has been debate as to the legal liability of the responsible party if these cars get into accidents.<sup class=\"reference\" id=\"cite_ref-75\"><a href=\"#cite_note-75\">[75]</a></sup><sup class=\"reference\" id=\"cite_ref-76\"><a href=\"#cite_note-76\">[76]</a></sup> In one report where a driverless car hit a pedestrian, the driver was inside the car but the controls were fully in the hand of computers. This led to a dilemma over who was at fault for the accident.<sup class=\"reference\" id=\"cite_ref-77\"><a href=\"#cite_note-77\">[77]</a></sup>\n</p><p>In another incident on March 18, 2018, <a class=\"mw-redirect\" href=\"/wiki/Elaine_Herzberg\" title=\"Elaine Herzberg\">Elaine Herzberg</a> was struck and killed by a self-driving <a href=\"/wiki/Uber\" title=\"Uber\">Uber</a> in Arizona. In this case, the automated car was capable of detecting cars and certain obstacles in order to autonomously navigate the roadway, but it could not anticipate a pedestrian in the middle of the road. This raised the question of whether the driver, pedestrian, the car company, or the government should be held responsible for her death.<sup class=\"reference\" id=\"cite_ref-78\"><a href=\"#cite_note-78\">[78]</a></sup>\n</p><p>Currently, self-driving cars are considered semi-autonomous, requiring the driver to pay attention and be prepared to take control if necessary.<sup class=\"reference\" id=\"cite_ref-79\"><a href=\"#cite_note-79\">[79]</a></sup><sup class=\"noprint Inline-Template\" style=\"white-space:nowrap;\">[<i><a href=\"/wiki/Wikipedia:Verifiability\" title=\"Wikipedia:Verifiability\"><span title=\"The material near this tag failed verification of its source citation(s). (November 2020)\">failed verification</span></a></i>]</sup> Thus, it falls on governments to regulate the driver who over-relies on autonomous features. as well educate them that these are just technologies that, while convenient, are not a complete substitute. Before autonomous cars become widely used, these issues need to be tackled through new policies.<sup class=\"reference\" id=\"cite_ref-80\"><a href=\"#cite_note-80\">[80]</a></sup><sup class=\"reference\" id=\"cite_ref-81\"><a href=\"#cite_note-81\">[81]</a></sup><sup class=\"reference\" id=\"cite_ref-82\"><a href=\"#cite_note-82\">[82]</a></sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"Weaponization_of_artificial_intelligence\">Weaponization of artificial intelligence</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=11\" title=\"Edit section: Weaponization of artificial intelligence\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<link href=\"mw-data:TemplateStyles:r1033289096\" rel=\"mw-deduplicated-inline-style\"/><div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Lethal_autonomous_weapon\" title=\"Lethal autonomous weapon\">Lethal autonomous weapon</a></div>\n<p>Some experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomy.<sup class=\"reference\" id=\"cite_ref-Call_for_debate_on_killer_robots_13-1\"><a href=\"#cite_note-Call_for_debate_on_killer_robots-13\">[13]</a></sup><sup class=\"reference\" id=\"cite_ref-83\"><a href=\"#cite_note-83\">[83]</a></sup> On October 31, 2019, the United States Department of Defense's Defense Innovation Board published the draft of a report recommending principles for the ethical use of artificial intelligence by the Department of Defense that would ensure a human operator would always be able to look into the 'black box' and understand the kill-chain process. However, a major concern is how the report will be implemented.<sup class=\"reference\" id=\"cite_ref-84\"><a href=\"#cite_note-84\">[84]</a></sup> The US Navy has funded a report which indicates that as <a class=\"mw-redirect\" href=\"/wiki/Military_robots\" title=\"Military robots\">military robots</a> become more complex, there should be greater attention to implications of their ability to make autonomous decisions.<sup class=\"reference\" id=\"cite_ref-85\"><a href=\"#cite_note-85\">[85]</a></sup><sup class=\"reference\" id=\"cite_ref-engadget.com_15-1\"><a href=\"#cite_note-engadget.com-15\">[15]</a></sup> Some researchers state that <a href=\"/wiki/Autonomous_robot\" title=\"Autonomous robot\">autonomous robots</a> might be more humane, as they could make decisions more effectively.<sup class=\"reference\" id=\"cite_ref-86\"><a href=\"#cite_note-86\">[86]</a></sup>\n</p><p>Within this last decade, there has been intensive research in autonomous power with the ability to learn using assigned moral responsibilities. \"The results may be used when designing future military robots, to control unwanted tendencies to assign responsibility to the robots.\"<sup class=\"reference\" id=\"cite_ref-87\"><a href=\"#cite_note-87\">[87]</a></sup> From a <a href=\"/wiki/Consequentialism\" title=\"Consequentialism\">consequentialist</a> view, there is a chance that robots will develop the ability to make their own logical decisions on whom to kill and that is why there should be a set <a href=\"/wiki/Morality\" title=\"Morality\">moral</a> framework that the AI cannot override.<sup class=\"reference\" id=\"cite_ref-88\"><a href=\"#cite_note-88\">[88]</a></sup>\n</p><p>There has been a recent outcry with regard to the engineering of artificial intelligence weapons that have included ideas of a robot takeover of mankind. AI weapons do present a type of danger different from that of human-controlled weapons. Many governments have begun to fund programs to develop AI weaponry. The United States Navy recently announced plans to develop <a href=\"/wiki/Unmanned_combat_aerial_vehicle\" title=\"Unmanned combat aerial vehicle\">autonomous drone weapons</a>, paralleling similar announcements by Russia and Korea respectively. Due to the potential of AI weapons becoming more dangerous than human-operated weapons, <a href=\"/wiki/Stephen_Hawking\" title=\"Stephen Hawking\">Stephen Hawking</a> and <a href=\"/wiki/Max_Tegmark\" title=\"Max Tegmark\">Max Tegmark</a> signed a \"Future of Life\" petition<sup class=\"reference\" id=\"cite_ref-89\"><a href=\"#cite_note-89\">[89]</a></sup> to ban AI weapons. The message posted by Hawking and Tegmark states that AI weapons pose an immediate danger and that action is required to avoid catastrophic disasters in the near future.<sup class=\"reference\" id=\"cite_ref-theatlantic.com_90-0\"><a href=\"#cite_note-theatlantic.com-90\">[90]</a></sup>\n</p><p>\"If any major military power pushes ahead with the AI weapon development, a global <a href=\"/wiki/Arms_race\" title=\"Arms race\">arms race</a> is virtually inevitable, and the endpoint of this technological trajectory is obvious: autonomous weapons will become the Kalashnikovs of tomorrow\", says the petition, which includes <a href=\"/wiki/Skype\" title=\"Skype\">Skype</a> co-founder <a href=\"/wiki/Jaan_Tallinn\" title=\"Jaan Tallinn\">Jaan Tallinn</a> and MIT professor of linguistics <a href=\"/wiki/Noam_Chomsky\" title=\"Noam Chomsky\">Noam Chomsky</a> as additional supporters against AI weaponry.<sup class=\"reference\" id=\"cite_ref-91\"><a href=\"#cite_note-91\">[91]</a></sup>\n</p><p>Physicist and Astronomer Royal <a class=\"mw-redirect\" href=\"/wiki/Sir_Martin_Rees\" title=\"Sir Martin Rees\">Sir Martin Rees</a> has warned of catastrophic instances like \"dumb robots going rogue or a network that develops a mind of its own.\" <a href=\"/wiki/Huw_Price\" title=\"Huw Price\">Huw Price</a>, a colleague of Rees at Cambridge, has voiced a similar warning that humans might not survive when intelligence \"escapes the constraints of biology\". These two professors created the <a href=\"/wiki/Centre_for_the_Study_of_Existential_Risk\" title=\"Centre for the Study of Existential Risk\">Centre for the Study of Existential Risk</a> at Cambridge University in the hope of avoiding this threat to human existence.<sup class=\"reference\" id=\"cite_ref-theatlantic.com_90-1\"><a href=\"#cite_note-theatlantic.com-90\">[90]</a></sup>\n</p><p>Regarding the potential for smarter-than-human systems to be employed militarily, the <a class=\"mw-redirect\" href=\"/wiki/Open_Philanthropy_Project\" title=\"Open Philanthropy Project\">Open Philanthropy Project</a> writes that these scenarios \"seem potentially as important as the risks related to loss of control\", but research investigating AI's long-run social impact have spent relatively little time on this concern: \"this class of scenarios has not been a major focus for the organizations that have been most active in this space, such as the <a href=\"/wiki/Machine_Intelligence_Research_Institute\" title=\"Machine Intelligence Research Institute\">Machine Intelligence Research Institute</a> (MIRI) and the <a href=\"/wiki/Future_of_Humanity_Institute\" title=\"Future of Humanity Institute\">Future of Humanity Institute</a> (FHI), and there seems to have been less analysis and debate regarding them\".<sup class=\"reference\" id=\"cite_ref-givewell_92-0\"><a href=\"#cite_note-givewell-92\">[92]</a></sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"Opaque_algorithms\">Opaque algorithms</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=12\" title=\"Edit section: Opaque algorithms\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Approaches like machine learning with <a href=\"/wiki/Neural_network\" title=\"Neural network\">neural networks</a> can result in computers making decisions that they and the humans who programmed them cannot explain. It is difficult for people to determine if such decisions are fair and trustworthy, leading potentially to bias in AI systems going undetected, or people rejecting the use of such systems. This has led to advocacy and in some jurisdictions legal requirements for <a href=\"/wiki/Explainable_artificial_intelligence\" title=\"Explainable artificial intelligence\">explainable artificial intelligence</a>.<sup class=\"reference\" id=\"cite_ref-93\"><a href=\"#cite_note-93\">[93]</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"Singularity\">Singularity</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=13\" title=\"Edit section: Singularity\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<link href=\"mw-data:TemplateStyles:r1033289096\" rel=\"mw-deduplicated-inline-style\"/><div class=\"hatnote navigation-not-searchable\" role=\"note\">Further information: <a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">Existential risk from artificial general intelligence</a>, <a href=\"/wiki/Superintelligence\" title=\"Superintelligence\">Superintelligence</a>, and <a href=\"/wiki/Technological_singularity\" title=\"Technological singularity\">Technological singularity</a></div>\n<p>Many researchers have argued that, by way of an \"intelligence explosion\", a self-improving AI could become so powerful that humans would not be able to stop it from achieving its goals.<sup class=\"reference\" id=\"cite_ref-Muehlhauser,_Luke_2012_94-0\"><a href=\"#cite_note-Muehlhauser,_Luke_2012-94\">[94]</a></sup> In his paper \"Ethical Issues in Advanced Artificial Intelligence\" and subsequent book <i><a href=\"/wiki/Superintelligence:_Paths,_Dangers,_Strategies\" title=\"Superintelligence: Paths, Dangers, Strategies\">Superintelligence: Paths, Dangers, Strategies</a></i>, philosopher <a href=\"/wiki/Nick_Bostrom\" title=\"Nick Bostrom\">Nick Bostrom</a> argues that artificial intelligence has the capability to bring about human extinction. He claims that general <a href=\"/wiki/Superintelligence\" title=\"Superintelligence\">superintelligence</a> would be capable of independent initiative and of making its own plans, and may therefore be more appropriately thought of as an autonomous agent. Since artificial intellects need not share our human motivational tendencies, it would be up to the designers of the superintelligence to specify its original motivations. Because a superintelligent AI would be able to bring about almost any possible outcome and to thwart any attempt to prevent the implementation of its goals, many uncontrolled <a href=\"/wiki/Unintended_consequences\" title=\"Unintended consequences\">unintended consequences</a> could arise. It could kill off all other agents, persuade them to change their behavior, or block their attempts at interference.<sup class=\"reference\" id=\"cite_ref-Bostrom,_Nick_2003_95-0\"><a href=\"#cite_note-Bostrom,_Nick_2003-95\">[95]</a></sup>\n</p><p>However, instead of overwhelming the human race and leading to our destruction, Bostrom has also asserted that superintelligence can help us solve many difficult problems such as disease, poverty, and environmental destruction, and could help us to \"enhance\" ourselves.<sup class=\"reference\" id=\"cite_ref-96\"><a href=\"#cite_note-96\">[96]</a></sup>\n</p><p>The sheer complexity of human value systems makes it very difficult to make AI's motivations human-friendly.<sup class=\"reference\" id=\"cite_ref-Muehlhauser,_Luke_2012_94-1\"><a href=\"#cite_note-Muehlhauser,_Luke_2012-94\">[94]</a></sup><sup class=\"reference\" id=\"cite_ref-Bostrom,_Nick_2003_95-1\"><a href=\"#cite_note-Bostrom,_Nick_2003-95\">[95]</a></sup> Unless moral philosophy provides us with a flawless ethical theory, an AI's utility function could allow for many potentially harmful scenarios that conform with a given ethical framework but not \"common sense\". According to <a href=\"/wiki/Eliezer_Yudkowsky\" title=\"Eliezer Yudkowsky\">Eliezer Yudkowsky</a>, there is little reason to suppose that an artificially designed mind would have such an adaptation.<sup class=\"reference\" id=\"cite_ref-97\"><a href=\"#cite_note-97\">[97]</a></sup> AI researchers such as <a href=\"/wiki/Stuart_J._Russell\" title=\"Stuart J. Russell\">Stuart J. Russell</a>,<sup class=\"reference\" id=\"cite_ref-HC_98-0\"><a href=\"#cite_note-HC-98\">[98]</a></sup> <a href=\"/wiki/Bill_Hibbard\" title=\"Bill Hibbard\">Bill Hibbard</a>,<sup class=\"reference\" id=\"cite_ref-hibbard_2014_72-1\"><a href=\"#cite_note-hibbard_2014-72\">[72]</a></sup> <a href=\"/wiki/Roman_Yampolskiy\" title=\"Roman Yampolskiy\">Roman Yampolskiy</a>,<sup class=\"reference\" id=\"cite_ref-99\"><a href=\"#cite_note-99\">[99]</a></sup> <a href=\"/wiki/Shannon_Vallor\" title=\"Shannon Vallor\">Shannon Vallor</a>,<sup class=\"reference\" id=\"cite_ref-100\"><a href=\"#cite_note-100\">[100]</a></sup> <a class=\"new\" href=\"/w/index.php?title=Steven_Umbrello&amp;action=edit&amp;redlink=1\" title=\"Steven Umbrello (page does not exist)\">Steven Umbrello</a><sup class=\"reference\" id=\"cite_ref-101\"><a href=\"#cite_note-101\">[101]</a></sup> and <a href=\"/wiki/Luciano_Floridi\" title=\"Luciano Floridi\">Luciano Floridi</a><sup class=\"reference\" id=\"cite_ref-102\"><a href=\"#cite_note-102\">[102]</a></sup> have proposed design strategies for developing beneficial machines.\n</p>\n<h2><span class=\"mw-headline\" id=\"Actors_in_AI_ethics\">Actors in AI ethics</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=14\" title=\"Edit section: Actors in AI ethics\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<p>There are many organisations concerned with AI ethics and policy, public and governmental as well as corporate and societal.\n</p><p><a class=\"mw-redirect\" href=\"/wiki/Amazon.com,_Inc.\" title=\"Amazon.com, Inc.\">Amazon</a>, <a href=\"/wiki/Google\" title=\"Google\">Google</a>, <a href=\"/wiki/Facebook\" title=\"Facebook\">Facebook</a>, <a href=\"/wiki/IBM\" title=\"IBM\">IBM</a>, and <a href=\"/wiki/Microsoft\" title=\"Microsoft\">Microsoft</a> have established a non-profit, The Partnership on AI to Benefit People and Society, to formulate best practices on artificial intelligence technologies, advance the public's understanding, and to serve as a platform about artificial intelligence. Apple joined in January 2017. The corporate members will make financial and research contributions to the group, while engaging with the scientific community to bring academics onto the board.<sup class=\"reference\" id=\"cite_ref-103\"><a href=\"#cite_note-103\">[103]</a></sup>\n</p><p>The <a class=\"mw-redirect\" href=\"/wiki/IEEE\" title=\"IEEE\">IEEE</a> put together a Global Initiative on Ethics of Autonomous and Intelligent Systems which has been creating and revising guidelines with the help of public input, and accepts as members many professionals from within and without its organization.\n</p><p>Traditionally, <a href=\"/wiki/Government\" title=\"Government\">government</a> has been used by societies to ensure ethics are observed through legislation and policing. There are now many efforts by national governments, as well as transnational government and <a class=\"mw-redirect\" href=\"/wiki/NGO\" title=\"NGO\">non-government organizations</a> to ensure AI is ethically applied.\n</p>\n<h3><span class=\"mw-headline\" id=\"Intergovernmental_initiatives\">Intergovernmental initiatives</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=15\" title=\"Edit section: Intergovernmental initiatives\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<ul><li>The <a href=\"/wiki/European_Commission\" title=\"European Commission\">European Commission</a> has a High-Level Expert Group on Artificial Intelligence. On 8 April 2019, this published its \"Ethics Guidelines for Trustworthy Artificial Intelligence\".<sup class=\"reference\" id=\"cite_ref-104\"><a href=\"#cite_note-104\">[104]</a></sup> The European Commission also has a Robotics and Artificial Intelligence Innovation and Excellence unit, which published a white paper on excellence and trust in artificial intelligence innovation on 19 February 2020.<sup class=\"reference\" id=\"cite_ref-105\"><a href=\"#cite_note-105\">[105]</a></sup></li>\n<li>The <a href=\"/wiki/OECD\" title=\"OECD\">OECD</a> established an OECD AI Policy Observatory.<sup class=\"reference\" id=\"cite_ref-106\"><a href=\"#cite_note-106\">[106]</a></sup></li></ul>\n<h3><span class=\"mw-headline\" id=\"Governmental_initiatives\">Governmental initiatives</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=16\" title=\"Edit section: Governmental initiatives\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<ul><li>In the <a href=\"/wiki/United_States\" title=\"United States\">United States</a> the <a class=\"mw-redirect\" href=\"/wiki/Obama\" title=\"Obama\">Obama</a> administration put together a Roadmap for AI Policy.<sup class=\"reference\" id=\"cite_ref-107\"><a href=\"#cite_note-107\">[107]</a></sup> The Obama Administration released two prominent <a class=\"mw-redirect\" href=\"/wiki/White_papers\" title=\"White papers\">white papers</a> on the future and impact of AI. In 2019 the White House through an executive memo known as the \"American AI Initiative\" instructed NIST the (National Institute of Standards and Technology) to begin work on Federal Engagement of AI Standards (February 2019).<sup class=\"reference\" id=\"cite_ref-108\"><a href=\"#cite_note-108\">[108]</a></sup></li>\n<li>In January 2020, in the United States, the <a class=\"mw-redirect\" href=\"/wiki/Trump_administration\" title=\"Trump administration\">Trump Administration</a> released a draft executive order issued by the Office of Management and Budget (OMB) on \"Guidance for Regulation of Artificial Intelligence Applications\" (\"OMB AI Memorandum\"). The order emphasizes the need to invest in AI applications, boost public trust in AI, reduce barriers for usage of AI, and keep American AI technology competitive in a global market. There is a nod to the need for privacy concerns, but no further detail on enforcement. The advances of American AI technology seems to be the focus and priority. Additionally, federal entities are even encouraged to use the order to circumnavigate any state laws and regulations that a market might see as too onerous to fulfill.<sup class=\"reference\" id=\"cite_ref-109\"><a href=\"#cite_note-109\">[109]</a></sup></li>\n<li>The <a href=\"/wiki/Computing_Community_Consortium\" title=\"Computing Community Consortium\">Computing Community Consortium (CCC)</a> weighed in with a 100-plus page draft report<sup class=\"reference\" id=\"cite_ref-110\"><a href=\"#cite_note-110\">[110]</a></sup> – <i>A 20-Year Community Roadmap for Artificial Intelligence Research in the US</i><sup class=\"reference\" id=\"cite_ref-111\"><a href=\"#cite_note-111\">[111]</a></sup></li>\n<li>The <a href=\"/wiki/Center_for_Security_and_Emerging_Technology\" title=\"Center for Security and Emerging Technology\">Center for Security and Emerging Technology</a> advises US policymakers on the security implications of emerging technologies such as AI.</li>\n<li>The <a class=\"new\" href=\"/w/index.php?title=Non-Human_Party&amp;action=edit&amp;redlink=1\" title=\"Non-Human Party (page does not exist)\">Non-Human Party</a> is running for election in <a href=\"/wiki/New_South_Wales\" title=\"New South Wales\">New South Wales</a>, with policies around granting rights to robots, animals and generally, non-human entities whose intelligence has been overlooked.<sup class=\"reference\" id=\"cite_ref-112\"><a href=\"#cite_note-112\">[112]</a></sup></li>\n<li>In Russia, the first-ever Russian \"Codex of ethics of artificial intelligence\" for business was signed in 2021. It was driven by <a href=\"/wiki/Analytical_Center_for_the_Government_of_the_Russian_Federation\" title=\"Analytical Center for the Government of the Russian Federation\">Analytical Center for the Government of the Russian Federation</a> together with major commercial and academic institutions such as <a href=\"/wiki/Sberbank\" title=\"Sberbank\">Sberbank</a>, <a href=\"/wiki/Yandex\" title=\"Yandex\">Yandex</a>, <a href=\"/wiki/Rosatom\" title=\"Rosatom\">Rosatom</a>, <a href=\"/wiki/Higher_School_of_Economics\" title=\"Higher School of Economics\">Higher School of Economics</a>, <a href=\"/wiki/Moscow_Institute_of_Physics_and_Technology\" title=\"Moscow Institute of Physics and Technology\">Moscow Institute of Physics and Technology</a>, <a href=\"/wiki/ITMO_University\" title=\"ITMO University\">ITMO University</a>, <a href=\"/wiki/Nanosemantics\" title=\"Nanosemantics\">Nanosemantics</a>, <a href=\"/wiki/Rostelecom\" title=\"Rostelecom\">Rostelecom</a>, <a class=\"mw-redirect\" href=\"/wiki/CIAN\" title=\"CIAN\">CIAN</a> and others.<sup class=\"reference\" id=\"cite_ref-113\"><a href=\"#cite_note-113\">[113]</a></sup></li></ul>\n<h3><span class=\"mw-headline\" id=\"Academic_initiatives\">Academic initiatives</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=17\" title=\"Edit section: Academic initiatives\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<ul><li>There are three research institutes at the <a href=\"/wiki/University_of_Oxford\" title=\"University of Oxford\">University of Oxford</a> that are centrally focused on AI ethics. The <a href=\"/wiki/Future_of_Humanity_Institute\" title=\"Future of Humanity Institute\">Future of Humanity Institute</a> that focuses both on AI Safety<sup class=\"reference\" id=\"cite_ref-114\"><a href=\"#cite_note-114\">[114]</a></sup> and the Governance of AI.<sup class=\"reference\" id=\"cite_ref-115\"><a href=\"#cite_note-115\">[115]</a></sup> The Institute for Ethics in AI, directed by <a href=\"/wiki/John_Tasioulas\" title=\"John Tasioulas\">John Tasioulas</a>, whose primary goal, among others, is to promote AI ethics as a field proper in comparison to related applied ethics fields. The <a href=\"/wiki/Oxford_Internet_Institute\" title=\"Oxford Internet Institute\">Oxford Internet Institute</a>, directed by <a href=\"/wiki/Luciano_Floridi\" title=\"Luciano Floridi\">Luciano Floridi</a>, focuses on the ethics of near-term AI technologies and ICTs.<sup class=\"reference\" id=\"cite_ref-116\"><a href=\"#cite_note-116\">[116]</a></sup></li>\n<li>The <a href=\"/wiki/AI_Now_Institute\" title=\"AI Now Institute\">AI Now Institute</a> at <a class=\"mw-redirect\" href=\"/wiki/NYU\" title=\"NYU\">NYU</a> is a research institute studying the social implications of artificial intelligence. Its interdisciplinary research focuses on the themes bias and inclusion, labour and automation, rights and liberties, and safety and civil infrastructure.<sup class=\"reference\" id=\"cite_ref-117\"><a href=\"#cite_note-117\">[117]</a></sup></li>\n<li>The <a href=\"/wiki/Institute_for_Ethics_and_Emerging_Technologies\" title=\"Institute for Ethics and Emerging Technologies\">Institute for Ethics and Emerging Technologies</a> (IEET) researches the effects of AI on unemployment,<sup class=\"reference\" id=\"cite_ref-118\"><a href=\"#cite_note-118\">[118]</a></sup><sup class=\"reference\" id=\"cite_ref-119\"><a href=\"#cite_note-119\">[119]</a></sup> and policy.</li>\n<li>The <a class=\"mw-redirect\" href=\"/wiki/Institute_for_Ethics_in_Artificial_Intelligence\" title=\"Institute for Ethics in Artificial Intelligence\">Institute for Ethics in Artificial Intelligence</a> (IEAI) at the <a href=\"/wiki/Technical_University_of_Munich\" title=\"Technical University of Munich\">Technical University of Munich</a> directed by <a href=\"/wiki/Christoph_L%C3%BCtge\" title=\"Christoph Lütge\">Christoph Lütge</a> conducts research across various domains such as mobility, employment, healthcare and sustainability.<sup class=\"reference\" id=\"cite_ref-120\"><a href=\"#cite_note-120\">[120]</a></sup></li></ul>\n<h3><span class=\"mw-headline\" id=\"Private_organizations\">Private organizations</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=18\" title=\"Edit section: Private organizations\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<ul><li><a href=\"/wiki/Algorithmic_Justice_League\" title=\"Algorithmic Justice League\">Algorithmic Justice League</a><sup class=\"reference\" id=\"cite_ref-121\"><a href=\"#cite_note-121\">[121]</a></sup></li>\n<li><a href=\"/wiki/Black_in_AI\" title=\"Black in AI\">Black in AI</a><sup class=\"reference\" id=\"cite_ref-:1_122-0\"><a href=\"#cite_note-:1-122\">[122]</a></sup></li>\n<li><a href=\"/wiki/Data_for_Black_Lives\" title=\"Data for Black Lives\">Data for Black Lives</a><sup class=\"reference\" id=\"cite_ref-123\"><a href=\"#cite_note-123\">[123]</a></sup></li>\n<li>Queer in AI<sup class=\"reference\" id=\"cite_ref-:1_122-1\"><a href=\"#cite_note-:1-122\">[122]</a></sup></li></ul>\n<h2><span class=\"mw-headline\" id=\"Role_and_impact_of_fiction\">Role and impact of fiction</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=19\" title=\"Edit section: Role and impact of fiction\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<link href=\"mw-data:TemplateStyles:r1033289096\" rel=\"mw-deduplicated-inline-style\"/><div class=\"hatnote navigation-not-searchable\" role=\"note\">Main article: <a href=\"/wiki/Artificial_intelligence_in_fiction\" title=\"Artificial intelligence in fiction\">Artificial intelligence in fiction</a></div>\n<p>The role of fiction with regards to AI ethics has been a complex one. One can distinguish three levels at which fiction has impacted the development of artificial intelligence and robotics: Historically, fiction has been prefiguring common tropes that have not only influenced goals and visions for AI, but also outlined ethical questions and common fears associated with it. During the second half of the twentieth and the first decades of the twenty-first century, popular culture, in particular movies, TV series and video games have frequently echoed preoccupations and dystopian projections around ethical questions concerning AI and robotics. Recently, these themes have also been increasingly treated in literature beyond the realm of science fiction. And, as Carme Torras, research professor at the <i>Institut de Robòtica i Informàtica Industrial</i> (Institute of robotics and industrial computing) at the Technical University of Catalonia notes,<sup class=\"reference\" id=\"cite_ref-124\"><a href=\"#cite_note-124\">[124]</a></sup> in higher education, science fiction is also increasingly used for teaching technology-related ethical issues in technological degrees.\n</p>\n<h3><span class=\"mw-headline\" id=\"History\">History</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=20\" title=\"Edit section: History\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>Historically speaking, the investigation of moral and ethical implications of \"thinking machines\" goes back at least to the Enlightenment: <a href=\"/wiki/Gottfried_Wilhelm_Leibniz\" title=\"Gottfried Wilhelm Leibniz\">Leibniz</a> already poses the question if we might attribute intelligence to a mechanism that behaves as if it were a sentient being,<sup class=\"reference\" id=\"cite_ref-125\"><a href=\"#cite_note-125\">[125]</a></sup> and so does <a href=\"/wiki/Ren%C3%A9_Descartes\" title=\"René Descartes\">Descartes</a>, who describes what could be considered an early version of the Turing Test.<sup class=\"reference\" id=\"cite_ref-126\"><a href=\"#cite_note-126\">[126]</a></sup>\n</p><p>The romantic period has several times envisioned artificial creatures that escape the control of their creator with dire consequences, most famously in <a href=\"/wiki/Mary_Shelley\" title=\"Mary Shelley\">Mary Shelley</a>'s <i><a href=\"/wiki/Frankenstein\" title=\"Frankenstein\">Frankenstein</a></i>. The widespread preoccupation with industrialization and mechanization in the 19th and early 20th century, however, brought ethical implications of unhinged technical developments to the forefront of fiction: <a href=\"/wiki/R.U.R.\" title=\"R.U.R.\"><i>R.U.R – Rossum's Universal Robots</i></a>, Karel Čapek's play of sentient robots endowed with emotions used as slave labor is not only credited with the invention of the term 'robot' (derived from the Czech word for forced labor, <i>robota</i>) but was also an international success after it premiered in 1921. George Bernard Shaw's play <i><a href=\"/wiki/Back_to_Methuselah\" title=\"Back to Methuselah\">Back to Methuselah</a></i>, published in 1921, questions at one point the validity of thinking machines that act like humans; Fritz Lang's 1927 film <a href=\"/wiki/Metropolis_(1927_film)\" title=\"Metropolis (1927 film)\"><i>Metropolis</i></a> shows an android leading the uprising of the exploited masses against the oppressive regime of a technocratic society.\n</p>\n<h3><span class=\"mw-headline\" id=\"Impact_on_technological_development\">Impact on technological development</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=21\" title=\"Edit section: Impact on technological development\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>While the anticipation of a future dominated by potentially indomitable technology has fueled the imagination of writers and film makers for a long time, one question has been less frequently analyzed, namely, to what extent fiction has played a role in providing inspiration for technological development. It has been documented, for instance, that the young Alan Turing saw and appreciated G.B. Shaw's play <i>Back to Methuselah</i> in 1933<sup class=\"reference\" id=\"cite_ref-127\"><a href=\"#cite_note-127\">[127]</a></sup> (just 3 years before the publication of his first seminal paper<sup class=\"reference\" id=\"cite_ref-128\"><a href=\"#cite_note-128\">[128]</a></sup> which laid the groundwork for the digital computer), and he would likely have been at least aware of plays like <i>R.U.R.</i>, which was an international success and translated into many languages.\n</p><p>One might also ask the question which role science fiction played in establishing the tenets and ethical implications of AI development: Isaac Asimov conceptualized his <a href=\"/wiki/Three_Laws_of_Robotics\" title=\"Three Laws of Robotics\">Three Laws of Robotics</a> in the 1942 short story  \"<a href=\"/wiki/Runaround_(story)\" title=\"Runaround (story)\">Runaround</a>\", part of the short story collection  <i><a href=\"/wiki/I,_Robot\" title=\"I, Robot\">I, Robot</a></i>; Arthur C. Clarke's short \"<a href=\"/wiki/The_Sentinel_(short_story)\" title=\"The Sentinel (short story)\">The Sentinel</a>\", on which Stanley Kubrick's film <a href=\"/wiki/2001:_A_Space_Odyssey_(film)\" title=\"2001: A Space Odyssey (film)\"><i>2001: A Space Odyssey</i></a>  is based, was written in 1948 and published in 1952. Another example (among many others) would be Philip K. Dicks numerous short stories and novels – in particular <i><a href=\"/wiki/Do_Androids_Dream_of_Electric_Sheep%3F\" title=\"Do Androids Dream of Electric Sheep?\">Do Androids Dream of Electric Sheep?</a></i>, published in 1968, and featuring its own version of a Turing Test, the <a href=\"/wiki/Blade_Runner#Voight-Kampff_machine\" title=\"Blade Runner\"><i>Voight-Kampff Test</i></a>, to gauge emotional responses of androids indistinguishable from humans. The novel later became the basis of the influential 1982 movie <i><a href=\"/wiki/Blade_Runner\" title=\"Blade Runner\">Blade Runner</a></i> by Ridley Scott.\n</p><p>Science fiction has been grappling with ethical implications of AI developments for decades, and thus provided a blueprint for ethical issues that might emerge once something akin to general artificial intelligence has been achieved: Spike Jonze's 2013 film <a href=\"/wiki/Her_(film)\" title=\"Her (film)\"><i>Her</i></a> shows what can happen if a user falls in love with the seductive voice of his smartphone operating system; <a href=\"/wiki/Ex_Machina_(film)\" title=\"Ex Machina (film)\"><i>Ex Machina</i></a>, on the other hand, asks a more difficult question: if confronted with a clearly recognizable machine, made only human by a face and an empathetic and sensual voice, would we still be able to establish an emotional connection, still be seduced by it?  (The film echoes a theme already present two centuries earlier, in the 1817 short story \"<a href=\"/wiki/The_Sandman_(short_story)\" title=\"The Sandman (short story)\">The Sandmann</a>\" by <a href=\"/wiki/E._T._A._Hoffmann\" title=\"E. T. A. Hoffmann\">E.T.A. Hoffmann.</a>)\n</p><p>The theme of coexistence with artificial sentient beings is also the theme of two recent novels: <a href=\"/wiki/Machines_Like_Me\" title=\"Machines Like Me\"><i>Machines like me</i></a> by <a href=\"/wiki/Ian_McEwan\" title=\"Ian McEwan\">Ian McEwan</a>, published in 2019, involves (among many other things) a love-triangle involving an artificial person as well as a human couple. <i><a href=\"/wiki/Klara_and_the_Sun\" title=\"Klara and the Sun\">Klara and the Sun</a></i> by <a href=\"/wiki/Nobel_Prize_in_Literature\" title=\"Nobel Prize in Literature\">Nobel Prize</a> winner <a href=\"/wiki/Kazuo_Ishiguro\" title=\"Kazuo Ishiguro\">Kazuo Ishiguro</a>, published in 2021, is the first-person account of Klara, an 'AF' (artificial friend), who is trying, in her own way, to help the girl she is living with, who, after having been 'lifted' (i.e. having been subjected to genetic enhancements), is suffering from a strange illness.\n</p>\n<h3><span class=\"mw-headline\" id=\"TV_series\">TV series</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=22\" title=\"Edit section: TV series\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>While ethical questions linked to AI have been featured in science fiction literature and <a href=\"/wiki/List_of_artificial_intelligence_films\" title=\"List of artificial intelligence films\">feature films</a> for decades, the emergence of the TV series as a genre allowing for longer and more complex story lines and character development has led to some significant contributions that deal with ethical implications of technology. The Swedish series <i><a href=\"/wiki/Real_Humans\" title=\"Real Humans\">Real Humans</a></i> (2012–2013) tackled the complex ethical and social consequences linked to the integration of artificial sentient beings in society. The British dystopian science fiction anthology series <i><a href=\"/wiki/Black_Mirror\" title=\"Black Mirror\">Black Mirror</a></i> (2013–2019) was particularly notable for experimenting with dystopian fictional developments linked to a wide variety of recent technology developments. Both the French series <a href=\"/wiki/Osmosis_(TV_series)\" title=\"Osmosis (TV series)\"><i>Osmosis</i></a> (2020) and British series <a href=\"/wiki/The_One_(TV_series)\" title=\"The One (TV series)\"><i>The One</i></a> deal with the question of what can happen if technology tries to find the ideal partner for a person. Several episodes of the Netflix series <a href=\"/wiki/Love,_Death_%26_Robots\" title=\"Love, Death &amp; Robots\"><i>Love, Death+Robots</i></a> have imagined scenes of robots and humans living together. The most representative one of them is S02 E01, it shows how bad the consequences can be when robots get out of control if humans rely too much on them in their lives.<sup class=\"reference\" id=\"cite_ref-129\"><a href=\"#cite_note-129\">[129]</a></sup>\n</p>\n<h3><span class=\"mw-headline\" id=\"Future_visions_in_fiction_and_games\">Future visions in fiction and games</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=23\" title=\"Edit section: Future visions in fiction and games\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h3>\n<p>The movie <i><a href=\"/wiki/The_Thirteenth_Floor\" title=\"The Thirteenth Floor\">The Thirteenth Floor</a></i> suggests a future where <a href=\"/wiki/Simulated_reality\" title=\"Simulated reality\">simulated worlds</a> with sentient inhabitants are created by computer <a class=\"mw-redirect\" href=\"/wiki/Game_console\" title=\"Game console\">game consoles</a> for the purpose of entertainment. The movie <i><a href=\"/wiki/The_Matrix\" title=\"The Matrix\">The Matrix</a></i> suggests a future where the dominant species on planet Earth are sentient machines and humanity is treated with utmost <a href=\"/wiki/Speciesism\" title=\"Speciesism\">speciesism</a>. The short story \"<a href=\"/wiki/The_Planck_Dive\" title=\"The Planck Dive\">The Planck Dive</a>\" suggests a future where humanity has turned itself into software that can be duplicated and optimized and the relevant distinction between types of software is sentient and non-sentient. The same idea can be found in the <a class=\"mw-redirect\" href=\"/wiki/Emergency_Medical_Hologram\" title=\"Emergency Medical Hologram\">Emergency Medical Hologram</a> of <i><a class=\"mw-redirect\" href=\"/wiki/USS_Voyager_(NCC-74656)\" title=\"USS Voyager (NCC-74656)\">Starship Voyager</a></i>, which is an apparently sentient copy of a reduced subset of the consciousness of its creator, <a class=\"mw-redirect\" href=\"/wiki/Lewis_Zimmerman\" title=\"Lewis Zimmerman\">Dr. Zimmerman</a>, who, for the best motives, has created the system to give medical assistance in case of emergencies. The movies <i><a href=\"/wiki/Bicentennial_Man_(film)\" title=\"Bicentennial Man (film)\">Bicentennial Man</a></i> and <i><a href=\"/wiki/A.I._Artificial_Intelligence\" title=\"A.I. Artificial Intelligence\">A.I.</a></i> deal with the possibility of sentient robots that could love. <i><a href=\"/wiki/I,_Robot_(film)\" title=\"I, Robot (film)\">I, Robot</a></i> explored some aspects of Asimov's three laws. All these scenarios try to foresee possibly unethical consequences of the creation of sentient computers.<sup class=\"reference\" id=\"cite_ref-130\"><a href=\"#cite_note-130\">[130]</a></sup>\n</p><p>The ethics of artificial intelligence is one of several core themes in BioWare's <a href=\"/wiki/Mass_Effect\" title=\"Mass Effect\">Mass Effect</a> series of games.<sup class=\"reference\" id=\"cite_ref-131\"><a href=\"#cite_note-131\">[131]</a></sup> It explores the scenario of a civilization accidentally creating AI through a rapid increase in computational power through a global scale <a href=\"/wiki/Neural_network\" title=\"Neural network\">neural network</a>. This event caused an ethical schism between those who felt bestowing organic rights upon the newly sentient Geth was appropriate and those who continued to see them as disposable machinery and fought to destroy them. Beyond the initial conflict, the complexity of the relationship between the machines and their creators is another ongoing theme throughout the story.\n</p><p><i><a href=\"/wiki/Detroit:_Become_Human\" title=\"Detroit: Become Human\">Detroit: Become Human</a></i> is one of the most famous video games which discusses the ethics of artificial intelligence recently. Quantic Dream designed the chapters of the game using interactive storylines to give players a more immersive gaming experience. Players manipulate three different awakened bionic men in the face of different events to make different choices to achieve the purpose of changing the human view of the bionic group and different choices will result in different endings. This is one of the few games that puts players in the bionic perspective, which allows them to better consider the rights and interests of robots once a true artificial intelligence is created.<sup class=\"reference\" id=\"cite_ref-132\"><a href=\"#cite_note-132\">[132]</a></sup>\n</p><p>Over time, debates have tended to focus less and less on <i>possibility</i> and more on <i>desirability</i>,<sup class=\"reference\" id=\"cite_ref-133\"><a href=\"#cite_note-133\">[133]</a></sup> as emphasized in the <a href=\"/wiki/Hugo_de_Garis#The_Artilect_War\" title=\"Hugo de Garis\">\"Cosmist\" and \"Terran\" debates</a> initiated by <a href=\"/wiki/Hugo_de_Garis\" title=\"Hugo de Garis\">Hugo de Garis</a> and <a href=\"/wiki/Kevin_Warwick\" title=\"Kevin Warwick\">Kevin Warwick</a>. A Cosmist, according to Hugo de Garis, is actually seeking to build more intelligent successors to the human species.\n</p><p>Experts at the University of Cambridge have argued that AI is portrayed in fiction and nonfiction overwhelmingly as racially White, in ways that distort perceptions of its risks and benefits.<sup class=\"reference\" id=\"cite_ref-134\"><a href=\"#cite_note-134\">[134]</a></sup>\n</p>\n<h2><span class=\"mw-headline\" id=\"See_also\">See also</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=24\" title=\"Edit section: See also\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<style data-mw-deduplicate=\"TemplateStyles:r998391716\">.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}</style><div class=\"div-col\" style=\"column-width: 30em;\">\n<ul><li><a href=\"/wiki/AI_takeover\" title=\"AI takeover\">AI takeover</a></li>\n<li><a href=\"/wiki/Artificial_consciousness\" title=\"Artificial consciousness\">Artificial consciousness</a></li>\n<li><a href=\"/wiki/Artificial_general_intelligence\" title=\"Artificial general intelligence\">Artificial general intelligence</a> (AGI)</li>\n<li><a href=\"/wiki/Computer_ethics\" title=\"Computer ethics\">Computer ethics</a></li>\n<li><a href=\"/wiki/Effective_altruism#Long-term_future_and_global_catastrophic_risks\" title=\"Effective altruism\">Effective altruism, the long term future and global catastrophic risks</a></li>\n<li><a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">Existential risk from artificial general intelligence</a></li>\n<li><i><a href=\"/wiki/Human_Compatible\" title=\"Human Compatible\">Human Compatible</a></i></li>\n<li><a href=\"/wiki/Philosophy_of_artificial_intelligence\" title=\"Philosophy of artificial intelligence\">Philosophy of artificial intelligence</a></li>\n<li><a href=\"/wiki/Regulation_of_artificial_intelligence\" title=\"Regulation of artificial intelligence\">Regulation of artificial intelligence</a></li>\n<li><a href=\"/wiki/Robotic_governance\" title=\"Robotic governance\">Robotic Governance</a></li>\n<li><i><a href=\"/wiki/Superintelligence:_Paths,_Dangers,_Strategies\" title=\"Superintelligence: Paths, Dangers, Strategies\">Superintelligence: Paths, Dangers, Strategies</a></i></li></ul>\n<dl><dt>Researchers</dt></dl>\n<ul><li><a href=\"/wiki/Timnit_Gebru\" title=\"Timnit Gebru\">Timnit Gebru</a></li>\n<li><a href=\"/wiki/Joy_Buolamwini\" title=\"Joy Buolamwini\">Joy Buolamwini</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Deb_Raji\" title=\"Deb Raji\">Deb Raji</a></li>\n<li><a href=\"/wiki/Ruha_Benjamin\" title=\"Ruha Benjamin\">Ruha Benjamin</a></li>\n<li><a href=\"/wiki/Safiya_Noble\" title=\"Safiya Noble\">Safiya Noble</a></li>\n<li><a href=\"/wiki/Margaret_Mitchell_(scientist)\" title=\"Margaret Mitchell (scientist)\">Margaret Mitchell</a></li>\n<li><a href=\"/wiki/Meredith_Whittaker\" title=\"Meredith Whittaker\">Meredith Whittaker</a></li>\n<li><a href=\"/wiki/Alison_Adam\" title=\"Alison Adam\">Alison Adam</a></li>\n<li><a href=\"/wiki/Seth_Baum\" title=\"Seth Baum\">Seth Baum</a></li>\n<li><a href=\"/wiki/Nick_Bostrom\" title=\"Nick Bostrom\">Nick Bostrom</a></li>\n<li><a href=\"/wiki/Joanna_Bryson\" title=\"Joanna Bryson\">Joanna Bryson</a></li>\n<li><a href=\"/wiki/Kate_Crawford\" title=\"Kate Crawford\">Kate Crawford</a></li>\n<li><a href=\"/wiki/Kate_Darling\" title=\"Kate Darling\">Kate Darling</a></li>\n<li><a href=\"/wiki/Luciano_Floridi\" title=\"Luciano Floridi\">Luciano Floridi</a></li>\n<li><a href=\"/wiki/Anja_Kaspersen\" title=\"Anja Kaspersen\">Anja Kaspersen</a></li>\n<li><a href=\"/wiki/Michael_Kearns_(computer_scientist)\" title=\"Michael Kearns (computer scientist)\">Michael Kearns</a></li>\n<li><a href=\"/wiki/Ray_Kurzweil\" title=\"Ray Kurzweil\">Ray Kurzweil</a></li>\n<li><a href=\"/wiki/Catherine_Malabou\" title=\"Catherine Malabou\">Catherine Malabou</a></li>\n<li><a href=\"/wiki/Ajung_Moon\" title=\"Ajung Moon\">Ajung Moon</a></li>\n<li><a href=\"/wiki/Vincent_C._M%C3%BCller\" title=\"Vincent C. Müller\">Vincent C. Müller</a></li>\n<li><a href=\"/wiki/Peter_Norvig\" title=\"Peter Norvig\">Peter Norvig</a></li>\n<li><a href=\"/wiki/Steve_Omohundro\" title=\"Steve Omohundro\">Steve Omohundro</a></li>\n<li><a href=\"/wiki/Stuart_J._Russell\" title=\"Stuart J. Russell\">Stuart J. Russell</a></li>\n<li><a href=\"/wiki/Anders_Sandberg\" title=\"Anders Sandberg\">Anders Sandberg</a></li>\n<li><a href=\"/wiki/Mariarosaria_Taddeo\" title=\"Mariarosaria Taddeo\">Mariarosaria Taddeo</a></li>\n<li><a href=\"/wiki/John_Tasioulas\" title=\"John Tasioulas\">John Tasioulas</a></li>\n<li><a href=\"/wiki/Roman_Yampolskiy\" title=\"Roman Yampolskiy\">Roman Yampolskiy</a></li>\n<li><a href=\"/wiki/Eliezer_Yudkowsky\" title=\"Eliezer Yudkowsky\">Eliezer Yudkowsky</a></li>\n<li><a href=\"/wiki/Emily_M._Bender\" title=\"Emily M. Bender\">Emily M. Bender</a></li></ul>\n<dl><dt>Organisations</dt></dl>\n<ul><li><a href=\"/wiki/Center_for_Human-Compatible_Artificial_Intelligence\" title=\"Center for Human-Compatible Artificial Intelligence\">Center for Human-Compatible Artificial Intelligence</a></li>\n<li><a href=\"/wiki/Center_for_Security_and_Emerging_Technology\" title=\"Center for Security and Emerging Technology\">Center for Security and Emerging Technology</a></li>\n<li><a href=\"/wiki/Centre_for_the_Study_of_Existential_Risk\" title=\"Centre for the Study of Existential Risk\">Centre for the Study of Existential Risk</a></li>\n<li><a href=\"/wiki/Future_of_Humanity_Institute\" title=\"Future of Humanity Institute\">Future of Humanity Institute</a></li>\n<li><a href=\"/wiki/Future_of_Life_Institute\" title=\"Future of Life Institute\">Future of Life Institute</a></li>\n<li><a href=\"/wiki/Machine_Intelligence_Research_Institute\" title=\"Machine Intelligence Research Institute\">Machine Intelligence Research Institute</a></li>\n<li><a href=\"/wiki/Partnership_on_AI\" title=\"Partnership on AI\">Partnership on AI</a></li>\n<li><a href=\"/wiki/Leverhulme_Centre_for_the_Future_of_Intelligence\" title=\"Leverhulme Centre for the Future of Intelligence\">Leverhulme Centre for the Future of Intelligence</a></li>\n<li><a href=\"/wiki/Institute_for_Ethics_and_Emerging_Technologies\" title=\"Institute for Ethics and Emerging Technologies\">Institute for Ethics and Emerging Technologies</a></li>\n<li><a href=\"/wiki/Oxford_Internet_Institute\" title=\"Oxford Internet Institute\">Oxford Internet Institute</a></li></ul></div>\n<h2><span class=\"mw-headline\" id=\"Notes\">Notes</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=25\" title=\"Edit section: Notes\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<style data-mw-deduplicate=\"TemplateStyles:r1011085734\">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style><div class=\"reflist\">\n<div class=\"mw-references-wrap mw-references-columns\"><ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\"><style data-mw-deduplicate=\"TemplateStyles:r1067248974\">.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#3a3;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style><cite class=\"citation web cs1\" id=\"CITEREFMüller2020\">Müller, Vincent C. (30 April 2020). <a class=\"external text\" href=\"https://plato.stanford.edu/entries/ethics-ai/\" rel=\"nofollow\">\"Ethics of Artificial Intelligence and Robotics\"</a>. <i>Stanford Encyclopedia of Philosophy</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20201010174108/https://plato.stanford.edu/entries/ethics-ai/\" rel=\"nofollow\">Archived</a> from the original on 10 October 2020<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">26 September</span> 2020</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Stanford+Encyclopedia+of+Philosophy&amp;rft.atitle=Ethics+of+Artificial+Intelligence+and+Robotics&amp;rft.date=2020-04-30&amp;rft.aulast=M%C3%BCller&amp;rft.aufirst=Vincent+C.&amp;rft_id=https%3A%2F%2Fplato.stanford.edu%2Fentries%2Fethics-ai%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-Veruggio2002-2\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Veruggio2002_2-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFVeruggio,_Gianmarco2011\">Veruggio, Gianmarco (2011). \"The Roboethics Roadmap\". <i>EURON Roboethics Atelier</i>. Scuola di Robotica: 2. <a class=\"mw-redirect\" href=\"/wiki/CiteSeerX_(identifier)\" title=\"CiteSeerX (identifier)\">CiteSeerX</a> <span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.466.2810\" rel=\"nofollow\">10.1.1.466.2810</a></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=EURON+Roboethics+Atelier&amp;rft.atitle=The+Roboethics+Roadmap&amp;rft.pages=2&amp;rft.date=2011&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.466.2810%23id-name%3DCiteSeerX&amp;rft.au=Veruggio%2C+Gianmarco&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-3\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-3\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation cs2\" id=\"CITEREFMüller2020\">Müller, Vincent C. (2020), <a class=\"external text\" href=\"https://plato.stanford.edu/archives/win2020/entries/ethics-ai/\" rel=\"nofollow\">\"Ethics of Artificial Intelligence and Robotics\"</a>,  in Zalta, Edward N. (ed.), <i>The Stanford Encyclopedia of Philosophy</i> (Winter 2020 ed.), Metaphysics Research Lab, Stanford University<span class=\"reference-accessdate\">, retrieved <span class=\"nowrap\">2021-03-18</span></span></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Ethics+of+Artificial+Intelligence+and+Robotics&amp;rft.btitle=The+Stanford+Encyclopedia+of+Philosophy&amp;rft.edition=Winter+2020&amp;rft.pub=Metaphysics+Research+Lab%2C+Stanford+University&amp;rft.date=2020&amp;rft.aulast=M%C3%BCller&amp;rft.aufirst=Vincent+C.&amp;rft_id=https%3A%2F%2Fplato.stanford.edu%2Farchives%2Fwin2020%2Fentries%2Fethics-ai%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-Andersonweb-4\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Andersonweb_4-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFAnderson\">Anderson. <a class=\"external text\" href=\"http://uhaweb.hartford.edu/anderson/MachineEthics.html\" rel=\"nofollow\">\"Machine Ethics\"</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20110928233656/http://uhaweb.hartford.edu/anderson/MachineEthics.html\" rel=\"nofollow\">Archived</a> from the original on 28 September 2011<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">27 June</span> 2011</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Machine+Ethics&amp;rft.au=Anderson&amp;rft_id=http%3A%2F%2Fuhaweb.hartford.edu%2Fanderson%2FMachineEthics.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-Anderson2011-5\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Anderson2011_5-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation book cs1\" id=\"CITEREFAndersonAnderson2011\">Anderson, Michael; Anderson, Susan Leigh, eds. (July 2011). <i>Machine Ethics</i>. <a href=\"/wiki/Cambridge_University_Press\" title=\"Cambridge University Press\">Cambridge University Press</a>. <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-521-11235-2\" title=\"Special:BookSources/978-0-521-11235-2\"><bdi>978-0-521-11235-2</bdi></a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Machine+Ethics&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2011-07&amp;rft.isbn=978-0-521-11235-2&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-Anderson2006-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Anderson2006_6-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFAndersonAnderson2006\">Anderson, M.; Anderson, S.L. (July 2006). \"Guest Editors' Introduction: Machine Ethics\". <i>IEEE Intelligent Systems</i>. <b>21</b> (4): 10–11. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1109%2Fmis.2006.70\" rel=\"nofollow\">10.1109/mis.2006.70</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:9570832\" rel=\"nofollow\">9570832</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Intelligent+Systems&amp;rft.atitle=Guest+Editors%27+Introduction%3A+Machine+Ethics&amp;rft.volume=21&amp;rft.issue=4&amp;rft.pages=10-11&amp;rft.date=2006-07&amp;rft_id=info%3Adoi%2F10.1109%2Fmis.2006.70&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A9570832%23id-name%3DS2CID&amp;rft.aulast=Anderson&amp;rft.aufirst=M.&amp;rft.au=Anderson%2C+S.L.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-Anderson2007-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Anderson2007_7-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFAndersonAnderson2007\">Anderson, Michael; Anderson, Susan Leigh (15 December 2007). \"Machine Ethics: Creating an Ethical Intelligent Agent\". <i>AI Magazine</i>. <b>28</b> (4): 15. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1609%2Faimag.v28i4.2065\" rel=\"nofollow\">10.1609/aimag.v28i4.2065</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:17033332\" rel=\"nofollow\">17033332</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=AI+Magazine&amp;rft.atitle=Machine+Ethics%3A+Creating+an+Ethical+Intelligent+Agent&amp;rft.volume=28&amp;rft.issue=4&amp;rft.pages=15&amp;rft.date=2007-12-15&amp;rft_id=info%3Adoi%2F10.1609%2Faimag.v28i4.2065&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A17033332%23id-name%3DS2CID&amp;rft.aulast=Anderson&amp;rft.aufirst=Michael&amp;rft.au=Anderson%2C+Susan+Leigh&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFBoyles2017\">Boyles, Robert James M. (2017). <a class=\"external text\" href=\"https://philarchive.org/rec/BOYPSF\" rel=\"nofollow\">\"Philosophical Signposts for Artificial Moral Agent Frameworks\"</a>. <i>Suri</i>. <b>6</b> (2): 92–109.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Suri&amp;rft.atitle=Philosophical+Signposts+for+Artificial+Moral+Agent+Frameworks&amp;rft.volume=6&amp;rft.issue=2&amp;rft.pages=92-109&amp;rft.date=2017&amp;rft.aulast=Boyles&amp;rft.aufirst=Robert+James+M.&amp;rft_id=https%3A%2F%2Fphilarchive.org%2Frec%2FBOYPSF&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-Asimov2008-9\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Asimov2008_9-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation book cs1\" id=\"CITEREFAsimov2008\">Asimov, Isaac (2008). <a href=\"/wiki/I,_Robot\" title=\"I, Robot\"><i>I, Robot</i></a>. New York: Bantam. <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-553-38256-3\" title=\"Special:BookSources/978-0-553-38256-3\"><bdi>978-0-553-38256-3</bdi></a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=I%2C+Robot&amp;rft.place=New+York&amp;rft.pub=Bantam&amp;rft.date=2008&amp;rft.isbn=978-0-553-38256-3&amp;rft.aulast=Asimov&amp;rft.aufirst=Isaac&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-lacuna-10\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-lacuna_10-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"lacuna\">Bryson, Joanna; Diamantis, Mihailis; Grant, Thomas (September 2017). <a class=\"external text\" href=\"https://doi.org/10.1007%2Fs10506-017-9214-9\" rel=\"nofollow\">\"Of, for, and by the people: the legal lacuna of synthetic persons\"</a>. <i>Artificial Intelligence and Law</i>. <b>25</b> (3): 273–291. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"https://doi.org/10.1007%2Fs10506-017-9214-9\" rel=\"nofollow\">10.1007/s10506-017-9214-9</a></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Artificial+Intelligence+and+Law&amp;rft.atitle=Of%2C+for%2C+and+by+the+people%3A+the+legal+lacuna+of+synthetic+persons&amp;rft.volume=25&amp;rft.issue=3&amp;rft.pages=273-291&amp;rft.date=2017-09&amp;rft_id=info%3Adoi%2F10.1007%2Fs10506-017-9214-9&amp;rft.aulast=Bryson&amp;rft.aufirst=Joanna&amp;rft.au=Diamantis%2C+Mihailis&amp;rft.au=Grant%2C+Thomas&amp;rft_id=%2F%2Fdoi.org%2F10.1007%252Fs10506-017-9214-9&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-principles-11\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-principles_11-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"principles\"><a class=\"external text\" href=\"https://epsrc.ukri.org/research/ourportfolio/themes/engineering/activities/principlesofrobotics/\" rel=\"nofollow\">\"Principles of robotics\"</a>. UK's EPSRC. September 2010. <a class=\"external text\" href=\"https://web.archive.org/web/20180401004346/https://www.epsrc.ac.uk/research/ourportfolio/themes/engineering/activities/principlesofrobotics/\" rel=\"nofollow\">Archived</a> from the original on 1 April 2018<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">10 January</span> 2019</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Principles+of+robotics&amp;rft.pub=UK%27s+EPSRC&amp;rft.date=2010-09&amp;rft_id=https%3A%2F%2Fepsrc.ukri.org%2Fresearch%2Fourportfolio%2Fthemes%2Fengineering%2Factivities%2Fprinciplesofrobotics%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-12\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-12\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://www.popsci.com/scitech/article/2009-08/evolving-robots-learn-lie-hide-resources-each-other\" rel=\"nofollow\">Evolving Robots Learn To Lie To Each Other</a> <a class=\"external text\" href=\"https://web.archive.org/web/20090828105728/http://www.popsci.com/scitech/article/2009-08/evolving-robots-learn-lie-hide-resources-each-other\" rel=\"nofollow\">Archived</a> 2009-08-28 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>, Popular Science, August 18, 2009</span>\n</li>\n<li id=\"cite_note-Call_for_debate_on_killer_robots-13\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Call_for_debate_on_killer_robots_13-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Call_for_debate_on_killer_robots_13-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://news.bbc.co.uk/2/hi/technology/8182003.stm\" rel=\"nofollow\">Call for debate on killer robots</a> <a class=\"external text\" href=\"https://web.archive.org/web/20090807005005/http://news.bbc.co.uk/2/hi/technology/8182003.stm\" rel=\"nofollow\">Archived</a> 2009-08-07 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>, By Jason Palmer, Science and technology reporter, BBC News, 8/3/09.</span>\n</li>\n<li id=\"cite_note-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-14\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://www.dailytech.com/New%20Navyfunded%20Report%20Warns%20of%20War%20Robots%20Going%20Terminator/article14298.htm\" rel=\"nofollow\">Science New Navy-funded Report Warns of War Robots Going \"Terminator\"</a> <a class=\"external text\" href=\"https://web.archive.org/web/20090728101106/http://www.dailytech.com/New%20Navyfunded%20Report%20Warns%20of%20War%20Robots%20Going%20Terminator/article14298.htm\" rel=\"nofollow\">Archived</a> 2009-07-28 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>, by Jason Mick (Blog), dailytech.com, February 17, 2009.</span>\n</li>\n<li id=\"cite_note-engadget.com-15\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-engadget.com_15-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-engadget.com_15-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><a class=\"external text\" href=\"https://www.engadget.com/2009/02/18/navy-report-warns-of-robot-uprising-suggests-a-strong-moral-com/\" rel=\"nofollow\">Navy report warns of robot uprising, suggests a strong moral compass</a> <a class=\"external text\" href=\"https://web.archive.org/web/20110604145633/http://www.engadget.com/2009/02/18/navy-report-warns-of-robot-uprising-suggests-a-strong-moral-com/\" rel=\"nofollow\">Archived</a> 2011-06-04 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>, by Joseph L. Flatley engadget.com, Feb 18th 2009.</span>\n</li>\n<li id=\"cite_note-16\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-16\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://research.microsoft.com/en-us/um/people/horvitz/AAAI_Presidential_Panel_2008-2009.htm\" rel=\"nofollow\">AAAI Presidential Panel on Long-Term AI Futures 2008–2009 Study</a> <a class=\"external text\" href=\"https://web.archive.org/web/20090828214741/http://research.microsoft.com/en-us/um/people/horvitz/AAAI_Presidential_Panel_2008-2009.htm\" rel=\"nofollow\">Archived</a> 2009-08-28 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>, Association for the Advancement of Artificial Intelligence, Accessed 7/26/09.</span>\n</li>\n<li id=\"cite_note-nytimes_july09-17\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-nytimes_july09_17-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-nytimes_july09_17-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation news cs1\" id=\"CITEREFMarkoff2009\">Markoff, John (25 July 2009). <a class=\"external text\" href=\"https://www.nytimes.com/2009/07/26/science/26robot.html\" rel=\"nofollow\">\"Scientists Worry Machines May Outsmart Man\"</a>. <i>The New York Times</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20170225202201/http://www.nytimes.com/2009/07/26/science/26robot.html\" rel=\"nofollow\">Archived</a> from the original on 25 February 2017<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">24 February</span> 2017</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=Scientists+Worry+Machines+May+Outsmart+Man&amp;rft.date=2009-07-25&amp;rft.aulast=Markoff&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2009%2F07%2F26%2Fscience%2F26robot.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-18\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-18\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html\" rel=\"nofollow\">The Coming Technological Singularity: How to Survive in the Post-Human Era</a> <a class=\"external text\" href=\"https://web.archive.org/web/20070101133646/http://www-rohan.sdsu.edu/faculty/vinge/misc/singularity.html\" rel=\"nofollow\">Archived</a> 2007-01-01 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>, by Vernor Vinge, Department of Mathematical Sciences, San Diego State University, (c) 1993 by Vernor Vinge.</span>\n</li>\n<li id=\"cite_note-19\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-19\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://www.asimovlaws.com/articles/archives/2004/07/why_we_need_fri_1.html\" rel=\"nofollow\">Article at Asimovlaws.com</a> <a class=\"external text\" href=\"https://web.archive.org/web/20120524150856/http://www.asimovlaws.com/articles/archives/2004/07/why_we_need_fri_1.html\" rel=\"nofollow\">Archived</a> May 24, 2012, at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>, July 2004, accessed 7/27/09.</span>\n</li>\n<li id=\"cite_note-:0-20\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:0_20-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:0_20-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFWinfieldMichaelPittEvers2019\">Winfield, A. F.; Michael, K.; Pitt, J.; Evers, V. (March 2019). <a class=\"external text\" href=\"https://ieeexplore.ieee.org/document/8662743\" rel=\"nofollow\">\"Machine Ethics: The Design and Governance of Ethical AI and Autonomous Systems [Scanning the Issue]\"</a>. <i>Proceedings of the IEEE</i>. <b>107</b> (3): 509–517. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1109%2FJPROC.2019.2900622\" rel=\"nofollow\">10.1109/JPROC.2019.2900622</a>. <a class=\"mw-redirect\" href=\"/wiki/ISSN_(identifier)\" title=\"ISSN (identifier)\">ISSN</a> <a class=\"external text\" href=\"//www.worldcat.org/issn/1558-2256\" rel=\"nofollow\">1558-2256</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:77393713\" rel=\"nofollow\">77393713</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20201102031635/https://ieeexplore.ieee.org/document/8662743\" rel=\"nofollow\">Archived</a> from the original on 2020-11-02<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2020-11-21</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+IEEE&amp;rft.atitle=Machine+Ethics%3A+The+Design+and+Governance+of+Ethical+AI+and+Autonomous+Systems+%5BScanning+the+Issue%5D&amp;rft.volume=107&amp;rft.issue=3&amp;rft.pages=509-517&amp;rft.date=2019-03&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A77393713%23id-name%3DS2CID&amp;rft.issn=1558-2256&amp;rft_id=info%3Adoi%2F10.1109%2FJPROC.2019.2900622&amp;rft.aulast=Winfield&amp;rft.aufirst=A.+F.&amp;rft.au=Michael%2C+K.&amp;rft.au=Pitt%2C+J.&amp;rft.au=Evers%2C+V.&amp;rft_id=https%3A%2F%2Fieeexplore.ieee.org%2Fdocument%2F8662743&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-21\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-21\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation news cs1\" id=\"CITEREFAl-Rodhan2015\">Al-Rodhan, Nayef (7 December 2015). <a class=\"external text\" href=\"https://www.foreignaffairs.com/articles/2015-08-12/moral-code\" rel=\"nofollow\">\"The Moral Code\"</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20170305044025/https://www.foreignaffairs.com/articles/2015-08-12/moral-code\" rel=\"nofollow\">Archived</a> from the original on 2017-03-05<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2017-03-04</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=The+Moral+Code&amp;rft.date=2015-12-07&amp;rft.aulast=Al-Rodhan&amp;rft.aufirst=Nayef&amp;rft_id=https%3A%2F%2Fwww.foreignaffairs.com%2Farticles%2F2015-08-12%2Fmoral-code&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-Wallach2008-22\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Wallach2008_22-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation book cs1\" id=\"CITEREFWallachAllen2008\">Wallach, Wendell; Allen, Colin (November 2008). <i>Moral Machines: Teaching Robots Right from Wrong</i>. USA: <a href=\"/wiki/Oxford_University_Press\" title=\"Oxford University Press\">Oxford University Press</a>. <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-19-537404-9\" title=\"Special:BookSources/978-0-19-537404-9\"><bdi>978-0-19-537404-9</bdi></a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Moral+Machines%3A+Teaching+Robots+Right+from+Wrong&amp;rft.place=USA&amp;rft.pub=Oxford+University+Press&amp;rft.date=2008-11&amp;rft.isbn=978-0-19-537404-9&amp;rft.aulast=Wallach&amp;rft.aufirst=Wendell&amp;rft.au=Allen%2C+Colin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-23\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-23\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFBostromYudkowsky2011\"><a href=\"/wiki/Nick_Bostrom\" title=\"Nick Bostrom\">Bostrom, Nick</a>; <a href=\"/wiki/Eliezer_Yudkowsky\" title=\"Eliezer Yudkowsky\">Yudkowsky, Eliezer</a> (2011). <a class=\"external text\" href=\"http://www.nickbostrom.com/ethics/artificial-intelligence.pdf\" rel=\"nofollow\">\"The Ethics of Artificial Intelligence\"</a> <span class=\"cs1-format\">(PDF)</span>. <i>Cambridge Handbook of Artificial Intelligence</i>. <a class=\"mw-redirect\" href=\"/wiki/Cambridge_Press\" title=\"Cambridge Press\">Cambridge Press</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20160304015020/http://www.nickbostrom.com/ethics/artificial-intelligence.pdf\" rel=\"nofollow\">Archived</a> <span class=\"cs1-format\">(PDF)</span> from the original on 2016-03-04<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2011-06-22</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Cambridge+Handbook+of+Artificial+Intelligence&amp;rft.atitle=The+Ethics+of+Artificial+Intelligence&amp;rft.date=2011&amp;rft.aulast=Bostrom&amp;rft.aufirst=Nick&amp;rft.au=Yudkowsky%2C+Eliezer&amp;rft_id=http%3A%2F%2Fwww.nickbostrom.com%2Fethics%2Fartificial-intelligence.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-SantosLang2002-24\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-SantosLang2002_24-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFSantos-Lang2002\">Santos-Lang, Chris (2002). <a class=\"external text\" href=\"http://santoslang.wordpress.com/article/ethics-for-artificial-intelligences-3iue30fi4gfq9-1\" rel=\"nofollow\">\"Ethics for Artificial Intelligences\"</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20141225093359/http://santoslang.wordpress.com/article/ethics-for-artificial-intelligences-3iue30fi4gfq9-1/\" rel=\"nofollow\">Archived</a> from the original on 2014-12-25<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2015-01-04</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Ethics+for+Artificial+Intelligences&amp;rft.date=2002&amp;rft.aulast=Santos-Lang&amp;rft.aufirst=Chris&amp;rft_id=http%3A%2F%2Fsantoslang.wordpress.com%2Farticle%2Fethics-for-artificial-intelligences-3iue30fi4gfq9-1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-25\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-25\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFHoward\">Howard, Ayanna. <a class=\"external text\" href=\"https://sloanreview.mit.edu/article/the-regulation-of-ai-should-organizations-be-worried/\" rel=\"nofollow\">\"The Regulation of AI – Should Organizations Be Worried? | Ayanna Howard\"</a>. <i>MIT Sloan Management Review</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190814134545/https://sloanreview.mit.edu/article/the-regulation-of-ai-should-organizations-be-worried/\" rel=\"nofollow\">Archived</a> from the original on 2019-08-14<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-08-14</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MIT+Sloan+Management+Review&amp;rft.atitle=The+Regulation+of+AI+%E2%80%93+Should+Organizations+Be+Worried%3F+%7C+Ayanna+Howard&amp;rft.aulast=Howard&amp;rft.aufirst=Ayanna&amp;rft_id=https%3A%2F%2Fsloanreview.mit.edu%2Farticle%2Fthe-regulation-of-ai-should-organizations-be-worried%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-auto-26\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-auto_26-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-auto_26-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFJobinIencaVayena2020\">Jobin, Anna; Ienca, Marcello; Vayena, Effy (2 September 2020). \"The global landscape of AI ethics guidelines\". <i>Nature</i>. <b>1</b> (9): 389–399. <a class=\"mw-redirect\" href=\"/wiki/ArXiv_(identifier)\" title=\"ArXiv (identifier)\">arXiv</a>:<span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//arxiv.org/abs/1906.11668\" rel=\"nofollow\">1906.11668</a></span>. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1038%2Fs42256-019-0088-2\" rel=\"nofollow\">10.1038/s42256-019-0088-2</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:201827642\" rel=\"nofollow\">201827642</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nature&amp;rft.atitle=The+global+landscape+of+AI+ethics+guidelines&amp;rft.volume=1&amp;rft.issue=9&amp;rft.pages=389-399&amp;rft.date=2020-09-02&amp;rft_id=info%3Aarxiv%2F1906.11668&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A201827642%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1038%2Fs42256-019-0088-2&amp;rft.aulast=Jobin&amp;rft.aufirst=Anna&amp;rft.au=Ienca%2C+Marcello&amp;rft.au=Vayena%2C+Effy&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-27\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-27\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFFloridiCowls2019\">Floridi, Luciano; Cowls, Josh (2 July 2019). \"A Unified Framework of Five Principles for AI in Society\". <i>Harvard Data Science Review</i>. <b>1</b>. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1162%2F99608f92.8cd550d1\" rel=\"nofollow\">10.1162/99608f92.8cd550d1</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:198775713\" rel=\"nofollow\">198775713</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Harvard+Data+Science+Review&amp;rft.atitle=A+Unified+Framework+of+Five+Principles+for+AI+in+Society&amp;rft.volume=1&amp;rft.date=2019-07-02&amp;rft_id=info%3Adoi%2F10.1162%2F99608f92.8cd550d1&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A198775713%23id-name%3DS2CID&amp;rft.aulast=Floridi&amp;rft.aufirst=Luciano&amp;rft.au=Cowls%2C+Josh&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-AGI-08a-28\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-AGI-08a_28-0\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://www.ssec.wisc.edu/~billh/g/hibbard_agi_workshop.pdf\" rel=\"nofollow\">Open Source AI.</a> <a class=\"external text\" href=\"https://web.archive.org/web/20160304054930/http://www.ssec.wisc.edu/~billh/g/hibbard_agi_workshop.pdf\" rel=\"nofollow\">Archived</a> 2016-03-04 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a> Bill Hibbard. 2008 proceedings of the First Conference on Artificial General Intelligence, eds. Pei Wang, Ben Goertzel, and Stan Franklin.</span>\n</li>\n<li id=\"cite_note-AGI-08b-29\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-AGI-08b_29-0\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.366.621&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow\">OpenCog: A Software Framework for Integrative Artificial General Intelligence.</a> <a class=\"external text\" href=\"https://web.archive.org/web/20160304205408/http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.366.621&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow\">Archived</a> 2016-03-04 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a> David Hart and Ben Goertzel. 2008 proceedings of the First Conference on Artificial General Intelligence, eds. Pei Wang, Ben Goertzel, and Stan Franklin.</span>\n</li>\n<li id=\"cite_note-OpenAI-30\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-OpenAI_30-0\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"https://www.wired.com/2016/04/openai-elon-musk-sam-altman-plan-to-set-artificial-intelligence-free/\" rel=\"nofollow\">Inside OpenAI, Elon Musk’s Wild Plan to Set Artificial Intelligence Free</a> <a class=\"external text\" href=\"https://web.archive.org/web/20160427162700/http://www.wired.com/2016/04/openai-elon-musk-sam-altman-plan-to-set-artificial-intelligence-free/\" rel=\"nofollow\">Archived</a> 2016-04-27 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a> Cade Metz, Wired 27 April 2016.</span>\n</li>\n<li id=\"cite_note-p7001-31\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-p7001_31-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"p7001\"><a class=\"external text\" href=\"https://standards.ieee.org/project/7001.html\" rel=\"nofollow\">\"P7001 – Transparency of Autonomous Systems\"</a>. <i>P7001 – Transparency of Autonomous Systems</i>. IEEE. <a class=\"external text\" href=\"https://web.archive.org/web/20190110133709/https://standards.ieee.org/project/7001.html\" rel=\"nofollow\">Archived</a> from the original on 10 January 2019<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">10 January</span> 2019</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=P7001+%E2%80%93+Transparency+of+Autonomous+Systems&amp;rft.atitle=P7001+%E2%80%93+Transparency+of+Autonomous+Systems&amp;rft_id=https%3A%2F%2Fstandards.ieee.org%2Fproject%2F7001.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span>.</span>\n</li>\n<li id=\"cite_note-WiredMS-32\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-WiredMS_32-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation magazine cs1\" id=\"WiredMS\">Thurm, Scott (July 13, 2018). <a class=\"external text\" href=\"https://www.wired.com/story/microsoft-calls-for-federal-regulation-of-facial-recognition/\" rel=\"nofollow\">\"MICROSOFT CALLS FOR FEDERAL REGULATION OF FACIAL RECOGNITION\"</a>. <i>Wired</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190509231338/https://www.wired.com/story/microsoft-calls-for-federal-regulation-of-facial-recognition/\" rel=\"nofollow\">Archived</a> from the original on May 9, 2019<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">January 10,</span> 2019</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Wired&amp;rft.atitle=MICROSOFT+CALLS+FOR+FEDERAL+REGULATION+OF+FACIAL+RECOGNITION&amp;rft.date=2018-07-13&amp;rft.aulast=Thurm&amp;rft.aufirst=Scott&amp;rft_id=https%3A%2F%2Fwww.wired.com%2Fstory%2Fmicrosoft-calls-for-federal-regulation-of-facial-recognition%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-DeloitteGDPR-33\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-DeloitteGDPR_33-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"DeloitteGDPR\">Bastin, Roland; Wantz, Georges (June 2017). <a class=\"external text\" href=\"https://www2.deloitte.com/content/dam/Deloitte/lu/Documents/technology/lu-general-data-protection-regulation-cross-industry-innovation-062017.pdf\" rel=\"nofollow\">\"The General Data Protection Regulation Cross-industry innovation\"</a> <span class=\"cs1-format\">(PDF)</span>. <i>Inside magazine</i>. Deloitte. <a class=\"external text\" href=\"https://web.archive.org/web/20190110183405/https://www2.deloitte.com/content/dam/Deloitte/lu/Documents/technology/lu-general-data-protection-regulation-cross-industry-innovation-062017.pdf\" rel=\"nofollow\">Archived</a> <span class=\"cs1-format\">(PDF)</span> from the original on 2019-01-10<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-01-10</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Inside+magazine&amp;rft.atitle=The+General+Data+Protection+Regulation+Cross-industry+innovation&amp;rft.date=2017-06&amp;rft.aulast=Bastin&amp;rft.aufirst=Roland&amp;rft.au=Wantz%2C+Georges&amp;rft_id=https%3A%2F%2Fwww2.deloitte.com%2Fcontent%2Fdam%2FDeloitte%2Flu%2FDocuments%2Ftechnology%2Flu-general-data-protection-regulation-cross-industry-innovation-062017.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-34\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-34\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://news.un.org/en/story/2017/06/558962-un-artificial-intelligence-summit-aims-tackle-poverty-humanitys-grand\" rel=\"nofollow\">\"UN artificial intelligence summit aims to tackle poverty, humanity's 'grand challenges'<span class=\"cs1-kern-right\"></span>\"</a>. <i>UN News</i>. 2017-06-07. <a class=\"external text\" href=\"https://web.archive.org/web/20190726084819/https://news.un.org/en/story/2017/06/558962-un-artificial-intelligence-summit-aims-tackle-poverty-humanitys-grand\" rel=\"nofollow\">Archived</a> from the original on 2019-07-26<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=UN+News&amp;rft.atitle=UN+artificial+intelligence+summit+aims+to+tackle+poverty%2C+humanity%27s+%27grand+challenges%27&amp;rft.date=2017-06-07&amp;rft_id=https%3A%2F%2Fnews.un.org%2Fen%2Fstory%2F2017%2F06%2F558962-un-artificial-intelligence-summit-aims-tackle-poverty-humanitys-grand&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-35\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-35\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"http://www.oecd.org/going-digital/ai/\" rel=\"nofollow\">\"Artificial intelligence – Organisation for Economic Co-operation and Development\"</a>. <i>www.oecd.org</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190722124751/http://www.oecd.org/going-digital/ai/\" rel=\"nofollow\">Archived</a> from the original on 2019-07-22<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.oecd.org&amp;rft.atitle=Artificial+intelligence+%E2%80%93+Organisation+for+Economic+Co-operation+and+Development&amp;rft_id=http%3A%2F%2Fwww.oecd.org%2Fgoing-digital%2Fai%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-36\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-36\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFAnonymous2018\">Anonymous (2018-06-14). <a class=\"external text\" href=\"https://ec.europa.eu/digital-single-market/en/european-ai-alliance\" rel=\"nofollow\">\"The European AI Alliance\"</a>. <i>Digital Single Market – European Commission</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190801011543/https://ec.europa.eu/digital-single-market/en/european-ai-alliance\" rel=\"nofollow\">Archived</a> from the original on 2019-08-01<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Digital+Single+Market+%E2%80%93+European+Commission&amp;rft.atitle=The+European+AI+Alliance&amp;rft.date=2018-06-14&amp;rft.au=Anonymous&amp;rft_id=https%3A%2F%2Fec.europa.eu%2Fdigital-single-market%2Fen%2Feuropean-ai-alliance&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-37\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-37\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFEuropean_Commission_High-Level_Expert_Group_on_AI2019\">European Commission High-Level Expert Group on AI (2019-06-26). <a class=\"external text\" href=\"https://ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence\" rel=\"nofollow\">\"Policy and investment recommendations for trustworthy Artificial Intelligence\"</a>. <i>Shaping Europe’s digital future – European Commission</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20200226023934/https://ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence\" rel=\"nofollow\">Archived</a> from the original on 2020-02-26<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2020-03-16</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Shaping+Europe%E2%80%99s+digital+future+%E2%80%93+European+Commission&amp;rft.atitle=Policy+and+investment+recommendations+for+trustworthy+Artificial+Intelligence&amp;rft.date=2019-06-26&amp;rft.au=European+Commission+High-Level+Expert+Group+on+AI&amp;rft_id=https%3A%2F%2Fec.europa.eu%2Fdigital-single-market%2Fen%2Fnews%2Fpolicy-and-investment-recommendations-trustworthy-artificial-intelligence&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-38\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-38\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://cdt.org/blog/eu-tech-policy-brief-july-2019-recap/\" rel=\"nofollow\">\"EU Tech Policy Brief: July 2019 Recap\"</a>. <i>Center for Democracy &amp; Technology</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190809194057/https://cdt.org/blog/eu-tech-policy-brief-july-2019-recap/\" rel=\"nofollow\">Archived</a> from the original on 2019-08-09<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-08-09</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Center+for+Democracy+%26+Technology&amp;rft.atitle=EU+Tech+Policy+Brief%3A+July+2019+Recap&amp;rft_id=https%3A%2F%2Fcdt.org%2Fblog%2Feu-tech-policy-brief-july-2019-recap%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-39\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-39\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFCurtisGillespieLockey2022\">Curtis, Caitlin; Gillespie, Nicole; Lockey, Steven (2022-05-24). <a class=\"external text\" href=\"https://doi.org/10.1007/s43681-022-00163-7\" rel=\"nofollow\">\"AI-deploying organizations are key to addressing 'perfect storm' of AI risks\"</a>. <i>AI and Ethics</i>: 1–9. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1007%2Fs43681-022-00163-7\" rel=\"nofollow\">10.1007/s43681-022-00163-7</a>. <a class=\"mw-redirect\" href=\"/wiki/ISSN_(identifier)\" title=\"ISSN (identifier)\">ISSN</a> <a class=\"external text\" href=\"//www.worldcat.org/issn/2730-5961\" rel=\"nofollow\">2730-5961</a>. <a class=\"mw-redirect\" href=\"/wiki/PMC_(identifier)\" title=\"PMC (identifier)\">PMC</a> <span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC9127285\" rel=\"nofollow\">9127285</a></span>. <a class=\"mw-redirect\" href=\"/wiki/PMID_(identifier)\" title=\"PMID (identifier)\">PMID</a> <a class=\"external text\" href=\"//pubmed.ncbi.nlm.nih.gov/35634256\" rel=\"nofollow\">35634256</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=AI+and+Ethics&amp;rft.atitle=AI-deploying+organizations+are+key+to+addressing+%27perfect+storm%27+of+AI+risks&amp;rft.pages=1-9&amp;rft.date=2022-05-24&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC9127285%23id-name%3DPMC&amp;rft.issn=2730-5961&amp;rft_id=info%3Apmid%2F35634256&amp;rft_id=info%3Adoi%2F10.1007%2Fs43681-022-00163-7&amp;rft.aulast=Curtis&amp;rft.aufirst=Caitlin&amp;rft.au=Gillespie%2C+Nicole&amp;rft.au=Lockey%2C+Steven&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1007%2Fs43681-022-00163-7&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-40\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-40\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFGabriel2018\">Gabriel, Iason (2018-03-14). <a class=\"external text\" href=\"https://medium.com/@Ethics_Society/the-case-for-fairer-algorithms-c008a12126f8\" rel=\"nofollow\">\"The case for fairer algorithms – Iason Gabriel\"</a>. <i>Medium</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190722080401/https://medium.com/@Ethics_Society/the-case-for-fairer-algorithms-c008a12126f8\" rel=\"nofollow\">Archived</a> from the original on 2019-07-22<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-22</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Medium&amp;rft.atitle=The+case+for+fairer+algorithms+%E2%80%93+Iason+Gabriel&amp;rft.date=2018-03-14&amp;rft.aulast=Gabriel&amp;rft.aufirst=Iason&amp;rft_id=https%3A%2F%2Fmedium.com%2F%40Ethics_Society%2Fthe-case-for-fairer-algorithms-c008a12126f8&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-41\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-41\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"http://social.techcrunch.com/2016/12/10/5-unexpected-sources-of-bias-in-artificial-intelligence/\" rel=\"nofollow\">\"5 unexpected sources of bias in artificial intelligence\"</a>. <i>TechCrunch</i>. 10 December 2016. <a class=\"external text\" href=\"https://web.archive.org/web/20210318060659/https://techcrunch.com/2016/12/10/5-unexpected-sources-of-bias-in-artificial-intelligence/\" rel=\"nofollow\">Archived</a> from the original on 2021-03-18<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-22</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=TechCrunch&amp;rft.atitle=5+unexpected+sources+of+bias+in+artificial+intelligence&amp;rft.date=2016-12-10&amp;rft_id=http%3A%2F%2Fsocial.techcrunch.com%2F2016%2F12%2F10%2F5-unexpected-sources-of-bias-in-artificial-intelligence%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-42\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-42\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFKnight\">Knight, Will. <a class=\"external text\" href=\"https://www.technologyreview.com/s/608986/forget-killer-robotsbias-is-the-real-ai-danger/\" rel=\"nofollow\">\"Google's AI chief says forget Elon Musk's killer robots, and worry about bias in AI systems instead\"</a>. <i>MIT Technology Review</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190704224752/https://www.technologyreview.com/s/608986/forget-killer-robotsbias-is-the-real-ai-danger/\" rel=\"nofollow\">Archived</a> from the original on 2019-07-04<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-22</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=Google%27s+AI+chief+says+forget+Elon+Musk%27s+killer+robots%2C+and+worry+about+bias+in+AI+systems+instead&amp;rft.aulast=Knight&amp;rft.aufirst=Will&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2Fs%2F608986%2Fforget-killer-robotsbias-is-the-real-ai-danger%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-43\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-43\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFVillasenor2019\">Villasenor, John (2019-01-03). <a class=\"external text\" href=\"https://www.brookings.edu/blog/techtank/2019/01/03/artificial-intelligence-and-bias-four-key-challenges/\" rel=\"nofollow\">\"Artificial intelligence and bias: Four key challenges\"</a>. <i>Brookings</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190722080355/https://www.brookings.edu/blog/techtank/2019/01/03/artificial-intelligence-and-bias-four-key-challenges/\" rel=\"nofollow\">Archived</a> from the original on 2019-07-22<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-22</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Brookings&amp;rft.atitle=Artificial+intelligence+and+bias%3A+Four+key+challenges&amp;rft.date=2019-01-03&amp;rft.aulast=Villasenor&amp;rft.aufirst=John&amp;rft_id=https%3A%2F%2Fwww.brookings.edu%2Fblog%2Ftechtank%2F2019%2F01%2F03%2Fartificial-intelligence-and-bias-four-key-challenges%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-44\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-44\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation news cs1\" id=\"CITEREFLohr2018\">Lohr, Steve (9 February 2018). <a class=\"external text\" href=\"https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html\" rel=\"nofollow\">\"Facial Recognition Is Accurate, if You're a White Guy\"</a>. <i>The New York Times</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190109131036/https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html\" rel=\"nofollow\">Archived</a> from the original on 9 January 2019<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">29 May</span> 2019</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=Facial+Recognition+Is+Accurate%2C+if+You%27re+a+White+Guy&amp;rft.date=2018-02-09&amp;rft.aulast=Lohr&amp;rft.aufirst=Steve&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2018%2F02%2F09%2Ftechnology%2Ffacial-recognition-race-artificial-intelligence.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-45\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-45\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFKoeneckeNamLakeNudell2020\">Koenecke, Allison; Nam, Andrew; Lake, Emily; Nudell, Joe; Quartey, Minnie; Mengesha, Zion; Toups, Connor; Rickford, John R.; Jurafsky, Dan; Goel, Sharad (7 April 2020). <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC7149386\" rel=\"nofollow\">\"Racial disparities in automated speech recognition\"</a>. <i>Proceedings of the National Academy of Sciences</i>. <b>117</b> (14): 7684–7689. <a class=\"mw-redirect\" href=\"/wiki/Bibcode_(identifier)\" title=\"Bibcode (identifier)\">Bibcode</a>:<a class=\"external text\" href=\"https://ui.adsabs.harvard.edu/abs/2020PNAS..117.7684K\" rel=\"nofollow\">2020PNAS..117.7684K</a>. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"https://doi.org/10.1073%2Fpnas.1915768117\" rel=\"nofollow\">10.1073/pnas.1915768117</a></span>. <a class=\"mw-redirect\" href=\"/wiki/PMC_(identifier)\" title=\"PMC (identifier)\">PMC</a> <span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC7149386\" rel=\"nofollow\">7149386</a></span>. <a class=\"mw-redirect\" href=\"/wiki/PMID_(identifier)\" title=\"PMID (identifier)\">PMID</a> <a class=\"external text\" href=\"//pubmed.ncbi.nlm.nih.gov/32205437\" rel=\"nofollow\">32205437</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+National+Academy+of+Sciences&amp;rft.atitle=Racial+disparities+in+automated+speech+recognition&amp;rft.volume=117&amp;rft.issue=14&amp;rft.pages=7684-7689&amp;rft.date=2020-04-07&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC7149386%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F32205437&amp;rft_id=info%3Adoi%2F10.1073%2Fpnas.1915768117&amp;rft_id=info%3Abibcode%2F2020PNAS..117.7684K&amp;rft.aulast=Koenecke&amp;rft.aufirst=Allison&amp;rft.au=Nam%2C+Andrew&amp;rft.au=Lake%2C+Emily&amp;rft.au=Nudell%2C+Joe&amp;rft.au=Quartey%2C+Minnie&amp;rft.au=Mengesha%2C+Zion&amp;rft.au=Toups%2C+Connor&amp;rft.au=Rickford%2C+John+R.&amp;rft.au=Jurafsky%2C+Dan&amp;rft.au=Goel%2C+Sharad&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC7149386&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-46\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-46\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation news cs1\"><a class=\"external text\" href=\"https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G\" rel=\"nofollow\">\"Amazon scraps secret AI recruiting tool that showed bias against women\"</a>. <i>Reuters</i>. 2018-10-10. <a class=\"external text\" href=\"https://web.archive.org/web/20190527181625/https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G\" rel=\"nofollow\">Archived</a> from the original on 2019-05-27<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-05-29</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Reuters&amp;rft.atitle=Amazon+scraps+secret+AI+recruiting+tool+that+showed+bias+against+women&amp;rft.date=2018-10-10&amp;rft_id=https%3A%2F%2Fwww.reuters.com%2Farticle%2Fus-amazon-com-jobs-automation-insight-idUSKCN1MK08G&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-47\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-47\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFFriedmanNissenbaum1996\">Friedman, Batya; Nissenbaum, Helen (July 1996). \"Bias in computer systems\". <i>ACM Transactions on Information Systems</i>. <b>14</b> (3): 330–347. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1145%2F230538.230561\" rel=\"nofollow\">10.1145/230538.230561</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:207195759\" rel=\"nofollow\">207195759</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ACM+Transactions+on+Information+Systems&amp;rft.atitle=Bias+in+computer+systems&amp;rft.volume=14&amp;rft.issue=3&amp;rft.pages=330-347&amp;rft.date=1996-07&amp;rft_id=info%3Adoi%2F10.1145%2F230538.230561&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A207195759%23id-name%3DS2CID&amp;rft.aulast=Friedman&amp;rft.aufirst=Batya&amp;rft.au=Nissenbaum%2C+Helen&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-48\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-48\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://techxplore.com/news/2019-07-bias-ai.html\" rel=\"nofollow\">\"Eliminating bias in AI\"</a>. <i>techxplore.com</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190725200844/https://techxplore.com/news/2019-07-bias-ai.html\" rel=\"nofollow\">Archived</a> from the original on 2019-07-25<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=techxplore.com&amp;rft.atitle=Eliminating+bias+in+AI&amp;rft_id=https%3A%2F%2Ftechxplore.com%2Fnews%2F2019-07-bias-ai.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-49\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-49\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFOlson\">Olson, Parmy. <a class=\"external text\" href=\"https://www.forbes.com/sites/parmyolson/2018/03/13/google-deepmind-ai-machine-learning-bias/\" rel=\"nofollow\">\"Google's DeepMind Has An Idea For Stopping Biased AI\"</a>. <i>Forbes</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Forbes&amp;rft.atitle=Google%27s+DeepMind+Has+An+Idea+For+Stopping+Biased+AI&amp;rft.aulast=Olson&amp;rft.aufirst=Parmy&amp;rft_id=https%3A%2F%2Fwww.forbes.com%2Fsites%2Fparmyolson%2F2018%2F03%2F13%2Fgoogle-deepmind-ai-machine-learning-bias%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-50\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-50\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://developers.google.com/machine-learning/fairness-overview/\" rel=\"nofollow\">\"Machine Learning Fairness | ML Fairness\"</a>. <i>Google Developers</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190810004754/https://developers.google.com/machine-learning/fairness-overview/\" rel=\"nofollow\">Archived</a> from the original on 2019-08-10<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Google+Developers&amp;rft.atitle=Machine+Learning+Fairness+%7C+ML+Fairness&amp;rft_id=https%3A%2F%2Fdevelopers.google.com%2Fmachine-learning%2Ffairness-overview%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-51\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-51\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://www.research.ibm.com/5-in-5/ai-and-bias/\" rel=\"nofollow\">\"AI and bias – IBM Research – US\"</a>. <i>www.research.ibm.com</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190717175957/http://www.research.ibm.com/5-in-5/ai-and-bias/\" rel=\"nofollow\">Archived</a> from the original on 2019-07-17<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.research.ibm.com&amp;rft.atitle=AI+and+bias+%E2%80%93+IBM+Research+%E2%80%93+US&amp;rft_id=https%3A%2F%2Fwww.research.ibm.com%2F5-in-5%2Fai-and-bias%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-52\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-52\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFBenderFriedman2018\">Bender, Emily M.; Friedman, Batya (December 2018). <a class=\"external text\" href=\"https://doi.org/10.1162%2Ftacl_a_00041\" rel=\"nofollow\">\"Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science\"</a>. <i>Transactions of the Association for Computational Linguistics</i>. <b>6</b>: 587–604. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"https://doi.org/10.1162%2Ftacl_a_00041\" rel=\"nofollow\">10.1162/tacl_a_00041</a></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Transactions+of+the+Association+for+Computational+Linguistics&amp;rft.atitle=Data+Statements+for+Natural+Language+Processing%3A+Toward+Mitigating+System+Bias+and+Enabling+Better+Science&amp;rft.volume=6&amp;rft.pages=587-604&amp;rft.date=2018-12&amp;rft_id=info%3Adoi%2F10.1162%2Ftacl_a_00041&amp;rft.aulast=Bender&amp;rft.aufirst=Emily+M.&amp;rft.au=Friedman%2C+Batya&amp;rft_id=%2F%2Fdoi.org%2F10.1162%252Ftacl_a_00041&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-53\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-53\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation arxiv cs1\" id=\"CITEREFGebruMorgensternVecchioneVaughan2018\">Gebru, Timnit; Morgenstern, Jamie; Vecchione, Briana; Vaughan, Jennifer Wortman; <a href=\"/wiki/Hanna_Wallach\" title=\"Hanna Wallach\">Wallach, Hanna</a>; Daumé III, Hal; Crawford, Kate (2018). \"Datasheets for Datasets\". <a class=\"mw-redirect\" href=\"/wiki/ArXiv_(identifier)\" title=\"ArXiv (identifier)\">arXiv</a>:<span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//arxiv.org/abs/1803.09010\" rel=\"nofollow\">1803.09010</a></span> [<a class=\"external text\" href=\"//arxiv.org/archive/cs.DB\" rel=\"nofollow\">cs.DB</a>].</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Datasheets+for+Datasets&amp;rft.date=2018&amp;rft_id=info%3Aarxiv%2F1803.09010&amp;rft.aulast=Gebru&amp;rft.aufirst=Timnit&amp;rft.au=Morgenstern%2C+Jamie&amp;rft.au=Vecchione%2C+Briana&amp;rft.au=Vaughan%2C+Jennifer+Wortman&amp;rft.au=Wallach%2C+Hanna&amp;rft.au=Daum%C3%A9+III%2C+Hal&amp;rft.au=Crawford%2C+Kate&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-54\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-54\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFPery2021\">Pery, Andrew (2021-10-06). <a class=\"external text\" href=\"https://deepai.org/publication/trustworthy-artificial-intelligence-and-process-mining-challenges-and-opportunities\" rel=\"nofollow\">\"Trustworthy Artificial Intelligence and Process Mining: Challenges and Opportunities\"</a>. <i>DeepAI</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2022-02-18</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=DeepAI&amp;rft.atitle=Trustworthy+Artificial+Intelligence+and+Process+Mining%3A+Challenges+and+Opportunities&amp;rft.date=2021-10-06&amp;rft.aulast=Pery&amp;rft.aufirst=Andrew&amp;rft_id=https%3A%2F%2Fdeepai.org%2Fpublication%2Ftrustworthy-artificial-intelligence-and-process-mining-challenges-and-opportunities&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-55\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-55\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFKnight\">Knight, Will. <a class=\"external text\" href=\"https://www.technologyreview.com/s/608986/forget-killer-robotsbias-is-the-real-ai-danger/\" rel=\"nofollow\">\"Google's AI chief says forget Elon Musk's killer robots, and worry about bias in AI systems instead\"</a>. <i>MIT Technology Review</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190704224752/https://www.technologyreview.com/s/608986/forget-killer-robotsbias-is-the-real-ai-danger/\" rel=\"nofollow\">Archived</a> from the original on 2019-07-04<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=Google%27s+AI+chief+says+forget+Elon+Musk%27s+killer+robots%2C+and+worry+about+bias+in+AI+systems+instead&amp;rft.aulast=Knight&amp;rft.aufirst=Will&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2Fs%2F608986%2Fforget-killer-robotsbias-is-the-real-ai-danger%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-56\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-56\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://map.ai-global.org/\" rel=\"nofollow\">\"Where in the World is AI? Responsible &amp; Unethical AI Examples\"</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20201031034143/https://map.ai-global.org/\" rel=\"nofollow\">Archived</a> from the original on 2020-10-31<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2020-10-28</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Where+in+the+World+is+AI%3F+Responsible+%26+Unethical+AI+Examples&amp;rft_id=https%3A%2F%2Fmap.ai-global.org%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-57\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-57\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFEvans2015\"><a href=\"/wiki/Woody_Evans\" title=\"Woody Evans\">Evans, Woody</a> (2015). <a class=\"external text\" href=\"https://doi.org/10.5209%2Frev_TK.2015.v12.n2.49072\" rel=\"nofollow\">\"Posthuman Rights: Dimensions of Transhuman Worlds\"</a>. <i>Teknokultura</i>. <b>12</b> (2). <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"https://doi.org/10.5209%2Frev_TK.2015.v12.n2.49072\" rel=\"nofollow\">10.5209/rev_TK.2015.v12.n2.49072</a></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Teknokultura&amp;rft.atitle=Posthuman+Rights%3A+Dimensions+of+Transhuman+Worlds&amp;rft.volume=12&amp;rft.issue=2&amp;rft.date=2015&amp;rft_id=info%3Adoi%2F10.5209%2Frev_TK.2015.v12.n2.49072&amp;rft.aulast=Evans&amp;rft.aufirst=Woody&amp;rft_id=%2F%2Fdoi.org%2F10.5209%252Frev_TK.2015.v12.n2.49072&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-58\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-58\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFSheliazhenko2017\"><a class=\"new\" href=\"/w/index.php?title=Yurii_Sheliazhenko&amp;action=edit&amp;redlink=1\" title=\"Yurii Sheliazhenko (page does not exist)\">Sheliazhenko, Yurii</a> (2017). <a class=\"external text\" href=\"http://cyberleninka.ru/article/n/artificial-personal-autonomy-and-concept-of-robot-rights\" rel=\"nofollow\">\"Artificial Personal Autonomy and Concept of Robot Rights\"</a>. <i>European Journal of Law and Political Sciences</i>: 17–21. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.20534%2FEJLPS-17-1-17-21\" rel=\"nofollow\">10.20534/EJLPS-17-1-17-21</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20180714111141/https://cyberleninka.ru/article/n/artificial-personal-autonomy-and-concept-of-robot-rights\" rel=\"nofollow\">Archived</a> from the original on 14 July 2018<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">10 May</span> 2017</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=European+Journal+of+Law+and+Political+Sciences&amp;rft.atitle=Artificial+Personal+Autonomy+and+Concept+of+Robot+Rights&amp;rft.pages=17-21&amp;rft.date=2017&amp;rft_id=info%3Adoi%2F10.20534%2FEJLPS-17-1-17-21&amp;rft.aulast=Sheliazhenko&amp;rft.aufirst=Yurii&amp;rft_id=http%3A%2F%2Fcyberleninka.ru%2Farticle%2Fn%2Fartificial-personal-autonomy-and-concept-of-robot-rights&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-59\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-59\">^</a></b></span> <span class=\"reference-text\">\n\t \nThe American Heritage Dictionary of the English Language, Fourth Edition\n\t </span>\n</li>\n<li id=\"cite_note-60\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-60\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation news cs1\"><a class=\"external text\" href=\"http://news.bbc.co.uk/2/hi/technology/6200005.stm\" rel=\"nofollow\">\"Robots could demand legal rights\"</a>. <i>BBC News</i>. December 21, 2006. <a class=\"external text\" href=\"https://web.archive.org/web/20191015042628/http://news.bbc.co.uk/2/hi/technology/6200005.stm\" rel=\"nofollow\">Archived</a> from the original on October 15, 2019<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">January 3,</span> 2010</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=BBC+News&amp;rft.atitle=Robots+could+demand+legal+rights&amp;rft.date=2006-12-21&amp;rft_id=http%3A%2F%2Fnews.bbc.co.uk%2F2%2Fhi%2Ftechnology%2F6200005.stm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-TimesOnline-61\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-TimesOnline_61-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-TimesOnline_61-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation news cs1\" id=\"CITEREFHenderson2007\">Henderson, Mark (April 24, 2007). <a class=\"external text\" href=\"http://www.timesonline.co.uk/tol/news/uk/science/article1695546.ece\" rel=\"nofollow\">\"Human rights for robots? We're getting carried away\"</a>. <i>The Times Online</i>. The Times of London. <a class=\"external text\" href=\"https://web.archive.org/web/20080517022444/http://www.timesonline.co.uk/tol/news/uk/science/article1695546.ece\" rel=\"nofollow\">Archived</a> from the original on May 17, 2008<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">May 2,</span> 2010</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Times+Online&amp;rft.atitle=Human+rights+for+robots%3F+We%27re+getting+carried+away&amp;rft.date=2007-04-24&amp;rft.aulast=Henderson&amp;rft.aufirst=Mark&amp;rft_id=http%3A%2F%2Fwww.timesonline.co.uk%2Ftol%2Fnews%2Fuk%2Fscience%2Farticle1695546.ece&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-62\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-62\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFMcGee\">McGee, Glenn. <a class=\"external text\" href=\"https://www.the-scientist.com/column/a-robot-code-of-ethics-46522\" rel=\"nofollow\">\"A Robot Code of Ethics\"</a>. The Scientist. <a class=\"external text\" href=\"https://web.archive.org/web/20200906124127/https://www.the-scientist.com/column/a-robot-code-of-ethics-46522\" rel=\"nofollow\">Archived</a> from the original on 2020-09-06<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-03-25</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=A+Robot+Code+of+Ethics&amp;rft.pub=The+Scientist&amp;rft.aulast=McGee&amp;rft.aufirst=Glenn&amp;rft_id=https%3A%2F%2Fwww.the-scientist.com%2Fcolumn%2Fa-robot-code-of-ethics-46522&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-63\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-63\">^</a></b></span> <span class=\"reference-text\">\n<link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation book cs1\" id=\"CITEREFKurzweil2005\"><a href=\"/wiki/Ray_Kurzweil\" title=\"Ray Kurzweil\">Kurzweil, Ray</a> (2005). <a class=\"mw-redirect\" href=\"/wiki/The_Singularity_is_Near\" title=\"The Singularity is Near\"><i>The Singularity is Near</i></a>. Penguin Books. <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-670-03384-3\" title=\"Special:BookSources/978-0-670-03384-3\"><bdi>978-0-670-03384-3</bdi></a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Singularity+is+Near&amp;rft.pub=Penguin+Books&amp;rft.date=2005&amp;rft.isbn=978-0-670-03384-3&amp;rft.aulast=Kurzweil&amp;rft.aufirst=Ray&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-64\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-64\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"https://web.archive.org/web/20080522163926/http://www.independent.co.uk/news/science/the-big-question-should-the-human-race-be-worried-by-the-rise-of-robots-446107.html\" rel=\"nofollow\">The Big Question: Should the human race be worried by the rise of robots?</a>, Independent Newspaper,</span>\n</li>\n<li id=\"cite_note-65\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-65\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://loebner03.hamill.co.uk/docs/LPC%20Official%20Rules%20v2.0.pdf\" rel=\"nofollow\">Loebner Prize Contest Official Rules — Version 2.0</a> <a class=\"external text\" href=\"https://web.archive.org/web/20160303180753/http://loebner03.hamill.co.uk/docs/LPC%20Official%20Rules%20v2.0.pdf\" rel=\"nofollow\">Archived</a> 2016-03-03 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a> The competition was directed by <a href=\"/wiki/David_Hamill\" title=\"David Hamill\">David Hamill</a> and the rules were developed by members of the Robitron Yahoo group.</span>\n</li>\n<li id=\"cite_note-66\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-66\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://techcrunch.com/2017/10/26/saudi-arabia-robot-citizen-sophia/\" rel=\"nofollow\">\"Saudi Arabia bestows citizenship on a robot named Sophia\"</a>. 26 October 2017. <a class=\"external text\" href=\"https://web.archive.org/web/20171027023101/https://techcrunch.com/2017/10/26/saudi-arabia-robot-citizen-sophia/\" rel=\"nofollow\">Archived</a> from the original on 2017-10-27<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2017-10-27</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Saudi+Arabia+bestows+citizenship+on+a+robot+named+Sophia&amp;rft.date=2017-10-26&amp;rft_id=https%3A%2F%2Ftechcrunch.com%2F2017%2F10%2F26%2Fsaudi-arabia-robot-citizen-sophia%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-bs-67\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-bs_67-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"bs\">Vincent, James (30 October 2017). <a class=\"external text\" href=\"https://www.theverge.com/2017/10/30/16552006/robot-rights-citizenship-saudi-arabia-sophia\" rel=\"nofollow\">\"Pretending to give a robot citizenship helps no one\"</a>. <i>The Verge</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190803144659/https://www.theverge.com/2017/10/30/16552006/robot-rights-citizenship-saudi-arabia-sophia\" rel=\"nofollow\">Archived</a> from the original on 3 August 2019<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">10 January</span> 2019</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Verge&amp;rft.atitle=Pretending+to+give+a+robot+citizenship+helps+no+one&amp;rft.date=2017-10-30&amp;rft.aulast=Vincent&amp;rft.aufirst=James&amp;rft_id=https%3A%2F%2Fwww.theverge.com%2F2017%2F10%2F30%2F16552006%2Frobot-rights-citizenship-saudi-arabia-sophia&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-68\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-68\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation book cs1\" id=\"CITEREFWilks,_Yorick2010\">Wilks, Yorick, ed. (2010). <i>Close engagements with artificial companions: key social, psychological, ethical and design issues</i>. Amsterdam: John Benjamins Pub. Co. <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-9027249944\" title=\"Special:BookSources/978-9027249944\"><bdi>978-9027249944</bdi></a>. <a class=\"mw-redirect\" href=\"/wiki/OCLC_(identifier)\" title=\"OCLC (identifier)\">OCLC</a> <a class=\"external text\" href=\"//www.worldcat.org/oclc/642206106\" rel=\"nofollow\">642206106</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Close+engagements+with+artificial+companions%3A+key+social%2C+psychological%2C+ethical+and+design+issues&amp;rft.place=Amsterdam&amp;rft.pub=John+Benjamins+Pub.+Co&amp;rft.date=2010&amp;rft_id=info%3Aoclcnum%2F642206106&amp;rft.isbn=978-9027249944&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-Weizenbaum's_critique-69\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Weizenbaum's_critique_69-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Weizenbaum's_critique_69-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">\n<ul><li><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation book cs1\"><a href=\"/wiki/Joseph_Weizenbaum\" title=\"Joseph Weizenbaum\">Weizenbaum, Joseph</a> (1976). <a href=\"/wiki/Computer_Power_and_Human_Reason\" title=\"Computer Power and Human Reason\"><i>Computer Power and Human Reason</i></a>. San Francisco: W.H. Freeman &amp; Company. <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-7167-0464-5\" title=\"Special:BookSources/978-0-7167-0464-5\"><bdi>978-0-7167-0464-5</bdi></a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Computer+Power+and+Human+Reason&amp;rft.place=San+Francisco&amp;rft.pub=W.H.+Freeman+%26+Company&amp;rft.date=1976&amp;rft.isbn=978-0-7167-0464-5&amp;rft.aulast=Weizenbaum&amp;rft.aufirst=Joseph&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></li>\n<li><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation cs2\" id=\"CITEREFMcCorduck2004\"><a href=\"/wiki/Pamela_McCorduck\" title=\"Pamela McCorduck\">McCorduck, Pamela</a> (2004), <i>Machines Who Think</i> (2nd ed.), Natick, MA: A. K. Peters, Ltd., <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/1-56881-205-1\" title=\"Special:BookSources/1-56881-205-1\"><bdi>1-56881-205-1</bdi></a></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Machines+Who+Think&amp;rft.place=Natick%2C+MA&amp;rft.edition=2nd&amp;rft.pub=A.+K.+Peters%2C+Ltd.&amp;rft.date=2004&amp;rft.isbn=1-56881-205-1&amp;rft.aulast=McCorduck&amp;rft.aufirst=Pamela&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span>, pp. 132–144 </li></ul>\n</span></li>\n<li id=\"cite_note-MWZ-70\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-MWZ_70-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-MWZ_70-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><a href=\"/wiki/Joseph_Weizenbaum\" title=\"Joseph Weizenbaum\">Joseph Weizenbaum</a>, quoted in <a href=\"#CITEREFMcCorduck2004\">McCorduck 2004</a>, pp. 356, 374–376</span>\n</li>\n<li id=\"cite_note-71\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-71\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFKaplanHaenlein2019\">Kaplan, Andreas; Haenlein, Michael (January 2019). \"Siri, Siri, in my hand: Who's the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence\". <i>Business Horizons</i>. <b>62</b> (1): 15–25. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1016%2Fj.bushor.2018.08.004\" rel=\"nofollow\">10.1016/j.bushor.2018.08.004</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:158433736\" rel=\"nofollow\">158433736</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Business+Horizons&amp;rft.atitle=Siri%2C+Siri%2C+in+my+hand%3A+Who%27s+the+fairest+in+the+land%3F+On+the+interpretations%2C+illustrations%2C+and+implications+of+artificial+intelligence&amp;rft.volume=62&amp;rft.issue=1&amp;rft.pages=15-25&amp;rft.date=2019-01&amp;rft_id=info%3Adoi%2F10.1016%2Fj.bushor.2018.08.004&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A158433736%23id-name%3DS2CID&amp;rft.aulast=Kaplan&amp;rft.aufirst=Andreas&amp;rft.au=Haenlein%2C+Michael&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-hibbard_2014-72\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-hibbard_2014_72-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-hibbard_2014_72-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation arxiv cs1\" id=\"CITEREFHibbard2015\">Hibbard, Bill (17 November 2015). \"Ethical Artificial Intelligence\". <a class=\"mw-redirect\" href=\"/wiki/ArXiv_(identifier)\" title=\"ArXiv (identifier)\">arXiv</a>:<span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//arxiv.org/abs/1411.1373\" rel=\"nofollow\">1411.1373</a></span> [<a class=\"external text\" href=\"//arxiv.org/archive/cs.AI\" rel=\"nofollow\">cs.AI</a>].</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Ethical+Artificial+Intelligence&amp;rft.date=2015-11-17&amp;rft_id=info%3Aarxiv%2F1411.1373&amp;rft.aulast=Hibbard&amp;rft.aufirst=Bill&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-73\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-73\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation news cs1\" id=\"CITEREFDavies2016\">Davies, Alex (29 February 2016). <a class=\"external text\" href=\"https://www.wired.com/2016/02/googles-self-driving-car-may-caused-first-crash/\" rel=\"nofollow\">\"Google's Self-Driving Car Caused Its First Crash\"</a>. <i>Wired</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190707212719/https://www.wired.com/2016/02/googles-self-driving-car-may-caused-first-crash/\" rel=\"nofollow\">Archived</a> from the original on 7 July 2019<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">26 July</span> 2019</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Wired&amp;rft.atitle=Google%27s+Self-Driving+Car+Caused+Its+First+Crash&amp;rft.date=2016-02-29&amp;rft.aulast=Davies&amp;rft.aufirst=Alex&amp;rft_id=https%3A%2F%2Fwww.wired.com%2F2016%2F02%2Fgoogles-self-driving-car-may-caused-first-crash%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-74\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-74\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation news cs1\" id=\"CITEREFLevinWong2018\">Levin, Sam; Wong, Julia Carrie (19 March 2018). <a class=\"external text\" href=\"https://www.theguardian.com/technology/2018/mar/19/uber-self-driving-car-kills-woman-arizona-tempe\" rel=\"nofollow\">\"Self-driving Uber kills Arizona woman in first fatal crash involving pedestrian\"</a>. <i>The Guardian</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190726084818/https://www.theguardian.com/technology/2018/mar/19/uber-self-driving-car-kills-woman-arizona-tempe\" rel=\"nofollow\">Archived</a> from the original on 26 July 2019<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">26 July</span> 2019</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Guardian&amp;rft.atitle=Self-driving+Uber+kills+Arizona+woman+in+first+fatal+crash+involving+pedestrian&amp;rft.date=2018-03-19&amp;rft.aulast=Levin&amp;rft.aufirst=Sam&amp;rft.au=Wong%2C+Julia+Carrie&amp;rft_id=https%3A%2F%2Fwww.theguardian.com%2Ftechnology%2F2018%2Fmar%2F19%2Fuber-self-driving-car-kills-woman-arizona-tempe&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-75\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-75\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://futurism.com/who-responsible-when-self-driving-car-accident\" rel=\"nofollow\">\"Who is responsible when a self-driving car has an accident?\"</a>. <i>Futurism</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190726084819/https://futurism.com/who-responsible-when-self-driving-car-accident\" rel=\"nofollow\">Archived</a> from the original on 2019-07-26<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Futurism&amp;rft.atitle=Who+is+responsible+when+a+self-driving+car+has+an+accident%3F&amp;rft_id=https%3A%2F%2Ffuturism.com%2Fwho-responsible-when-self-driving-car-accident&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-76\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-76\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFRadioPolicyPodcastsAmerica\">Radio, Business; Policy, Law and Public; Podcasts; America, North. <a class=\"external text\" href=\"https://knowledge.wharton.upenn.edu/article/automated-car-accidents/\" rel=\"nofollow\">\"Autonomous Car Crashes: Who – or What – Is to Blame?\"</a>. <i>Knowledge@Wharton</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190726084820/https://knowledge.wharton.upenn.edu/article/automated-car-accidents/\" rel=\"nofollow\">Archived</a> from the original on 2019-07-26<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Knowledge%40Wharton&amp;rft.atitle=Autonomous+Car+Crashes%3A+Who+%E2%80%93+or+What+%E2%80%93+Is+to+Blame%3F&amp;rft.aulast=Radio&amp;rft.aufirst=Business&amp;rft.au=Policy%2C+Law+and+Public&amp;rft.au=Podcasts&amp;rft.au=America%2C+North&amp;rft_id=https%3A%2F%2Fknowledge.wharton.upenn.edu%2Farticle%2Fautomated-car-accidents%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span> <span class=\"cs1-visible-error citation-comment\"><code class=\"cs1-code\">{{<a href=\"/wiki/Template:Cite_web\" title=\"Template:Cite web\">cite web</a>}}</code>: </span><span class=\"cs1-visible-error citation-comment\"><code class=\"cs1-code\">|last2=</code> has generic name (<a href=\"/wiki/Help:CS1_errors#generic_name\" title=\"Help:CS1 errors\">help</a>)</span></span>\n</li>\n<li id=\"cite_note-77\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-77\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFDelbridge\">Delbridge, Emily. <a class=\"external text\" href=\"https://www.thebalance.com/driverless-car-accidents-4171792\" rel=\"nofollow\">\"Driverless Cars Gone Wild\"</a>. <i>The Balance</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190529020717/https://www.thebalance.com/driverless-car-accidents-4171792\" rel=\"nofollow\">Archived</a> from the original on 2019-05-29<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-05-29</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Balance&amp;rft.atitle=Driverless+Cars+Gone+Wild&amp;rft.aulast=Delbridge&amp;rft.aufirst=Emily&amp;rft_id=https%3A%2F%2Fwww.thebalance.com%2Fdriverless-car-accidents-4171792&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-78\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-78\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation cs2\" id=\"CITEREFStilgoe2020\">Stilgoe, Jack (2020), <a class=\"external text\" href=\"http://link.springer.com/10.1007/978-3-030-32320-2_1\" rel=\"nofollow\">\"Who Killed Elaine Herzberg?\"</a>, <i>Who’s Driving Innovation?</i>, Cham: Springer International Publishing, pp. 1–6, <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1007%2F978-3-030-32320-2_1\" rel=\"nofollow\">10.1007/978-3-030-32320-2_1</a>, <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-3-030-32319-6\" title=\"Special:BookSources/978-3-030-32319-6\"><bdi>978-3-030-32319-6</bdi></a>, <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:214359377\" rel=\"nofollow\">214359377</a>, <a class=\"external text\" href=\"https://web.archive.org/web/20210318060722/https://link.springer.com/chapter/10.1007%2F978-3-030-32320-2_1\" rel=\"nofollow\">archived</a> from the original on 2021-03-18<span class=\"reference-accessdate\">, retrieved <span class=\"nowrap\">2020-11-11</span></span></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Who%E2%80%99s+Driving+Innovation%3F&amp;rft.atitle=Who+Killed+Elaine+Herzberg%3F&amp;rft.pages=1-6&amp;rft.date=2020&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A214359377%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-030-32320-2_1&amp;rft.isbn=978-3-030-32319-6&amp;rft.aulast=Stilgoe&amp;rft.aufirst=Jack&amp;rft_id=http%3A%2F%2Flink.springer.com%2F10.1007%2F978-3-030-32320-2_1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-79\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-79\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFMaxmen2018\">Maxmen, Amy (October 2018). <a class=\"external text\" href=\"https://doi.org/10.1038%2Fd41586-018-07135-0\" rel=\"nofollow\">\"Self-driving car dilemmas reveal that moral choices are not universal\"</a>. <i>Nature</i>. <b>562</b> (7728): 469–470. <a class=\"mw-redirect\" href=\"/wiki/Bibcode_(identifier)\" title=\"Bibcode (identifier)\">Bibcode</a>:<a class=\"external text\" href=\"https://ui.adsabs.harvard.edu/abs/2018Natur.562..469M\" rel=\"nofollow\">2018Natur.562..469M</a>. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"https://doi.org/10.1038%2Fd41586-018-07135-0\" rel=\"nofollow\">10.1038/d41586-018-07135-0</a></span>. <a class=\"mw-redirect\" href=\"/wiki/PMID_(identifier)\" title=\"PMID (identifier)\">PMID</a> <a class=\"external text\" href=\"//pubmed.ncbi.nlm.nih.gov/30356197\" rel=\"nofollow\">30356197</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nature&amp;rft.atitle=Self-driving+car+dilemmas+reveal+that+moral+choices+are+not+universal&amp;rft.volume=562&amp;rft.issue=7728&amp;rft.pages=469-470&amp;rft.date=2018-10&amp;rft_id=info%3Apmid%2F30356197&amp;rft_id=info%3Adoi%2F10.1038%2Fd41586-018-07135-0&amp;rft_id=info%3Abibcode%2F2018Natur.562..469M&amp;rft.aulast=Maxmen&amp;rft.aufirst=Amy&amp;rft_id=%2F%2Fdoi.org%2F10.1038%252Fd41586-018-07135-0&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-80\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-80\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://www.gov.uk/government/publications/driverless-cars-in-the-uk-a-regulatory-review\" rel=\"nofollow\">\"Regulations for driverless cars\"</a>. <i>GOV.UK</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190726084816/https://www.gov.uk/government/publications/driverless-cars-in-the-uk-a-regulatory-review\" rel=\"nofollow\">Archived</a> from the original on 2019-07-26<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=GOV.UK&amp;rft.atitle=Regulations+for+driverless+cars&amp;rft_id=https%3A%2F%2Fwww.gov.uk%2Fgovernment%2Fpublications%2Fdriverless-cars-in-the-uk-a-regulatory-review&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-81\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-81\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://web.archive.org/web/20190726084828/https://cyberlaw.stanford.edu/wiki/index.php/Automated_Driving:_Legislative_and_Regulatory_Action\" rel=\"nofollow\">\"Automated Driving: Legislative and Regulatory Action – CyberWiki\"</a>. <i>cyberlaw.stanford.edu</i>. Archived from <a class=\"external text\" href=\"https://cyberlaw.stanford.edu/wiki/index.php/Automated_Driving:_Legislative_and_Regulatory_Action\" rel=\"nofollow\">the original</a> on 2019-07-26<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=cyberlaw.stanford.edu&amp;rft.atitle=Automated+Driving%3A+Legislative+and+Regulatory+Action+%E2%80%93+CyberWiki&amp;rft_id=https%3A%2F%2Fcyberlaw.stanford.edu%2Fwiki%2Findex.php%2FAutomated_Driving%3A_Legislative_and_Regulatory_Action&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-82\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-82\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"http://www.ncsl.org/research/transportation/autonomous-vehicles-self-driving-vehicles-enacted-legislation.aspx\" rel=\"nofollow\">\"Autonomous Vehicles | Self-Driving Vehicles Enacted Legislation\"</a>. <i>www.ncsl.org</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190726165225/http://www.ncsl.org/research/transportation/autonomous-vehicles-self-driving-vehicles-enacted-legislation.aspx\" rel=\"nofollow\">Archived</a> from the original on 2019-07-26<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.ncsl.org&amp;rft.atitle=Autonomous+Vehicles+%7C+Self-Driving+Vehicles+Enacted+Legislation&amp;rft_id=http%3A%2F%2Fwww.ncsl.org%2Fresearch%2Ftransportation%2Fautonomous-vehicles-self-driving-vehicles-enacted-legislation.aspx&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-83\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-83\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"https://www.wired.com/dangerroom/2009/08/robot-three-way-portends-autonomous-future/\" rel=\"nofollow\">Robot Three-Way Portends Autonomous Future</a> <a class=\"external text\" href=\"https://web.archive.org/web/20121107102140/http://www.wired.com/dangerroom/2009/08/robot-three-way-portends-autonomous-future/\" rel=\"nofollow\">Archived</a> 2012-11-07 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>, By David Axe wired.com, August 13, 2009.</span>\n</li>\n<li id=\"cite_note-84\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-84\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation book cs1\" id=\"CITEREFUnited_States._Defense_Innovation_Board\">United States. Defense Innovation Board. <i>AI principles: recommendations on the ethical use of artificial intelligence by the Department of Defense</i>. <a class=\"mw-redirect\" href=\"/wiki/OCLC_(identifier)\" title=\"OCLC (identifier)\">OCLC</a> <a class=\"external text\" href=\"//www.worldcat.org/oclc/1126650738\" rel=\"nofollow\">1126650738</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=AI+principles%3A+recommendations+on+the+ethical+use+of+artificial+intelligence+by+the+Department+of+Defense&amp;rft_id=info%3Aoclcnum%2F1126650738&amp;rft.au=United+States.+Defense+Innovation+Board&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-85\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-85\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"http://www.dailytech.com/New%20Navyfunded%20Report%20Warns%20of%20War%20Robots%20Going%20Terminator/article14298.htm\" rel=\"nofollow\">New Navy-funded Report Warns of War Robots Going \"Terminator\"</a> <a class=\"external text\" href=\"https://web.archive.org/web/20090728101106/http://www.dailytech.com/New%20Navyfunded%20Report%20Warns%20of%20War%20Robots%20Going%20Terminator/article14298.htm\" rel=\"nofollow\">Archived</a> 2009-07-28 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>, by Jason Mick (Blog), dailytech.com, February 17, 2009.</span>\n</li>\n<li id=\"cite_note-86\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-86\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFUmbrelloTorresDe_Bellis2020\">Umbrello, Steven; Torres, Phil; De Bellis, Angelo F. (March 2020). <a class=\"external text\" href=\"http://link.springer.com/10.1007/s00146-019-00879-x\" rel=\"nofollow\">\"The future of war: could lethal autonomous weapons make conflict more ethical?\"</a>. <i>AI &amp; Society</i>. <b>35</b> (1): 273–282. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1007%2Fs00146-019-00879-x\" rel=\"nofollow\">10.1007/s00146-019-00879-x</a>. <a class=\"mw-redirect\" href=\"/wiki/Hdl_(identifier)\" title=\"Hdl (identifier)\">hdl</a>:<a class=\"external text\" href=\"//hdl.handle.net/2318%2F1699364\" rel=\"nofollow\">2318/1699364</a>. <a class=\"mw-redirect\" href=\"/wiki/ISSN_(identifier)\" title=\"ISSN (identifier)\">ISSN</a> <a class=\"external text\" href=\"//www.worldcat.org/issn/0951-5666\" rel=\"nofollow\">0951-5666</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:59606353\" rel=\"nofollow\">59606353</a>. <a class=\"external text\" href=\"https://archive.today/20210105020836/https://link.springer.com/article/10.1007/s00146-019-00879-x\" rel=\"nofollow\">Archived</a> from the original on 2021-01-05<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2020-11-11</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=AI+%26+Society&amp;rft.atitle=The+future+of+war%3A+could+lethal+autonomous+weapons+make+conflict+more+ethical%3F&amp;rft.volume=35&amp;rft.issue=1&amp;rft.pages=273-282&amp;rft.date=2020-03&amp;rft_id=info%3Ahdl%2F2318%2F1699364&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A59606353%23id-name%3DS2CID&amp;rft.issn=0951-5666&amp;rft_id=info%3Adoi%2F10.1007%2Fs00146-019-00879-x&amp;rft.aulast=Umbrello&amp;rft.aufirst=Steven&amp;rft.au=Torres%2C+Phil&amp;rft.au=De+Bellis%2C+Angelo+F.&amp;rft_id=http%3A%2F%2Flink.springer.com%2F10.1007%2Fs00146-019-00879-x&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-87\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-87\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFHellström2013\">Hellström, Thomas (June 2013). \"On the moral responsibility of military robots\". <i>Ethics and Information Technology</i>. <b>15</b> (2): 99–107. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1007%2Fs10676-012-9301-2\" rel=\"nofollow\">10.1007/s10676-012-9301-2</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:15205810\" rel=\"nofollow\">15205810</a>. <link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><a class=\"mw-redirect\" href=\"/wiki/ProQuest_(identifier)\" title=\"ProQuest (identifier)\">ProQuest</a> <a class=\"external text\" href=\"https://search.proquest.com/docview/1372020233\" rel=\"nofollow\">1372020233</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Ethics+and+Information+Technology&amp;rft.atitle=On+the+moral+responsibility+of+military+robots&amp;rft.volume=15&amp;rft.issue=2&amp;rft.pages=99-107&amp;rft.date=2013-06&amp;rft_id=info%3Adoi%2F10.1007%2Fs10676-012-9301-2&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A15205810%23id-name%3DS2CID&amp;rft.aulast=Hellstr%C3%B6m&amp;rft.aufirst=Thomas&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-88\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-88\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFMitra2018\">Mitra, Ambarish (5 April 2018). <a class=\"external text\" href=\"https://qz.com/1244055/we-can-train-ai-to-identify-good-and-evil-and-then-use-it-to-teach-us-morality/\" rel=\"nofollow\">\"We can train AI to identify good and evil, and then use it to teach us morality\"</a>. <i>Quartz</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20190726085248/https://qz.com/1244055/we-can-train-ai-to-identify-good-and-evil-and-then-use-it-to-teach-us-morality/\" rel=\"nofollow\">Archived</a> from the original on 2019-07-26<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Quartz&amp;rft.atitle=We+can+train+AI+to+identify+good+and+evil%2C+and+then+use+it+to+teach+us+morality&amp;rft.date=2018-04-05&amp;rft.aulast=Mitra&amp;rft.aufirst=Ambarish&amp;rft_id=https%3A%2F%2Fqz.com%2F1244055%2Fwe-can-train-ai-to-identify-good-and-evil-and-then-use-it-to-teach-us-morality%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-89\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-89\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://futureoflife.org/ai-principles/\" rel=\"nofollow\">\"AI Principles\"</a>. <i>Future of Life Institute</i>. 11 August 2017. <a class=\"external text\" href=\"https://web.archive.org/web/20171211171044/https://futureoflife.org/ai-principles/\" rel=\"nofollow\">Archived</a> from the original on 2017-12-11<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-26</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Future+of+Life+Institute&amp;rft.atitle=AI+Principles&amp;rft.date=2017-08-11&amp;rft_id=https%3A%2F%2Ffutureoflife.org%2Fai-principles%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-theatlantic.com-90\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-theatlantic.com_90-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-theatlantic.com_90-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFZach_Musgrave_and_Bryan_W._Roberts2015\">Zach Musgrave and Bryan W. Roberts (2015-08-14). <a class=\"external text\" href=\"https://www.theatlantic.com/technology/archive/2015/08/humans-not-robots-are-the-real-reason-artificial-intelligence-is-scary/400994/\" rel=\"nofollow\">\"Why Artificial Intelligence Can Too Easily Be Weaponized – The Atlantic\"</a>. <i>The Atlantic</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20170411140722/https://www.theatlantic.com/technology/archive/2015/08/humans-not-robots-are-the-real-reason-artificial-intelligence-is-scary/400994/\" rel=\"nofollow\">Archived</a> from the original on 2017-04-11<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2017-03-06</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Atlantic&amp;rft.atitle=Why+Artificial+Intelligence+Can+Too+Easily+Be+Weaponized+%E2%80%93+The+Atlantic&amp;rft.date=2015-08-14&amp;rft.au=Zach+Musgrave+and+Bryan+W.+Roberts&amp;rft_id=https%3A%2F%2Fwww.theatlantic.com%2Ftechnology%2Farchive%2F2015%2F08%2Fhumans-not-robots-are-the-real-reason-artificial-intelligence-is-scary%2F400994%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-91\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-91\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\" id=\"CITEREFCat_Zakrzewski2015\">Cat Zakrzewski (2015-07-27). <a class=\"external text\" href=\"https://blogs.wsj.com/digits/2015/07/27/musk-hawking-warn-of-artificial-intelligence-weapons/\" rel=\"nofollow\">\"Musk, Hawking Warn of Artificial Intelligence Weapons\"</a>. <i>WSJ</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20150728173944/http://blogs.wsj.com/digits/2015/07/27/musk-hawking-warn-of-artificial-intelligence-weapons/\" rel=\"nofollow\">Archived</a> from the original on 2015-07-28<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2017-08-04</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=WSJ&amp;rft.atitle=Musk%2C+Hawking+Warn+of+Artificial+Intelligence+Weapons&amp;rft.date=2015-07-27&amp;rft.au=Cat+Zakrzewski&amp;rft_id=https%3A%2F%2Fblogs.wsj.com%2Fdigits%2F2015%2F07%2F27%2Fmusk-hawking-warn-of-artificial-intelligence-weapons%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-givewell-92\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-givewell_92-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation report cs1\" id=\"CITEREFGiveWell2015\"><a href=\"/wiki/GiveWell\" title=\"GiveWell\">GiveWell</a> (2015). <a class=\"external text\" href=\"http://www.givewell.org/labs/causes/ai-risk\" rel=\"nofollow\">Potential risks from advanced artificial intelligence</a> (Report). <a class=\"external text\" href=\"https://web.archive.org/web/20151012084043/http://www.givewell.org/labs/causes/ai-risk\" rel=\"nofollow\">Archived</a> from the original on 12 October 2015<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">11 October</span> 2015</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=report&amp;rft.btitle=Potential+risks+from+advanced+artificial+intelligence&amp;rft.date=2015&amp;rft.au=GiveWell&amp;rft_id=http%3A%2F%2Fwww.givewell.org%2Flabs%2Fcauses%2Fai-risk&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-93\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-93\">^</a></b></span> <span class=\"reference-text\"><a class=\"external text\" href=\"https://think.kera.org/2017/12/05/inside-the-mind-of-a-i/\" rel=\"nofollow\">Inside The Mind Of A.I.</a> - Cliff Kuang interview</span>\n</li>\n<li id=\"cite_note-Muehlhauser,_Luke_2012-94\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Muehlhauser,_Luke_2012_94-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Muehlhauser,_Luke_2012_94-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">Muehlhauser, Luke, and Louie Helm. 2012. <a class=\"external text\" href=\"https://intelligence.org/files/IE-ME.pdf\" rel=\"nofollow\">\"Intelligence Explosion and Machine Ethics\"</a> <a class=\"external text\" href=\"https://web.archive.org/web/20150507173028/http://intelligence.org/files/IE-ME.pdf\" rel=\"nofollow\">Archived</a> 2015-05-07 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>. In Singularity Hypotheses: A Scientific and Philosophical Assessment, edited by Amnon Eden, Johnny Søraker, James H. Moor, and Eric Steinhart. Berlin: Springer.</span>\n</li>\n<li id=\"cite_note-Bostrom,_Nick_2003-95\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-Bostrom,_Nick_2003_95-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-Bostrom,_Nick_2003_95-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\">Bostrom, Nick. 2003. <a class=\"external text\" href=\"http://www.nickbostrom.com/ethics/ai.html\" rel=\"nofollow\">\"Ethical Issues in Advanced Artificial Intelligence\"</a> <a class=\"external text\" href=\"https://web.archive.org/web/20181008090224/http://www.nickbostrom.com/ethics/ai.html\" rel=\"nofollow\">Archived</a> 2018-10-08 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>. In Cognitive, Emotive and Ethical Aspects of Decision Making in Humans and in Artificial Intelligence, edited by Iva Smit and George E. Lasker, 12–17. Vol. 2. Windsor, ON: International Institute for Advanced Studies in Systems Research / Cybernetics.</span>\n</li>\n<li id=\"cite_note-96\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-96\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFUmbrelloBaum2018\">Umbrello, Steven; Baum, Seth D. (2018-06-01). <a class=\"external text\" href=\"http://www.sciencedirect.com/science/article/pii/S0016328717301908\" rel=\"nofollow\">\"Evaluating future nanotechnology: The net societal impacts of atomically precise manufacturing\"</a>. <i>Futures</i>. <b>100</b>: 63–73. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1016%2Fj.futures.2018.04.007\" rel=\"nofollow\">10.1016/j.futures.2018.04.007</a>. <a class=\"mw-redirect\" href=\"/wiki/Hdl_(identifier)\" title=\"Hdl (identifier)\">hdl</a>:<a class=\"external text\" href=\"//hdl.handle.net/2318%2F1685533\" rel=\"nofollow\">2318/1685533</a>. <a class=\"mw-redirect\" href=\"/wiki/ISSN_(identifier)\" title=\"ISSN (identifier)\">ISSN</a> <a class=\"external text\" href=\"//www.worldcat.org/issn/0016-3287\" rel=\"nofollow\">0016-3287</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:158503813\" rel=\"nofollow\">158503813</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20190509222110/https://www.sciencedirect.com/science/article/pii/S0016328717301908\" rel=\"nofollow\">Archived</a> from the original on 2019-05-09<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2020-11-29</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Futures&amp;rft.atitle=Evaluating+future+nanotechnology%3A+The+net+societal+impacts+of+atomically+precise+manufacturing&amp;rft.volume=100&amp;rft.pages=63-73&amp;rft.date=2018-06-01&amp;rft_id=info%3Ahdl%2F2318%2F1685533&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A158503813%23id-name%3DS2CID&amp;rft.issn=0016-3287&amp;rft_id=info%3Adoi%2F10.1016%2Fj.futures.2018.04.007&amp;rft.aulast=Umbrello&amp;rft.aufirst=Steven&amp;rft.au=Baum%2C+Seth+D.&amp;rft_id=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2FS0016328717301908&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-97\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-97\">^</a></b></span> <span class=\"reference-text\">Yudkowsky, Eliezer. 2011. <a class=\"external text\" href=\"https://intelligence.org/files/ComplexValues.pdf\" rel=\"nofollow\">\"Complex Value Systems in Friendly AI\"</a> <a class=\"external text\" href=\"https://web.archive.org/web/20150929212318/http://intelligence.org/files/ComplexValues.pdf\" rel=\"nofollow\">Archived</a> 2015-09-29 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>. In Schmidhuber, Thórisson, and Looks 2011, 388–393.</span>\n</li>\n<li id=\"cite_note-HC-98\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-HC_98-0\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation book cs1\" id=\"CITEREFRussell2019\"><a href=\"/wiki/Stuart_J._Russell\" title=\"Stuart J. Russell\">Russell, Stuart</a> (October 8, 2019). <a href=\"/wiki/Human_Compatible\" title=\"Human Compatible\"><i>Human Compatible: Artificial Intelligence and the Problem of Control</i></a>. United States: Viking. <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-525-55861-3\" title=\"Special:BookSources/978-0-525-55861-3\"><bdi>978-0-525-55861-3</bdi></a>. <a class=\"mw-redirect\" href=\"/wiki/OCLC_(identifier)\" title=\"OCLC (identifier)\">OCLC</a> <a class=\"external text\" href=\"//www.worldcat.org/oclc/1083694322\" rel=\"nofollow\">1083694322</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Human+Compatible%3A+Artificial+Intelligence+and+the+Problem+of+Control&amp;rft.place=United+States&amp;rft.pub=Viking&amp;rft.date=2019-10-08&amp;rft_id=info%3Aoclcnum%2F1083694322&amp;rft.isbn=978-0-525-55861-3&amp;rft.aulast=Russell&amp;rft.aufirst=Stuart&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-99\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-99\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFYampolskiy2020\">Yampolskiy, Roman V. (2020-03-01). <a class=\"external text\" href=\"https://www.worldscientific.com/doi/abs/10.1142/S2705078520500034\" rel=\"nofollow\">\"Unpredictability of AI: On the Impossibility of Accurately Predicting All Actions of a Smarter Agent\"</a>. <i>Journal of Artificial Intelligence and Consciousness</i>. <b>07</b> (1): 109–118. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1142%2FS2705078520500034\" rel=\"nofollow\">10.1142/S2705078520500034</a>. <a class=\"mw-redirect\" href=\"/wiki/ISSN_(identifier)\" title=\"ISSN (identifier)\">ISSN</a> <a class=\"external text\" href=\"//www.worldcat.org/issn/2705-0785\" rel=\"nofollow\">2705-0785</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:218916769\" rel=\"nofollow\">218916769</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20210318060657/https://www.worldscientific.com/doi/abs/10.1142/S2705078520500034\" rel=\"nofollow\">Archived</a> from the original on 2021-03-18<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2020-11-29</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Artificial+Intelligence+and+Consciousness&amp;rft.atitle=Unpredictability+of+AI%3A+On+the+Impossibility+of+Accurately+Predicting+All+Actions+of+a+Smarter+Agent&amp;rft.volume=07&amp;rft.issue=1&amp;rft.pages=109-118&amp;rft.date=2020-03-01&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A218916769%23id-name%3DS2CID&amp;rft.issn=2705-0785&amp;rft_id=info%3Adoi%2F10.1142%2FS2705078520500034&amp;rft.aulast=Yampolskiy&amp;rft.aufirst=Roman+V.&amp;rft_id=https%3A%2F%2Fwww.worldscientific.com%2Fdoi%2Fabs%2F10.1142%2FS2705078520500034&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-100\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-100\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation cs2\" id=\"CITEREFWallachVallor2020\">Wallach, Wendell; Vallor, Shannon (2020-09-17), <a class=\"external text\" href=\"https://oxford.universitypressscholarship.com/view/10.1093/oso/9780190905033.001.0001/oso-9780190905033-chapter-14\" rel=\"nofollow\">\"Moral Machines: From Value Alignment to Embodied Virtue\"</a>, <i>Ethics of Artificial Intelligence</i>, Oxford University Press, pp. 383–412, <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1093%2Foso%2F9780190905033.003.0014\" rel=\"nofollow\">10.1093/oso/9780190905033.003.0014</a>, <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-19-090503-3\" title=\"Special:BookSources/978-0-19-090503-3\"><bdi>978-0-19-090503-3</bdi></a>, <a class=\"external text\" href=\"https://web.archive.org/web/20201208114354/https://oxford.universitypressscholarship.com/view/10.1093/oso/9780190905033.001.0001/oso-9780190905033-chapter-14\" rel=\"nofollow\">archived</a> from the original on 2020-12-08<span class=\"reference-accessdate\">, retrieved <span class=\"nowrap\">2020-11-29</span></span></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Ethics+of+Artificial+Intelligence&amp;rft.atitle=Moral+Machines%3A+From+Value+Alignment+to+Embodied+Virtue&amp;rft.pages=383-412&amp;rft.date=2020-09-17&amp;rft_id=info%3Adoi%2F10.1093%2Foso%2F9780190905033.003.0014&amp;rft.isbn=978-0-19-090503-3&amp;rft.aulast=Wallach&amp;rft.aufirst=Wendell&amp;rft.au=Vallor%2C+Shannon&amp;rft_id=https%3A%2F%2Foxford.universitypressscholarship.com%2Fview%2F10.1093%2Foso%2F9780190905033.001.0001%2Foso-9780190905033-chapter-14&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-101\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-101\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFUmbrello2019\">Umbrello, Steven (2019). <a class=\"external text\" href=\"https://doi.org/10.3390%2Fbdcc3010005\" rel=\"nofollow\">\"Beneficial Artificial Intelligence Coordination by Means of a Value Sensitive Design Approach\"</a>. <i>Big Data and Cognitive Computing</i>. <b>3</b> (1): 5. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"https://doi.org/10.3390%2Fbdcc3010005\" rel=\"nofollow\">10.3390/bdcc3010005</a></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Big+Data+and+Cognitive+Computing&amp;rft.atitle=Beneficial+Artificial+Intelligence+Coordination+by+Means+of+a+Value+Sensitive+Design+Approach&amp;rft.volume=3&amp;rft.issue=1&amp;rft.pages=5&amp;rft.date=2019&amp;rft_id=info%3Adoi%2F10.3390%2Fbdcc3010005&amp;rft.aulast=Umbrello&amp;rft.aufirst=Steven&amp;rft_id=%2F%2Fdoi.org%2F10.3390%252Fbdcc3010005&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-102\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-102\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFFloridiCowlsKingTaddeo2020\">Floridi, Luciano; Cowls, Josh; King, Thomas C.; Taddeo, Mariarosaria (2020). <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC7286860\" rel=\"nofollow\">\"How to Design AI for Social Good: Seven Essential Factors\"</a>. <i>Science and Engineering Ethics</i>. <b>26</b> (3): 1771–1796. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1007%2Fs11948-020-00213-5\" rel=\"nofollow\">10.1007/s11948-020-00213-5</a>. <a class=\"mw-redirect\" href=\"/wiki/ISSN_(identifier)\" title=\"ISSN (identifier)\">ISSN</a> <a class=\"external text\" href=\"//www.worldcat.org/issn/1353-3452\" rel=\"nofollow\">1353-3452</a>. <a class=\"mw-redirect\" href=\"/wiki/PMC_(identifier)\" title=\"PMC (identifier)\">PMC</a> <span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC7286860\" rel=\"nofollow\">7286860</a></span>. <a class=\"mw-redirect\" href=\"/wiki/PMID_(identifier)\" title=\"PMID (identifier)\">PMID</a> <a class=\"external text\" href=\"//pubmed.ncbi.nlm.nih.gov/32246245\" rel=\"nofollow\">32246245</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Science+and+Engineering+Ethics&amp;rft.atitle=How+to+Design+AI+for+Social+Good%3A+Seven+Essential+Factors&amp;rft.volume=26&amp;rft.issue=3&amp;rft.pages=1771-1796&amp;rft.date=2020&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC7286860%23id-name%3DPMC&amp;rft.issn=1353-3452&amp;rft_id=info%3Apmid%2F32246245&amp;rft_id=info%3Adoi%2F10.1007%2Fs11948-020-00213-5&amp;rft.aulast=Floridi&amp;rft.aufirst=Luciano&amp;rft.au=Cowls%2C+Josh&amp;rft.au=King%2C+Thomas+C.&amp;rft.au=Taddeo%2C+Mariarosaria&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC7286860&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-103\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-103\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation news cs1\" id=\"CITEREFFiegerman2016\">Fiegerman, Seth (28 September 2016). <a class=\"external text\" href=\"https://money.cnn.com/2016/09/28/technology/partnership-on-ai/\" rel=\"nofollow\">\"Facebook, Google, Amazon create group to ease AI concerns\"</a>. <i>CNNMoney</i>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=CNNMoney&amp;rft.atitle=Facebook%2C+Google%2C+Amazon+create+group+to+ease+AI+concerns&amp;rft.date=2016-09-28&amp;rft.aulast=Fiegerman&amp;rft.aufirst=Seth&amp;rft_id=https%3A%2F%2Fmoney.cnn.com%2F2016%2F09%2F28%2Ftechnology%2Fpartnership-on-ai%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-104\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-104\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai\" rel=\"nofollow\">\"Ethics guidelines for trustworthy AI\"</a>. <i>Shaping Europe’s digital future – European Commission</i>. European Commission. 2019-04-08. <a class=\"external text\" href=\"https://web.archive.org/web/20200220002342/https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai\" rel=\"nofollow\">Archived</a> from the original on 2020-02-20<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2020-02-20</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Shaping+Europe%E2%80%99s+digital+future+%E2%80%93+European+Commission&amp;rft.atitle=Ethics+guidelines+for+trustworthy+AI&amp;rft.date=2019-04-08&amp;rft_id=https%3A%2F%2Fec.europa.eu%2Fdigital-single-market%2Fen%2Fnews%2Fethics-guidelines-trustworthy-ai&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-105\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-105\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://ec.europa.eu/digital-single-market/en/news/white-paper-artificial-intelligence-european-approach-excellence-and-trust\" rel=\"nofollow\">\"White Paper on Artificial Intelligence – a European approach to excellence and trust | Shaping Europe's digital future\"</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=White+Paper+on+Artificial+Intelligence+%E2%80%93+a+European+approach+to+excellence+and+trust+%26%23124%3B+Shaping+Europe%27s+digital+future&amp;rft_id=https%3A%2F%2Fec.europa.eu%2Fdigital-single-market%2Fen%2Fnews%2Fwhite-paper-artificial-intelligence-european-approach-excellence-and-trust&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-106\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-106\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://www.oecd.ai/\" rel=\"nofollow\">\"OECD AI Policy Observatory\"</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=OECD+AI+Policy+Observatory&amp;rft_id=https%3A%2F%2Fwww.oecd.ai%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-107\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-107\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation news cs1\"><a class=\"external text\" href=\"https://hbr.org/2016/12/the-obama-administrations-roadmap-for-ai-policy\" rel=\"nofollow\">\"The Obama Administration's Roadmap for AI Policy\"</a>. <i>Harvard Business Review</i>. 2016-12-21. <a class=\"mw-redirect\" href=\"/wiki/ISSN_(identifier)\" title=\"ISSN (identifier)\">ISSN</a> <a class=\"external text\" href=\"//www.worldcat.org/issn/0017-8012\" rel=\"nofollow\">0017-8012</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20210122003445/https://hbr.org/2016/12/the-obama-administrations-roadmap-for-ai-policy\" rel=\"nofollow\">Archived</a> from the original on 2021-01-22<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2021-03-16</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Harvard+Business+Review&amp;rft.atitle=The+Obama+Administration%27s+Roadmap+for+AI+Policy&amp;rft.date=2016-12-21&amp;rft.issn=0017-8012&amp;rft_id=https%3A%2F%2Fhbr.org%2F2016%2F12%2Fthe-obama-administrations-roadmap-for-ai-policy&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-108\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-108\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://trumpwhitehouse.archives.gov/articles/accelerating-americas-leadership-in-artificial-intelligence/\" rel=\"nofollow\">\"Accelerating America's Leadership in Artificial Intelligence – The White House\"</a>. <i>trumpwhitehouse.archives.gov</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20210225073748/https://trumpwhitehouse.archives.gov/articles/accelerating-americas-leadership-in-artificial-intelligence/\" rel=\"nofollow\">Archived</a> from the original on 2021-02-25<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2021-03-16</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=trumpwhitehouse.archives.gov&amp;rft.atitle=Accelerating+America%27s+Leadership+in+Artificial+Intelligence+%E2%80%93+The+White+House&amp;rft_id=https%3A%2F%2Ftrumpwhitehouse.archives.gov%2Farticles%2Faccelerating-americas-leadership-in-artificial-intelligence%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-109\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-109\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://www.federalregister.gov/documents/2020/01/13/2020-00261/request-for-comments-on-a-draft-memorandum-to-the-heads-of-executive-departments-and-agencies\" rel=\"nofollow\">\"Request for Comments on a Draft Memorandum to the Heads of Executive Departments and Agencies, \"Guidance for Regulation of Artificial Intelligence Applications\"<span class=\"cs1-kern-right\"></span>\"</a>. <i>Federal Register</i>. 2020-01-13. <a class=\"external text\" href=\"https://web.archive.org/web/20201125060218/https://www.federalregister.gov/documents/2020/01/13/2020-00261/request-for-comments-on-a-draft-memorandum-to-the-heads-of-executive-departments-and-agencies\" rel=\"nofollow\">Archived</a> from the original on 2020-11-25<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2020-11-28</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Federal+Register&amp;rft.atitle=Request+for+Comments+on+a+Draft+Memorandum+to+the+Heads+of+Executive+Departments+and+Agencies%2C+%22Guidance+for+Regulation+of+Artificial+Intelligence+Applications%22&amp;rft.date=2020-01-13&amp;rft_id=https%3A%2F%2Fwww.federalregister.gov%2Fdocuments%2F2020%2F01%2F13%2F2020-00261%2Frequest-for-comments-on-a-draft-memorandum-to-the-heads-of-executive-departments-and-agencies&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-110\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-110\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://www.hpcwire.com/2019/05/14/ccc-offers-draft-20-year-ai-roadmap-seeks-comments/\" rel=\"nofollow\">\"CCC Offers Draft 20-Year AI Roadmap; Seeks Comments\"</a>. <i>HPCwire</i>. 2019-05-14. <a class=\"external text\" href=\"https://web.archive.org/web/20210318060659/https://www.hpcwire.com/2019/05/14/ccc-offers-draft-20-year-ai-roadmap-seeks-comments/\" rel=\"nofollow\">Archived</a> from the original on 2021-03-18<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-22</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=HPCwire&amp;rft.atitle=CCC+Offers+Draft+20-Year+AI+Roadmap%3B+Seeks+Comments&amp;rft.date=2019-05-14&amp;rft_id=https%3A%2F%2Fwww.hpcwire.com%2F2019%2F05%2F14%2Fccc-offers-draft-20-year-ai-roadmap-seeks-comments%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-111\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-111\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://www.cccblog.org/2019/05/13/request-comments-on-draft-a-20-year-community-roadmap-for-ai-research-in-the-us/\" rel=\"nofollow\">\"Request Comments on Draft: A 20-Year Community Roadmap for AI Research in the US » CCC Blog\"</a>. 13 May 2019. <a class=\"external text\" href=\"https://web.archive.org/web/20190514193546/https://www.cccblog.org/2019/05/13/request-comments-on-draft-a-20-year-community-roadmap-for-ai-research-in-the-us/\" rel=\"nofollow\">Archived</a> from the original on 2019-05-14<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2019-07-22</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Request+Comments+on+Draft%3A+A+20-Year+Community+Roadmap+for+AI+Research+in+the+US+%C2%BB+CCC+Blog&amp;rft.date=2019-05-13&amp;rft_id=https%3A%2F%2Fwww.cccblog.org%2F2019%2F05%2F13%2Frequest-comments-on-draft-a-20-year-community-roadmap-for-ai-research-in-the-us%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-112\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-112\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://nonhuman.party\" rel=\"nofollow\">\"Non-Human Party\"</a>. 2021.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Non-Human+Party&amp;rft.date=2021&amp;rft_id=https%3A%2F%2Fnonhuman.party&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-113\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-113\">^</a></b></span> <span class=\"reference-text\"><span class=\"languageicon\">(in Russian)</span> <a class=\"external text\" href=\"https://www.kommersant.ru/doc/5089365\" rel=\"nofollow\">Интеллектуальные правила</a> — <a href=\"/wiki/Kommersant\" title=\"Kommersant\">Kommersant</a>, 25.11.2021</span>\n</li>\n<li id=\"cite_note-114\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-114\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation arxiv cs1\" id=\"CITEREFGraceSalvatierDafoeZhang2018\">Grace, Katja; Salvatier, John; Dafoe, Allan; Zhang, Baobao; Evans, Owain (2018-05-03). \"When Will AI Exceed Human Performance? Evidence from AI Experts\". <a class=\"mw-redirect\" href=\"/wiki/ArXiv_(identifier)\" title=\"ArXiv (identifier)\">arXiv</a>:<span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//arxiv.org/abs/1705.08807\" rel=\"nofollow\">1705.08807</a></span> [<a class=\"external text\" href=\"//arxiv.org/archive/cs.AI\" rel=\"nofollow\">cs.AI</a>].</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=When+Will+AI+Exceed+Human+Performance%3F+Evidence+from+AI+Experts&amp;rft.date=2018-05-03&amp;rft_id=info%3Aarxiv%2F1705.08807&amp;rft.aulast=Grace&amp;rft.aufirst=Katja&amp;rft.au=Salvatier%2C+John&amp;rft.au=Dafoe%2C+Allan&amp;rft.au=Zhang%2C+Baobao&amp;rft.au=Evans%2C+Owain&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-115\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-115\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://www.technologyreview.com/2018/03/16/144630/china-wants-to-shape-the-global-future-of-artificial-intelligence/\" rel=\"nofollow\">\"China wants to shape the global future of artificial intelligence\"</a>. <i>MIT Technology Review</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20201120052853/https://www.technologyreview.com/2018/03/16/144630/china-wants-to-shape-the-global-future-of-artificial-intelligence/\" rel=\"nofollow\">Archived</a> from the original on 2020-11-20<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2020-11-29</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=China+wants+to+shape+the+global+future+of+artificial+intelligence&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2F2018%2F03%2F16%2F144630%2Fchina-wants-to-shape-the-global-future-of-artificial-intelligence%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-116\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-116\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFFloridiCowlsBeltramettiChatila2018\">Floridi, Luciano; Cowls, Josh; Beltrametti, Monica; Chatila, Raja; Chazerand, Patrice; Dignum, Virginia; Luetge, Christoph; Madelin, Robert; Pagallo, Ugo; Rossi, Francesca; Schafer, Burkhard (2018-12-01). <a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC6404626\" rel=\"nofollow\">\"AI4People—An Ethical Framework for a Good AI Society: Opportunities, Risks, Principles, and Recommendations\"</a>. <i>Minds and Machines</i>. <b>28</b> (4): 689–707. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1007%2Fs11023-018-9482-5\" rel=\"nofollow\">10.1007/s11023-018-9482-5</a>. <a class=\"mw-redirect\" href=\"/wiki/ISSN_(identifier)\" title=\"ISSN (identifier)\">ISSN</a> <a class=\"external text\" href=\"//www.worldcat.org/issn/1572-8641\" rel=\"nofollow\">1572-8641</a>. <a class=\"mw-redirect\" href=\"/wiki/PMC_(identifier)\" title=\"PMC (identifier)\">PMC</a> <span class=\"cs1-lock-free\" title=\"Freely accessible\"><a class=\"external text\" href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC6404626\" rel=\"nofollow\">6404626</a></span>. <a class=\"mw-redirect\" href=\"/wiki/PMID_(identifier)\" title=\"PMID (identifier)\">PMID</a> <a class=\"external text\" href=\"//pubmed.ncbi.nlm.nih.gov/30930541\" rel=\"nofollow\">30930541</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Minds+and+Machines&amp;rft.atitle=AI4People%E2%80%94An+Ethical+Framework+for+a+Good+AI+Society%3A+Opportunities%2C+Risks%2C+Principles%2C+and+Recommendations&amp;rft.volume=28&amp;rft.issue=4&amp;rft.pages=689-707&amp;rft.date=2018-12-01&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC6404626%23id-name%3DPMC&amp;rft.issn=1572-8641&amp;rft_id=info%3Apmid%2F30930541&amp;rft_id=info%3Adoi%2F10.1007%2Fs11023-018-9482-5&amp;rft.aulast=Floridi&amp;rft.aufirst=Luciano&amp;rft.au=Cowls%2C+Josh&amp;rft.au=Beltrametti%2C+Monica&amp;rft.au=Chatila%2C+Raja&amp;rft.au=Chazerand%2C+Patrice&amp;rft.au=Dignum%2C+Virginia&amp;rft.au=Luetge%2C+Christoph&amp;rft.au=Madelin%2C+Robert&amp;rft.au=Pagallo%2C+Ugo&amp;rft.au=Rossi%2C+Francesca&amp;rft.au=Schafer%2C+Burkhard&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC6404626&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-117\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-117\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://engineering.nyu.edu/news/new-artificial-intelligence-research-institute-launches\" rel=\"nofollow\">\"New Artificial Intelligence Research Institute Launches\"</a>. 2017-11-20. <a class=\"external text\" href=\"https://web.archive.org/web/20200918091106/https://engineering.nyu.edu/news/new-artificial-intelligence-research-institute-launches\" rel=\"nofollow\">Archived</a> from the original on 2020-09-18<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2021-02-21</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=New+Artificial+Intelligence+Research+Institute+Launches&amp;rft.date=2017-11-20&amp;rft_id=https%3A%2F%2Fengineering.nyu.edu%2Fnews%2Fnew-artificial-intelligence-research-institute-launches&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-118\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-118\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation book cs1\" id=\"CITEREFHughes,_James_J.LaGrandeur,_Kevin2017\">Hughes, James J.; LaGrandeur, Kevin, eds. (15 March 2017). <a class=\"external text\" href=\"https://www.worldcat.org/oclc/976407024\" rel=\"nofollow\"><i>Surviving the machine age: intelligent technology and the transformation of human work</i></a>. Cham, Switzerland. <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-3-319-51165-8\" title=\"Special:BookSources/978-3-319-51165-8\"><bdi>978-3-319-51165-8</bdi></a>. <a class=\"mw-redirect\" href=\"/wiki/OCLC_(identifier)\" title=\"OCLC (identifier)\">OCLC</a> <a class=\"external text\" href=\"//www.worldcat.org/oclc/976407024\" rel=\"nofollow\">976407024</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20210318060659/https://www.worldcat.org/title/surviving-the-machine-age-intelligent-technology-and-the-transformation-of-human-work/oclc/976407024\" rel=\"nofollow\">Archived</a> from the original on 18 March 2021<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">29 November</span> 2020</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Surviving+the+machine+age%3A+intelligent+technology+and+the+transformation+of+human+work&amp;rft.place=Cham%2C+Switzerland&amp;rft.date=2017-03-15&amp;rft_id=info%3Aoclcnum%2F976407024&amp;rft.isbn=978-3-319-51165-8&amp;rft_id=https%3A%2F%2Fwww.worldcat.org%2Foclc%2F976407024&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-119\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-119\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation book cs1\" id=\"CITEREFDanaher,_John2019\">Danaher, John (2019). <a class=\"external text\" href=\"https://www.worldcat.org/oclc/1114334813\" rel=\"nofollow\"><i>Automation and utopia: human flourishing in a world without work</i></a>. Cambridge, Massachusetts. <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-674-24220-3\" title=\"Special:BookSources/978-0-674-24220-3\"><bdi>978-0-674-24220-3</bdi></a>. <a class=\"mw-redirect\" href=\"/wiki/OCLC_(identifier)\" title=\"OCLC (identifier)\">OCLC</a> <a class=\"external text\" href=\"//www.worldcat.org/oclc/1114334813\" rel=\"nofollow\">1114334813</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Automation+and+utopia%3A+human+flourishing+in+a+world+without+work&amp;rft.place=Cambridge%2C+Massachusetts&amp;rft.date=2019&amp;rft_id=info%3Aoclcnum%2F1114334813&amp;rft.isbn=978-0-674-24220-3&amp;rft.au=Danaher%2C+John&amp;rft_id=https%3A%2F%2Fwww.worldcat.org%2Foclc%2F1114334813&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-120\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-120\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://www.tum.de/nc/en/about-tum/news/press-releases/details/35727/\" rel=\"nofollow\">\"TUM Institute for Ethics in Artificial Intelligence officially opened\"</a>. <i>www.tum.de</i>. <a class=\"external text\" href=\"https://web.archive.org/web/20201210032545/https://www.tum.de/nc/en/about-tum/news/press-releases/details/35727/\" rel=\"nofollow\">Archived</a> from the original on 2020-12-10<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2020-11-29</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.tum.de&amp;rft.atitle=TUM+Institute+for+Ethics+in+Artificial+Intelligence+officially+opened&amp;rft_id=https%3A%2F%2Fwww.tum.de%2Fnc%2Fen%2Fabout-tum%2Fnews%2Fpress-releases%2Fdetails%2F35727%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-121\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-121\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation news cs1\" id=\"CITEREFLee2020\">Lee, Jennifer 8 (2020-02-08). <a class=\"external text\" href=\"https://www.npr.org/sections/codeswitch/2020/02/08/770174171/when-bias-is-coded-into-our-technology\" rel=\"nofollow\">\"When Bias Is Coded Into Our Technology\"</a>. <i>NPR</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2021-12-22</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=NPR&amp;rft.atitle=When+Bias+Is+Coded+Into+Our+Technology&amp;rft.date=2020-02-08&amp;rft.aulast=Lee&amp;rft.aufirst=Jennifer+8&amp;rft_id=https%3A%2F%2Fwww.npr.org%2Fsections%2Fcodeswitch%2F2020%2F02%2F08%2F770174171%2Fwhen-bias-is-coded-into-our-technology&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-:1-122\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:1_122-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:1_122-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\"><a class=\"external text\" href=\"https://www.nature.com/articles/d41586-018-07718-x\" rel=\"nofollow\">\"How one conference embraced diversity\"</a>. <i>Nature</i>. <b>564</b> (7735): 161–162. 2018-12-12. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1038%2Fd41586-018-07718-x\" rel=\"nofollow\">10.1038/d41586-018-07718-x</a>. <a class=\"mw-redirect\" href=\"/wiki/PMID_(identifier)\" title=\"PMID (identifier)\">PMID</a> <a class=\"external text\" href=\"//pubmed.ncbi.nlm.nih.gov/31123357\" rel=\"nofollow\">31123357</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:54481549\" rel=\"nofollow\">54481549</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nature&amp;rft.atitle=How+one+conference+embraced+diversity&amp;rft.volume=564&amp;rft.issue=7735&amp;rft.pages=161-162&amp;rft.date=2018-12-12&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A54481549%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F31123357&amp;rft_id=info%3Adoi%2F10.1038%2Fd41586-018-07718-x&amp;rft_id=https%3A%2F%2Fwww.nature.com%2Farticles%2Fd41586-018-07718-x&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-123\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-123\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation news cs1\" id=\"CITEREFRoose2020\">Roose, Kevin (2020-12-30). <a class=\"external text\" href=\"https://www.nytimes.com/2020/12/30/technology/2020-good-tech-awards.html\" rel=\"nofollow\">\"The 2020 Good Tech Awards\"</a>. <i>The New York Times</i>. <a class=\"mw-redirect\" href=\"/wiki/ISSN_(identifier)\" title=\"ISSN (identifier)\">ISSN</a> <a class=\"external text\" href=\"//www.worldcat.org/issn/0362-4331\" rel=\"nofollow\">0362-4331</a><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2021-12-21</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=The+2020+Good+Tech+Awards&amp;rft.date=2020-12-30&amp;rft.issn=0362-4331&amp;rft.aulast=Roose&amp;rft.aufirst=Kevin&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2020%2F12%2F30%2Ftechnology%2F2020-good-tech-awards.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-124\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-124\">^</a></b></span> <span class=\"reference-text\">Torras, Carme, (2020), “Science-Fiction: A Mirror for the Future of Humankind” in <i>IDEES</i>, Centre d'estudis de temes contemporanis (CETC), Barcelona. <a class=\"external free\" href=\"https://revistaidees.cat/en/science-fiction-favors-engaging-debate-on-artificial-intelligence-and-ethics/\" rel=\"nofollow\">https://revistaidees.cat/en/science-fiction-favors-engaging-debate-on-artificial-intelligence-and-ethics/</a> Retrieved on 2021-06-10</span>\n</li>\n<li id=\"cite_note-125\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-125\">^</a></b></span> <span class=\"reference-text\">Gottfried Wilhelm Leibniz, (1714): Monadology, § 17 (“Mill Argument”). See also: Lodge, P. (2014): «Leibniz’s Mill Argument: Against Mechanical Materialism Revisited”, in ERGO, Volume 1, No. 03) <a class=\"external free\" href=\"https://quod.lib.umich.edu/e/ergo/12405314.0001.003/--leibniz-s-mill-argument-against-mechanical-materialism?rgn=main;view=fulltext\" rel=\"nofollow\">https://quod.lib.umich.edu/e/ergo/12405314.0001.003/--leibniz-s-mill-argument-against-mechanical-materialism?rgn=main;view=fulltext</a> Retrieved on 2021-06-10</span>\n</li>\n<li id=\"cite_note-126\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-126\">^</a></b></span> <span class=\"reference-text\">Cited in  Bringsjord, Selmer and Naveen Sundar Govindarajulu, \"Artificial Intelligence\", <i>The Stanford Encyclopedia of Philosophy</i> (Summer 2020 Edition), Edward N. Zalta (ed.), URL = &lt;<a class=\"external free\" href=\"https://plato.stanford.edu/archives/sum2020/entries/artificial-intelligence/\" rel=\"nofollow\">https://plato.stanford.edu/archives/sum2020/entries/artificial-intelligence/</a>&gt;. Retrieved on 2021-06-10</span>\n</li>\n<li id=\"cite_note-127\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-127\">^</a></b></span> <span class=\"reference-text\">Hodges, A. (2014), <i>Alan Turing: The Enigma</i>,Vintage, London,.p.334</span>\n</li>\n<li id=\"cite_note-128\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-128\">^</a></b></span> <span class=\"reference-text\">A. M. Turing (1936). \"On computable numbers, with an application to the Entscheidungsproblem.\" in <i>Proceedings of the London Mathematical Society</i>, 2 s. vol. 42 (1936–1937), pp. 230–265.</span>\n</li>\n<li id=\"cite_note-129\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-129\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://readysteadycut.com/2021/05/14/recap-love-death-and-robots-season-2-episode-1-automated-customer-service-netflix-series/\" rel=\"nofollow\">\"Love, Death &amp; Robots season 2, episode 1 recap - \"Automated Customer Service\"<span class=\"cs1-kern-right\"></span>\"</a>. <i>Ready Steady Cut</i>. 2021-05-14<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2021-12-21</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ready+Steady+Cut&amp;rft.atitle=Love%2C+Death+%26+Robots+season+2%2C+episode+1+recap+-+%22Automated+Customer+Service%22&amp;rft.date=2021-05-14&amp;rft_id=https%3A%2F%2Freadysteadycut.com%2F2021%2F05%2F14%2Frecap-love-death-and-robots-season-2-episode-1-automated-customer-service-netflix-series%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-130\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-130\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation book cs1\" id=\"CITEREFCave,_StephenDihal,_KantaDillon,_Sarah2020\">Cave, Stephen; Dihal, Kanta; Dillon, Sarah, eds. (14 February 2020). <a class=\"external text\" href=\"https://www.worldcat.org/oclc/1143647559\" rel=\"nofollow\"><i>AI narratives: a history of imaginative thinking about intelligent machines</i></a> (First ed.). Oxford. <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-0-19-258604-9\" title=\"Special:BookSources/978-0-19-258604-9\"><bdi>978-0-19-258604-9</bdi></a>. <a class=\"mw-redirect\" href=\"/wiki/OCLC_(identifier)\" title=\"OCLC (identifier)\">OCLC</a> <a class=\"external text\" href=\"//www.worldcat.org/oclc/1143647559\" rel=\"nofollow\">1143647559</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20210318060703/https://www.worldcat.org/title/ai-narratives-a-history-of-imaginative-thinking-about-intelligent-machines/oclc/1143647559\" rel=\"nofollow\">Archived</a> from the original on 18 March 2021<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">11 November</span> 2020</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=AI+narratives%3A+a+history+of+imaginative+thinking+about+intelligent+machines&amp;rft.place=Oxford&amp;rft.edition=First&amp;rft.date=2020-02-14&amp;rft_id=info%3Aoclcnum%2F1143647559&amp;rft.isbn=978-0-19-258604-9&amp;rft_id=https%3A%2F%2Fwww.worldcat.org%2Foclc%2F1143647559&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-131\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-131\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFJerreat-Poole2020\">Jerreat-Poole, Adam (1 February 2020). <a class=\"external text\" href=\"http://gamestudies.org/2001/articles/jerreatpoole\" rel=\"nofollow\">\"Sick, Slow, Cyborg: Crip Futurity in Mass Effect\"</a>. <i>Game Studies</i>. <b>20</b>. <a class=\"mw-redirect\" href=\"/wiki/ISSN_(identifier)\" title=\"ISSN (identifier)\">ISSN</a> <a class=\"external text\" href=\"//www.worldcat.org/issn/1604-7982\" rel=\"nofollow\">1604-7982</a>. <a class=\"external text\" href=\"https://web.archive.org/web/20201209080256/http://gamestudies.org/2001/articles/jerreatpoole\" rel=\"nofollow\">Archived</a> from the original on 9 December 2020<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">11 November</span> 2020</span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Game+Studies&amp;rft.atitle=Sick%2C+Slow%2C+Cyborg%3A+Crip+Futurity+in+Mass+Effect&amp;rft.volume=20&amp;rft.date=2020-02-01&amp;rft.issn=1604-7982&amp;rft.aulast=Jerreat-Poole&amp;rft.aufirst=Adam&amp;rft_id=http%3A%2F%2Fgamestudies.org%2F2001%2Farticles%2Fjerreatpoole&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-132\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-132\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation web cs1\"><a class=\"external text\" href=\"https://coffeeordie.com/detroit-become-human-will-challenge-your-morals-and-your-humanity/\" rel=\"nofollow\">\"<span class=\"cs1-kern-left\"></span>\"Detroit: Become Human\" Will Challenge your Morals and your Humanity\"</a>. <i>Coffee or Die Magazine</i>. 2018-08-06<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">2021-12-07</span></span>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Coffee+or+Die+Magazine&amp;rft.atitle=%22Detroit%3A+Become+Human%22+Will+Challenge+your+Morals+and+your+Humanity&amp;rft.date=2018-08-06&amp;rft_id=https%3A%2F%2Fcoffeeordie.com%2Fdetroit-become-human-will-challenge-your-morals-and-your-humanity%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-133\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-133\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation cs2\" id=\"CITEREFCerquiWarwick2008\">Cerqui, Daniela; Warwick, Kevin (2008), <a class=\"external text\" href=\"http://link.springer.com/10.1007/978-1-4020-6591-0_14\" rel=\"nofollow\">\"Re-Designing Humankind: The Rise of Cyborgs, a Desirable Goal?\"</a>, <i>Philosophy and Design</i>, Dordrecht: Springer Netherlands, pp. 185–195, <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1007%2F978-1-4020-6591-0_14\" rel=\"nofollow\">10.1007/978-1-4020-6591-0_14</a>, <a class=\"mw-redirect\" href=\"/wiki/ISBN_(identifier)\" title=\"ISBN (identifier)\">ISBN</a> <a href=\"/wiki/Special:BookSources/978-1-4020-6590-3\" title=\"Special:BookSources/978-1-4020-6590-3\"><bdi>978-1-4020-6590-3</bdi></a>, <a class=\"external text\" href=\"https://web.archive.org/web/20210318060701/https://link.springer.com/chapter/10.1007%2F978-1-4020-6591-0_14\" rel=\"nofollow\">archived</a> from the original on 2021-03-18<span class=\"reference-accessdate\">, retrieved <span class=\"nowrap\">2020-11-11</span></span></cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophy+and+Design&amp;rft.atitle=Re-Designing+Humankind%3A+The+Rise+of+Cyborgs%2C+a+Desirable+Goal%3F&amp;rft.pages=185-195&amp;rft.date=2008&amp;rft_id=info%3Adoi%2F10.1007%2F978-1-4020-6591-0_14&amp;rft.isbn=978-1-4020-6590-3&amp;rft.aulast=Cerqui&amp;rft.aufirst=Daniela&amp;rft.au=Warwick%2C+Kevin&amp;rft_id=http%3A%2F%2Flink.springer.com%2F10.1007%2F978-1-4020-6591-0_14&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n<li id=\"cite_note-134\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-134\">^</a></b></span> <span class=\"reference-text\"><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFCaveDihal2020\">Cave, Stephen; Dihal, Kanta (6 August 2020). \"The Whiteness of AI\". <i>Philosophy &amp; Technology</i>. <b>33</b> (4): 685–703. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1007%2Fs13347-020-00415-6\" rel=\"nofollow\">10.1007/s13347-020-00415-6</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:225466550\" rel=\"nofollow\">225466550</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophy+%26+Technology&amp;rft.atitle=The+Whiteness+of+AI&amp;rft.volume=33&amp;rft.issue=4&amp;rft.pages=685-703&amp;rft.date=2020-08-06&amp;rft_id=info%3Adoi%2F10.1007%2Fs13347-020-00415-6&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A225466550%23id-name%3DS2CID&amp;rft.aulast=Cave&amp;rft.aufirst=Stephen&amp;rft.au=Dihal%2C+Kanta&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></span>\n</li>\n</ol></div></div>\n<h2><span class=\"mw-headline\" id=\"External_links\">External links</span><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit&amp;section=26\" title=\"Edit section: External links\">edit</a><span class=\"mw-editsection-bracket\">]</span></span></h2>\n<ul><li><a class=\"external text\" href=\"http://www.iep.utm.edu/ethic-ai/\" rel=\"nofollow\">Ethics of Artificial Intelligence</a> at the <i><a href=\"/wiki/Internet_Encyclopedia_of_Philosophy\" title=\"Internet Encyclopedia of Philosophy\">Internet Encyclopedia of Philosophy</a></i></li>\n<li><a class=\"external text\" href=\"https://plato.stanford.edu/entries/ethics-ai/\" rel=\"nofollow\">Ethics of Artificial Intelligence and Robotics</a> at the <a href=\"/wiki/Stanford_Encyclopedia_of_Philosophy\" title=\"Stanford Encyclopedia of Philosophy\">Stanford Encyclopedia of Philosophy</a></li>\n<li><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFRussellHauertAltmanVeloso2015\">Russell, S.; Hauert, S.; Altman, R.; Veloso, M. (May 2015). \"Robotics: Ethics of artificial intelligence\". <i>Nature</i>. <b>521</b> (7553): 415–418. <a class=\"mw-redirect\" href=\"/wiki/Bibcode_(identifier)\" title=\"Bibcode (identifier)\">Bibcode</a>:<a class=\"external text\" href=\"https://ui.adsabs.harvard.edu/abs/2015Natur.521..415.\" rel=\"nofollow\">2015Natur.521..415.</a>. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1038%2F521415a\" rel=\"nofollow\">10.1038/521415a</a>. <a class=\"mw-redirect\" href=\"/wiki/PMID_(identifier)\" title=\"PMID (identifier)\">PMID</a> <a class=\"external text\" href=\"//pubmed.ncbi.nlm.nih.gov/26017428\" rel=\"nofollow\">26017428</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:4452826\" rel=\"nofollow\">4452826</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Nature&amp;rft.atitle=Robotics%3A+Ethics+of+artificial+intelligence&amp;rft.volume=521&amp;rft.issue=7553&amp;rft.pages=415-418&amp;rft.date=2015-05&amp;rft_id=info%3Adoi%2F10.1038%2F521415a&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A4452826%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F26017428&amp;rft_id=info%3Abibcode%2F2015Natur.521..415.&amp;rft.aulast=Russell&amp;rft.aufirst=S.&amp;rft.au=Hauert%2C+S.&amp;rft.au=Altman%2C+R.&amp;rft.au=Veloso%2C+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></li>\n<li><a class=\"external text\" href=\"http://news.bbc.co.uk/1/hi/sci/tech/1809769.stm\" rel=\"nofollow\">BBC News: Games to take on a life of their own</a></li>\n<li><a class=\"external text\" href=\"http://www.dasboot.org/thorisson.htm\" rel=\"nofollow\">Who's Afraid of Robots?</a> <a class=\"external text\" href=\"https://web.archive.org/web/20180322214031/http://www.dasboot.org/thorisson.htm\" rel=\"nofollow\">Archived</a> 2018-03-22 at the <a href=\"/wiki/Wayback_Machine\" title=\"Wayback Machine\">Wayback Machine</a>, an article on humanity's fear of artificial intelligence.</li>\n<li><a class=\"external text\" href=\"https://web.archive.org/web/20080418122849/http://www.southernct.edu/organizations/rccs/resources/research/introduction/bynum_shrt_hist.html\" rel=\"nofollow\">A short history of computer ethics</a></li>\n<li><a class=\"external text\" href=\"https://algorithmwatch.org/en/project/ai-ethics-guidelines-global-inventory/\" rel=\"nofollow\">AI Ethics Guidelines Global Inventory</a> by <a class=\"external text\" href=\"https://algorithmwatch.org\" rel=\"nofollow\">Algorithmwatch</a></li>\n<li><link href=\"mw-data:TemplateStyles:r1067248974\" rel=\"mw-deduplicated-inline-style\"/><cite class=\"citation journal cs1\" id=\"CITEREFHagendorff2020\">Hagendorff, Thilo (March 2020). \"The Ethics of AI Ethics: An Evaluation of Guidelines\". <i>Minds and Machines</i>. <b>30</b> (1): 99–120. <a class=\"mw-redirect\" href=\"/wiki/Doi_(identifier)\" title=\"Doi (identifier)\">doi</a>:<a class=\"external text\" href=\"https://doi.org/10.1007%2Fs11023-020-09517-8\" rel=\"nofollow\">10.1007/s11023-020-09517-8</a>. <a class=\"mw-redirect\" href=\"/wiki/S2CID_(identifier)\" title=\"S2CID (identifier)\">S2CID</a> <a class=\"external text\" href=\"https://api.semanticscholar.org/CorpusID:72940833\" rel=\"nofollow\">72940833</a>.</cite><span class=\"Z3988\" title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Minds+and+Machines&amp;rft.atitle=The+Ethics+of+AI+Ethics%3A+An+Evaluation+of+Guidelines&amp;rft.volume=30&amp;rft.issue=1&amp;rft.pages=99-120&amp;rft.date=2020-03&amp;rft_id=info%3Adoi%2F10.1007%2Fs11023-020-09517-8&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A72940833%23id-name%3DS2CID&amp;rft.aulast=Hagendorff&amp;rft.aufirst=Thilo&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEthics+of+artificial+intelligence\"></span></li></ul>\n<div class=\"navbox-styles nomobile\"><style data-mw-deduplicate=\"TemplateStyles:r1061467846\">.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}</style></div><div aria-labelledby=\"Ethics\" class=\"navbox\" role=\"navigation\" style=\"padding:3px\"><table class=\"nowraplinks hlist mw-collapsible autocollapse navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th class=\"navbox-title\" colspan=\"2\" scope=\"col\"><link href=\"mw-data:TemplateStyles:r1063604349\" rel=\"mw-deduplicated-inline-style\"/><div class=\"navbar plainlinks hlist navbar-mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Ethics\" title=\"Template:Ethics\"><abbr style=\";;background:none transparent;border:none;box-shadow:none;padding:0;\" title=\"View this template\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Ethics\" title=\"Template talk:Ethics\"><abbr style=\";;background:none transparent;border:none;box-shadow:none;padding:0;\" title=\"Discuss this template\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"https://en.wikipedia.org/w/index.php?title=Template:Ethics&amp;action=edit\"><abbr style=\";;background:none transparent;border:none;box-shadow:none;padding:0;\" title=\"Edit this template\">e</abbr></a></li></ul></div><div id=\"Ethics\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Ethics\" title=\"Ethics\">Ethics</a></div></th></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\"><a href=\"/wiki/Normative_ethics\" title=\"Normative ethics\">Normative ethics</a></th><td class=\"navbox-list-with-group navbox-list navbox-odd\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Consequentialism\" title=\"Consequentialism\">Consequentialism</a>\n<ul><li><a href=\"/wiki/Utilitarianism\" title=\"Utilitarianism\">Utilitarianism</a></li></ul></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Deontological_ethics\" title=\"Deontological ethics\">Deontology</a>\n<ul><li><a href=\"/wiki/Kantian_ethics\" title=\"Kantian ethics\">Kantian ethics</a></li></ul></li>\n<li><a href=\"/wiki/Ethics_of_care\" title=\"Ethics of care\">Ethics of care</a></li>\n<li><a href=\"/wiki/Existentialism\" title=\"Existentialism\">Existentialist ethics</a></li>\n<li><a href=\"/wiki/Moral_particularism\" title=\"Moral particularism\">Particularism</a></li>\n<li><a href=\"/wiki/Pragmatic_ethics\" title=\"Pragmatic ethics\">Pragmatic ethics</a></li>\n<li><a href=\"/wiki/Role_ethics\" title=\"Role ethics\">Role ethics</a></li>\n<li><a href=\"/wiki/Virtue_ethics\" title=\"Virtue ethics\">Virtue ethics</a>\n<ul><li><a href=\"/wiki/Eudaimonia\" title=\"Eudaimonia\">Eudaimonia</a></li></ul></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\"><a href=\"/wiki/Applied_ethics\" title=\"Applied ethics\">Applied ethics</a></th><td class=\"navbox-list-with-group navbox-list navbox-even\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Animal_ethics\" title=\"Animal ethics\">Animal ethics</a></li>\n<li><a href=\"/wiki/Bioethics\" title=\"Bioethics\">Bioethics</a></li>\n<li><a href=\"/wiki/Business_ethics\" title=\"Business ethics\">Business ethics</a></li>\n<li><a href=\"/wiki/Discourse_ethics\" title=\"Discourse ethics\">Discourse ethics</a></li>\n<li><a href=\"/wiki/Engineering_ethics\" title=\"Engineering ethics\">Engineering ethics</a></li>\n<li><a href=\"/wiki/Environmental_ethics\" title=\"Environmental ethics\">Environmental ethics</a></li>\n<li><a href=\"/wiki/Legal_ethics\" title=\"Legal ethics\">Legal ethics</a></li>\n<li><a href=\"/wiki/Machine_ethics\" title=\"Machine ethics\">Machine ethics</a></li>\n<li><a href=\"/wiki/Media_ethics\" title=\"Media ethics\">Media ethics</a></li>\n<li><a href=\"/wiki/Medical_ethics\" title=\"Medical ethics\">Medical ethics</a></li>\n<li><a href=\"/wiki/Nursing_ethics\" title=\"Nursing ethics\">Nursing ethics</a></li>\n<li><a href=\"/wiki/Professional_ethics\" title=\"Professional ethics\">Professional ethics</a></li>\n<li><a href=\"/wiki/Sexual_ethics\" title=\"Sexual ethics\">Sexual ethics</a></li>\n<li><a class=\"mw-selflink selflink\">Ethics of artificial intelligence</a></li>\n<li><a href=\"/wiki/Ethics_of_eating_meat\" title=\"Ethics of eating meat\">Ethics of eating meat</a></li>\n<li><a href=\"/wiki/Ethics_of_technology\" title=\"Ethics of technology\">Ethics of technology</a></li>\n<li><a href=\"/wiki/Ethics_of_terraforming\" title=\"Ethics of terraforming\">Ethics of terraforming</a></li>\n<li><a href=\"/wiki/Ethics_of_uncertain_sentience\" title=\"Ethics of uncertain sentience\">Ethics of uncertain sentience</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\"><a href=\"/wiki/Meta-ethics\" title=\"Meta-ethics\">Meta-ethics</a></th><td class=\"navbox-list-with-group navbox-list navbox-odd\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Cognitivism_(ethics)\" title=\"Cognitivism (ethics)\">Cognitivism</a>\n<ul><li><a href=\"/wiki/Moral_realism\" title=\"Moral realism\">Moral realism</a>\n<ul><li><a href=\"/wiki/Ethical_naturalism\" title=\"Ethical naturalism\">Ethical naturalism</a></li>\n<li><a href=\"/wiki/Ethical_non-naturalism\" title=\"Ethical non-naturalism\">Ethical non-naturalism</a></li></ul></li>\n<li><a href=\"/wiki/Ethical_subjectivism\" title=\"Ethical subjectivism\">Ethical subjectivism</a>\n<ul><li><a href=\"/wiki/Ideal_observer_theory\" title=\"Ideal observer theory\">Ideal observer theory</a></li>\n<li><a href=\"/wiki/Divine_command_theory\" title=\"Divine command theory\">Divine command theory</a></li></ul></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Error_theory\" title=\"Error theory\">Error theory</a></li></ul></li>\n<li><a href=\"/wiki/Non-cognitivism\" title=\"Non-cognitivism\">Non-cognitivism</a>\n<ul><li><a href=\"/wiki/Emotivism\" title=\"Emotivism\">Emotivism</a></li>\n<li><a href=\"/wiki/Expressivism\" title=\"Expressivism\">Expressivism</a></li>\n<li><a href=\"/wiki/Quasi-realism\" title=\"Quasi-realism\">Quasi-realism</a></li>\n<li><a href=\"/wiki/Universal_prescriptivism\" title=\"Universal prescriptivism\">Universal prescriptivism</a></li></ul></li>\n<li><a href=\"/wiki/Moral_universalism\" title=\"Moral universalism\">Moral universalism</a>\n<ul><li><a href=\"/wiki/Value_pluralism\" title=\"Value pluralism\">Value monism – Value pluralism</a></li></ul></li>\n<li><a href=\"/wiki/Moral_constructivism\" title=\"Moral constructivism\">Moral constructivism</a></li>\n<li><a href=\"/wiki/Moral_relativism\" title=\"Moral relativism\">Moral relativism</a></li>\n<li><a href=\"/wiki/Moral_nihilism\" title=\"Moral nihilism\">Moral nihilism</a></li>\n<li><a href=\"/wiki/Moral_rationalism\" title=\"Moral rationalism\">Moral rationalism</a></li>\n<li><a href=\"/wiki/Ethical_intuitionism\" title=\"Ethical intuitionism\">Ethical intuitionism</a></li>\n<li><a href=\"/wiki/Moral_skepticism\" title=\"Moral skepticism\">Moral skepticism</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">Concepts <br/> (<a href=\"/wiki/Index_of_ethics_articles\" title=\"Index of ethics articles\">index</a>)</th><td class=\"navbox-list-with-group navbox-list navbox-even\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Autonomy\" title=\"Autonomy\">Autonomy</a></li>\n<li><a href=\"/wiki/Axiology\" title=\"Axiology\">Axiology</a></li>\n<li><a href=\"/wiki/Conscience\" title=\"Conscience\">Conscience</a></li>\n<li><a href=\"/wiki/Consent\" title=\"Consent\">Consent</a></li>\n<li><a href=\"/wiki/Egalitarianism\" title=\"Egalitarianism\">Equality</a></li>\n<li><a href=\"/wiki/Free_will\" title=\"Free will\">Free will</a></li>\n<li><a href=\"/wiki/Good_and_evil\" title=\"Good and evil\">Good and evil</a>\n<ul><li><a href=\"/wiki/Good\" title=\"Good\">Good</a></li>\n<li><a href=\"/wiki/Evil\" title=\"Evil\">Evil</a></li></ul></li>\n<li><a href=\"/wiki/Happiness\" title=\"Happiness\">Happiness</a></li>\n<li><a href=\"/wiki/Ideal_(ethics)\" title=\"Ideal (ethics)\">Ideal</a></li>\n<li><a href=\"/wiki/Immorality\" title=\"Immorality\">Immorality</a></li>\n<li><a href=\"/wiki/Justice\" title=\"Justice\">Justice</a></li>\n<li><a href=\"/wiki/Liberty\" title=\"Liberty\">Liberty</a></li>\n<li><a href=\"/wiki/Morality\" title=\"Morality\">Morality</a></li>\n<li><a href=\"/wiki/Norm_(philosophy)\" title=\"Norm (philosophy)\">Norm</a></li>\n<li><a href=\"/wiki/Political_freedom\" title=\"Political freedom\">Freedom</a></li>\n<li><a href=\"/wiki/Suffering\" title=\"Suffering\">Suffering or Pain</a></li>\n<li><a href=\"/wiki/Stewardship\" title=\"Stewardship\">Stewardship</a></li>\n<li><a href=\"/wiki/Sympathy\" title=\"Sympathy\">Sympathy</a></li>\n<li><a href=\"/wiki/Trust_(social_science)\" title=\"Trust (social science)\">Trust</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Value_(ethics)\" title=\"Value (ethics)\">Value</a></li>\n<li><a href=\"/wiki/Virtue\" title=\"Virtue\">Virtue</a></li>\n<li><a href=\"/wiki/Wrongdoing\" title=\"Wrongdoing\">Wrong</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\"><a href=\"/wiki/List_of_ethicists\" title=\"List of ethicists\">Ethicist<br/> philosophers</a></th><td class=\"navbox-list-with-group navbox-list navbox-odd\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Laozi\" title=\"Laozi\">Laozi</a></li>\n<li><a href=\"/wiki/Socrates\" title=\"Socrates\">Socrates</a></li>\n<li><a href=\"/wiki/Plato\" title=\"Plato\">Plato</a></li>\n<li><a href=\"/wiki/Aristotle\" title=\"Aristotle\">Aristotle</a></li>\n<li><a href=\"/wiki/Diogenes\" title=\"Diogenes\">Diogenes</a></li>\n<li><a href=\"/wiki/Thiruvalluvar\" title=\"Thiruvalluvar\">Valluvar</a></li>\n<li><a href=\"/wiki/Cicero\" title=\"Cicero\">Cicero</a></li>\n<li><a href=\"/wiki/Confucius\" title=\"Confucius\">Confucius</a></li>\n<li><a href=\"/wiki/Augustine_of_Hippo\" title=\"Augustine of Hippo\">Augustine of Hippo</a></li>\n<li><a href=\"/wiki/Mencius\" title=\"Mencius\">Mencius</a></li>\n<li><a href=\"/wiki/Mozi\" title=\"Mozi\">Mozi</a></li>\n<li><a href=\"/wiki/Xun_Kuang\" title=\"Xun Kuang\">Xunzi</a></li>\n<li><a href=\"/wiki/Thomas_Aquinas\" title=\"Thomas Aquinas\">Thomas Aquinas</a></li>\n<li><a href=\"/wiki/Baruch_Spinoza\" title=\"Baruch Spinoza\">Baruch Spinoza</a></li>\n<li><a href=\"/wiki/David_Hume\" title=\"David Hume\">David Hume</a></li>\n<li><a href=\"/wiki/Immanuel_Kant\" title=\"Immanuel Kant\">Immanuel Kant</a></li>\n<li><a href=\"/wiki/Georg_Wilhelm_Friedrich_Hegel\" title=\"Georg Wilhelm Friedrich Hegel\">Georg W. F. Hegel</a></li>\n<li><a href=\"/wiki/Arthur_Schopenhauer\" title=\"Arthur Schopenhauer\">Arthur Schopenhauer</a></li>\n<li><a href=\"/wiki/Jeremy_Bentham\" title=\"Jeremy Bentham\">Jeremy Bentham</a></li>\n<li><a href=\"/wiki/John_Stuart_Mill\" title=\"John Stuart Mill\">John Stuart Mill</a></li>\n<li><a href=\"/wiki/S%C3%B8ren_Kierkegaard\" title=\"Søren Kierkegaard\">Søren Kierkegaard</a></li>\n<li><a href=\"/wiki/Henry_Sidgwick\" title=\"Henry Sidgwick\">Henry Sidgwick</a></li>\n<li><a href=\"/wiki/Friedrich_Nietzsche\" title=\"Friedrich Nietzsche\">Friedrich Nietzsche</a></li>\n<li><a href=\"/wiki/G._E._Moore\" title=\"G. E. Moore\">G. E. Moore</a></li>\n<li><a href=\"/wiki/Karl_Barth\" title=\"Karl Barth\">Karl Barth</a></li>\n<li><a href=\"/wiki/Paul_Tillich\" title=\"Paul Tillich\">Paul Tillich</a></li>\n<li><a href=\"/wiki/Dietrich_Bonhoeffer\" title=\"Dietrich Bonhoeffer\">Dietrich Bonhoeffer</a></li>\n<li><a href=\"/wiki/Philippa_Foot\" title=\"Philippa Foot\">Philippa Foot</a></li>\n<li><a href=\"/wiki/John_Rawls\" title=\"John Rawls\">John Rawls</a></li>\n<li><a href=\"/wiki/John_Dewey\" title=\"John Dewey\">John Dewey</a></li>\n<li><a href=\"/wiki/Bernard_Williams\" title=\"Bernard Williams\">Bernard Williams</a></li>\n<li><a href=\"/wiki/J._L._Mackie\" title=\"J. L. Mackie\">J. L. Mackie</a></li>\n<li><a href=\"/wiki/G._E._M._Anscombe\" title=\"G. E. M. Anscombe\">G. E. M. Anscombe</a></li>\n<li><a href=\"/wiki/William_Frankena\" title=\"William Frankena\">William Frankena</a></li>\n<li><a href=\"/wiki/Alasdair_MacIntyre\" title=\"Alasdair MacIntyre\">Alasdair MacIntyre</a></li>\n<li><a href=\"/wiki/R._M._Hare\" title=\"R. M. Hare\">R. M. Hare</a></li>\n<li><a href=\"/wiki/Peter_Singer\" title=\"Peter Singer\">Peter Singer</a></li>\n<li><a href=\"/wiki/Derek_Parfit\" title=\"Derek Parfit\">Derek Parfit</a></li>\n<li><a href=\"/wiki/Thomas_Nagel\" title=\"Thomas Nagel\">Thomas Nagel</a></li>\n<li><a href=\"/wiki/Robert_Merrihew_Adams\" title=\"Robert Merrihew Adams\">Robert Merrihew Adams</a></li>\n<li><a href=\"/wiki/Charles_Taylor_(philosopher)\" title=\"Charles Taylor (philosopher)\">Charles Taylor</a></li>\n<li><a href=\"/wiki/Joxe_Azurmendi\" title=\"Joxe Azurmendi\">Joxe Azurmendi</a></li>\n<li><a href=\"/wiki/Christine_Korsgaard\" title=\"Christine Korsgaard\">Christine Korsgaard</a></li>\n<li><a href=\"/wiki/Martha_Nussbaum\" title=\"Martha Nussbaum\">Martha Nussbaum</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">Related articles</th><td class=\"navbox-list-with-group navbox-list navbox-even\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Casuistry\" title=\"Casuistry\">Casuistry</a></li>\n<li><a href=\"/wiki/Christian_ethics\" title=\"Christian ethics\">Christian ethics</a></li>\n<li><a href=\"/wiki/Descriptive_ethics\" title=\"Descriptive ethics\">Descriptive ethics</a></li>\n<li><a href=\"/wiki/Ethics_in_religion\" title=\"Ethics in religion\">Ethics in religion</a></li>\n<li><a href=\"/wiki/Evolutionary_ethics\" title=\"Evolutionary ethics\">Evolutionary ethics</a></li>\n<li><a href=\"/wiki/Feminist_ethics\" title=\"Feminist ethics\">Feminist ethics</a></li>\n<li><a href=\"/wiki/History_of_ethics\" title=\"History of ethics\">History of ethics</a></li>\n<li><a href=\"/wiki/Ideology\" title=\"Ideology\">Ideology</a></li>\n<li><a href=\"/wiki/Islamic_ethics\" title=\"Islamic ethics\">Islamic ethics</a></li>\n<li><a href=\"/wiki/Jewish_ethics\" title=\"Jewish ethics\">Jewish ethics</a></li>\n<li><a href=\"/wiki/Moral_psychology\" title=\"Moral psychology\">Moral psychology</a></li>\n<li><a href=\"/wiki/Philosophy_of_law\" title=\"Philosophy of law\">Philosophy of law</a></li>\n<li><a href=\"/wiki/Political_philosophy\" title=\"Political philosophy\">Political philosophy</a></li>\n<li><a href=\"/wiki/Population_ethics\" title=\"Population ethics\">Population ethics</a></li>\n<li><a href=\"/wiki/Social_philosophy\" title=\"Social philosophy\">Social philosophy</a></li>\n<li><a href=\"/wiki/Suffering-focused_ethics\" title=\"Suffering-focused ethics\">Suffering-focused ethics</a></li></ul>\n</div></td></tr><tr><td class=\"navbox-abovebelow\" colspan=\"2\"><div>\n<ul><li><img alt=\"\" class=\"noviewer\" data-file-height=\"185\" data-file-width=\"180\" decoding=\"async\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/16px-Symbol_category_class.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/23px-Symbol_category_class.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/31px-Symbol_category_class.svg.png 2x\" title=\"Category\" width=\"16\"/> <a href=\"/wiki/Category:Ethics\" title=\"Category:Ethics\">Category</a></li></ul>\n</div></td></tr></tbody></table></div>\n<div class=\"navbox-styles nomobile\"><link href=\"mw-data:TemplateStyles:r1061467846\" rel=\"mw-deduplicated-inline-style\"/></div><div aria-labelledby=\"Existential_risk_from_artificial_intelligence\" class=\"navbox\" role=\"navigation\" style=\"padding:3px\"><table class=\"nowraplinks mw-collapsible autocollapse navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th class=\"navbox-title\" colspan=\"2\" scope=\"col\"><link href=\"mw-data:TemplateStyles:r1063604349\" rel=\"mw-deduplicated-inline-style\"/><div class=\"navbar plainlinks hlist navbar-mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Existential_risk_from_artificial_intelligence\" title=\"Template:Existential risk from artificial intelligence\"><abbr style=\";;background:none transparent;border:none;box-shadow:none;padding:0;\" title=\"View this template\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Existential_risk_from_artificial_intelligence\" title=\"Template talk:Existential risk from artificial intelligence\"><abbr style=\";;background:none transparent;border:none;box-shadow:none;padding:0;\" title=\"Discuss this template\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"https://en.wikipedia.org/w/index.php?title=Template:Existential_risk_from_artificial_intelligence&amp;action=edit\"><abbr style=\";;background:none transparent;border:none;box-shadow:none;padding:0;\" title=\"Edit this template\">e</abbr></a></li></ul></div><div id=\"Existential_risk_from_artificial_intelligence\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">Existential risk</a> from <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a></div></th></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">Concepts</th><td class=\"navbox-list-with-group navbox-list navbox-odd hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/AI_alignment\" title=\"AI alignment\">AI alignment</a></li>\n<li><a href=\"/wiki/AI_capability_control\" title=\"AI capability control\">AI capability control</a></li>\n<li><a href=\"/wiki/AI_takeover\" title=\"AI takeover\">AI takeover</a></li>\n<li><a href=\"/wiki/Accelerating_change\" title=\"Accelerating change\">Accelerating change</a></li>\n<li><a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">Existential risk from artificial general intelligence</a></li>\n<li><a href=\"/wiki/Friendly_artificial_intelligence\" title=\"Friendly artificial intelligence\">Friendly artificial intelligence</a></li>\n<li><a href=\"/wiki/Instrumental_convergence\" title=\"Instrumental convergence\">Instrumental convergence</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Intelligence_explosion\" title=\"Intelligence explosion\">Intelligence explosion</a></li>\n<li><a href=\"/wiki/Machine_ethics\" title=\"Machine ethics\">Machine ethics</a></li>\n<li><a href=\"/wiki/Superintelligence\" title=\"Superintelligence\">Superintelligence</a></li>\n<li><a href=\"/wiki/Technological_singularity\" title=\"Technological singularity\">Technological singularity</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">Organizations</th><td class=\"navbox-list-with-group navbox-list navbox-even hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Allen_Institute_for_AI\" title=\"Allen Institute for AI\">Allen Institute for AI</a></li>\n<li><a href=\"/wiki/Center_for_Applied_Rationality\" title=\"Center for Applied Rationality\">Center for Applied Rationality</a></li>\n<li><a href=\"/wiki/Center_for_Human-Compatible_Artificial_Intelligence\" title=\"Center for Human-Compatible Artificial Intelligence\">Center for Human-Compatible Artificial Intelligence</a></li>\n<li><a href=\"/wiki/Centre_for_the_Study_of_Existential_Risk\" title=\"Centre for the Study of Existential Risk\">Centre for the Study of Existential Risk</a></li>\n<li><a href=\"/wiki/DeepMind\" title=\"DeepMind\">DeepMind</a></li>\n<li><a href=\"/wiki/Foundational_Questions_Institute\" title=\"Foundational Questions Institute\">Foundational Questions Institute</a></li>\n<li><a href=\"/wiki/Future_of_Humanity_Institute\" title=\"Future of Humanity Institute\">Future of Humanity Institute</a></li>\n<li><a href=\"/wiki/Future_of_Life_Institute\" title=\"Future of Life Institute\">Future of Life Institute</a></li>\n<li><a href=\"/wiki/Humanity%2B\" title=\"Humanity+\">Humanity+</a></li>\n<li><a href=\"/wiki/Institute_for_Ethics_and_Emerging_Technologies\" title=\"Institute for Ethics and Emerging Technologies\">Institute for Ethics and Emerging Technologies</a></li>\n<li><a href=\"/wiki/Leverhulme_Centre_for_the_Future_of_Intelligence\" title=\"Leverhulme Centre for the Future of Intelligence\">Leverhulme Centre for the Future of Intelligence</a></li>\n<li><a href=\"/wiki/Machine_Intelligence_Research_Institute\" title=\"Machine Intelligence Research Institute\">Machine Intelligence Research Institute</a></li>\n<li><a href=\"/wiki/OpenAI\" title=\"OpenAI\">OpenAI</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">People</th><td class=\"navbox-list-with-group navbox-list navbox-odd hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Slate_Star_Codex\" title=\"Slate Star Codex\">Scott Alexander</a></li>\n<li><a href=\"/wiki/Nick_Bostrom\" title=\"Nick Bostrom\">Nick Bostrom</a></li>\n<li><a href=\"/wiki/K._Eric_Drexler\" title=\"K. Eric Drexler\">Eric Drexler</a></li>\n<li><a href=\"/wiki/Sam_Harris\" title=\"Sam Harris\">Sam Harris</a></li>\n<li><a href=\"/wiki/Stephen_Hawking\" title=\"Stephen Hawking\">Stephen Hawking</a></li>\n<li><a href=\"/wiki/Bill_Hibbard\" title=\"Bill Hibbard\">Bill Hibbard</a></li>\n<li><a href=\"/wiki/Bill_Joy\" title=\"Bill Joy\">Bill Joy</a></li>\n<li><a href=\"/wiki/Elon_Musk\" title=\"Elon Musk\">Elon Musk</a></li>\n<li><a href=\"/wiki/Steve_Omohundro\" title=\"Steve Omohundro\">Steve Omohundro</a></li>\n<li><a href=\"/wiki/Huw_Price\" title=\"Huw Price\">Huw Price</a></li>\n<li><a href=\"/wiki/Martin_Rees\" title=\"Martin Rees\">Martin Rees</a></li>\n<li><a href=\"/wiki/Stuart_J._Russell\" title=\"Stuart J. Russell\">Stuart J. Russell</a></li>\n<li><a href=\"/wiki/Jaan_Tallinn\" title=\"Jaan Tallinn\">Jaan Tallinn</a></li>\n<li><a href=\"/wiki/Max_Tegmark\" title=\"Max Tegmark\">Max Tegmark</a></li>\n<li><a href=\"/wiki/Frank_Wilczek\" title=\"Frank Wilczek\">Frank Wilczek</a></li>\n<li><a href=\"/wiki/Roman_Yampolskiy\" title=\"Roman Yampolskiy\">Roman Yampolskiy</a></li>\n<li><a href=\"/wiki/Andrew_Yang\" title=\"Andrew Yang\">Andrew Yang</a></li>\n<li><a href=\"/wiki/Eliezer_Yudkowsky\" title=\"Eliezer Yudkowsky\">Eliezer Yudkowsky</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:1%\">Other</th><td class=\"navbox-list-with-group navbox-list navbox-even hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Global_catastrophic_risk#Artificial_intelligence\" title=\"Global catastrophic risk\">Artificial intelligence as a global catastrophic risk</a></li>\n<li><a href=\"/wiki/Artificial_general_intelligence#Controversies_and_dangers\" title=\"Artificial general intelligence\">Controversies and dangers of artificial general intelligence</a></li>\n<li><a class=\"mw-selflink selflink\">Ethics of artificial intelligence</a></li>\n<li><a href=\"/wiki/Suffering_risks\" title=\"Suffering risks\">Suffering risks</a></li>\n<li><i><a href=\"/wiki/Human_Compatible\" title=\"Human Compatible\">Human Compatible</a></i></li>\n<li><a href=\"/wiki/Open_Letter_on_Artificial_Intelligence\" title=\"Open Letter on Artificial Intelligence\">Open Letter on Artificial Intelligence</a></li>\n<li><i><a href=\"/wiki/Our_Final_Invention\" title=\"Our Final Invention\">Our Final Invention</a></i></li>\n<li><i><a href=\"/wiki/The_Precipice:_Existential_Risk_and_the_Future_of_Humanity\" title=\"The Precipice: Existential Risk and the Future of Humanity\">The Precipice</a></i></li>\n<li><i><a href=\"/wiki/Superintelligence:_Paths,_Dangers,_Strategies\" title=\"Superintelligence: Paths, Dangers, Strategies\">Superintelligence: Paths, Dangers, Strategies</a></i></li>\n<li><i><a href=\"/wiki/Do_You_Trust_This_Computer%3F\" title=\"Do You Trust This Computer?\">Do You Trust This Computer?</a></i></li></ul>\n</div></td></tr><tr><td class=\"navbox-abovebelow\" colspan=\"2\"><div><img alt=\"\" class=\"noviewer\" data-file-height=\"185\" data-file-width=\"180\" decoding=\"async\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/16px-Symbol_category_class.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/23px-Symbol_category_class.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/31px-Symbol_category_class.svg.png 2x\" title=\"Category\" width=\"16\"/> <a href=\"/wiki/Category:Existential_risk_from_artificial_general_intelligence\" title=\"Category:Existential risk from artificial general intelligence\">Category</a></div></td></tr></tbody></table></div>\n<div class=\"navbox-styles nomobile\"><link href=\"mw-data:TemplateStyles:r1061467846\" rel=\"mw-deduplicated-inline-style\"/></div><div aria-labelledby=\"Philosophy_of_science\" class=\"navbox\" role=\"navigation\" style=\"padding:3px\"><table class=\"nowraplinks hlist mw-collapsible autocollapse navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th class=\"navbox-title\" colspan=\"2\" scope=\"col\"><link href=\"mw-data:TemplateStyles:r1063604349\" rel=\"mw-deduplicated-inline-style\"/><div class=\"navbar plainlinks hlist navbar-mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Philosophy_of_science\" title=\"Template:Philosophy of science\"><abbr style=\";;background:none transparent;border:none;box-shadow:none;padding:0;\" title=\"View this template\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Philosophy_of_science\" title=\"Template talk:Philosophy of science\"><abbr style=\";;background:none transparent;border:none;box-shadow:none;padding:0;\" title=\"Discuss this template\">t</abbr></a></li><li class=\"nv-edit\"><a class=\"external text\" href=\"https://en.wikipedia.org/w/index.php?title=Template:Philosophy_of_science&amp;action=edit\"><abbr style=\";;background:none transparent;border:none;box-shadow:none;padding:0;\" title=\"Edit this template\">e</abbr></a></li></ul></div><div id=\"Philosophy_of_science\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Philosophy_of_science\" title=\"Philosophy of science\">Philosophy of science</a></div></th></tr><tr><td class=\"navbox-list navbox-odd\" colspan=\"2\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:7.5em\">Concepts</th><td class=\"navbox-list-with-group navbox-list navbox-odd\" style=\"padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Philosophical_analysis\" title=\"Philosophical analysis\">Analysis</a></li>\n<li><a href=\"/wiki/Analytic%E2%80%93synthetic_distinction\" title=\"Analytic–synthetic distinction\">Analytic–synthetic distinction</a></li>\n<li><a href=\"/wiki/A_priori_and_a_posteriori\" title=\"A priori and a posteriori\"><i>A priori</i> and <i>a posteriori</i></a></li>\n<li><a href=\"/wiki/Causality\" title=\"Causality\">Causality</a></li>\n<li><a href=\"/wiki/Commensurability_(philosophy_of_science)\" title=\"Commensurability (philosophy of science)\">Commensurability</a></li>\n<li><a href=\"/wiki/Consilience\" title=\"Consilience\">Consilience</a></li>\n<li><a href=\"/wiki/Construct_(philosophy)\" title=\"Construct (philosophy)\">Construct</a></li>\n<li><a href=\"/wiki/Creative_synthesis\" title=\"Creative synthesis\">Creative synthesis</a></li>\n<li><a href=\"/wiki/Demarcation_problem\" title=\"Demarcation problem\">Demarcation problem</a></li>\n<li><a href=\"/wiki/Empirical_evidence\" title=\"Empirical evidence\">Empirical evidence</a></li>\n<li><a href=\"/wiki/Explanatory_power\" title=\"Explanatory power\">Explanatory power</a></li>\n<li><a href=\"/wiki/Fact\" title=\"Fact\">Fact</a></li>\n<li><a href=\"/wiki/Falsifiability\" title=\"Falsifiability\">Falsifiability</a></li>\n<li><a href=\"/wiki/Feminist_method\" title=\"Feminist method\">Feminist method</a></li>\n<li><a href=\"/wiki/Functional_contextualism\" title=\"Functional contextualism\">Functional contextualism</a></li></ul>\n<ul><li><i><a href=\"/wiki/Ignoramus_et_ignorabimus\" title=\"Ignoramus et ignorabimus\">Ignoramus et ignorabimus</a></i></li>\n<li><a href=\"/wiki/Inductive_reasoning\" title=\"Inductive reasoning\">Inductive reasoning</a></li>\n<li><a href=\"/wiki/Intertheoretic_reduction\" title=\"Intertheoretic reduction\">Intertheoretic reduction</a></li>\n<li><a href=\"/wiki/Inquiry\" title=\"Inquiry\">Inquiry</a></li>\n<li><a href=\"/wiki/Nature_(philosophy)\" title=\"Nature (philosophy)\">Nature</a></li>\n<li><a href=\"/wiki/Objectivity_(philosophy)\" title=\"Objectivity (philosophy)\">Objectivity</a></li>\n<li><a href=\"/wiki/Observation\" title=\"Observation\">Observation</a></li>\n<li><a href=\"/wiki/Paradigm\" title=\"Paradigm\">Paradigm</a></li>\n<li><a href=\"/wiki/Problem_of_induction\" title=\"Problem of induction\">Problem of induction</a></li>\n<li><a href=\"/wiki/Scientific_law\" title=\"Scientific law\">Scientific law</a></li>\n<li><a href=\"/wiki/Scientific_method\" title=\"Scientific method\">Scientific method</a></li>\n<li><a href=\"/wiki/Scientific_pluralism\" title=\"Scientific pluralism\">Scientific pluralism</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Scientific_revolution\" title=\"Scientific revolution\">Scientific revolution</a></li>\n<li><a href=\"/wiki/Scientific_theory\" title=\"Scientific theory\">Scientific theory</a></li>\n<li><a href=\"/wiki/Testability\" title=\"Testability\">Testability</a></li>\n<li><a href=\"/wiki/Theory_choice\" title=\"Theory choice\">Theory choice</a></li>\n<li><a href=\"/wiki/Theory-ladenness\" title=\"Theory-ladenness\">Theory-ladenness</a></li>\n<li><a href=\"/wiki/Underdetermination\" title=\"Underdetermination\">Underdetermination</a></li>\n<li><a href=\"/wiki/Unity_of_science\" title=\"Unity of science\">Unity of science</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:7.5em\"><a href=\"/wiki/Category:Metatheory_of_science\" title=\"Category:Metatheory of science\">Metatheory<br/>of science</a></th><td class=\"navbox-list-with-group navbox-list navbox-even\" style=\"padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Coherentism\" title=\"Coherentism\">Coherentism</a></li>\n<li><a href=\"/wiki/Confirmation_holism\" title=\"Confirmation holism\">Confirmation holism</a></li>\n<li><a href=\"/wiki/Constructive_empiricism\" title=\"Constructive empiricism\">Constructive empiricism</a></li>\n<li><a href=\"/wiki/Constructive_realism\" title=\"Constructive realism\">Constructive realism</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Constructivist_epistemology\" title=\"Constructivist epistemology\">Constructivist epistemology</a></li>\n<li><a href=\"/wiki/Contextualism\" title=\"Contextualism\">Contextualism</a></li>\n<li><a href=\"/wiki/Conventionalism\" title=\"Conventionalism\">Conventionalism</a></li>\n<li><a href=\"/wiki/Deductive-nomological_model\" title=\"Deductive-nomological model\">Deductive-nomological model</a></li>\n<li><a href=\"/wiki/Hypothetico-deductive_model\" title=\"Hypothetico-deductive model\">Hypothetico-deductive model</a></li>\n<li><a href=\"/wiki/Inductionism\" title=\"Inductionism\">Inductionism</a></li>\n<li><a class=\"mw-redirect\" href=\"/wiki/Epistemological_anarchism\" title=\"Epistemological anarchism\">Epistemological anarchism</a></li>\n<li><a href=\"/wiki/Evolutionism\" title=\"Evolutionism\">Evolutionism</a></li>\n<li><a href=\"/wiki/Fallibilism\" title=\"Fallibilism\">Fallibilism</a></li>\n<li><a href=\"/wiki/Foundationalism\" title=\"Foundationalism\">Foundationalism</a></li>\n<li><a href=\"/wiki/Instrumentalism\" title=\"Instrumentalism\">Instrumentalism</a></li>\n<li><a href=\"/wiki/Pragmatism\" title=\"Pragmatism\">Pragmatism</a></li>\n<li><a href=\"/wiki/Model-dependent_realism\" title=\"Model-dependent realism\">Model-dependent realism</a></li>\n<li><a href=\"/wiki/Naturalism_(philosophy)\" title=\"Naturalism (philosophy)\">Naturalism</a></li>\n<li><a href=\"/wiki/Physicalism\" title=\"Physicalism\">Physicalism</a></li>\n<li><a href=\"/wiki/Positivism\" title=\"Positivism\">Positivism</a> / <a href=\"/wiki/Reductionism\" title=\"Reductionism\">Reductionism</a> / <a href=\"/wiki/Determinism\" title=\"Determinism\">Determinism</a></li>\n<li><a href=\"/wiki/Rationalism\" title=\"Rationalism\">Rationalism</a> / <a href=\"/wiki/Empiricism\" title=\"Empiricism\">Empiricism</a></li>\n<li><a href=\"/wiki/Received_view_of_theories\" title=\"Received view of theories\">Received view</a> / <a href=\"/wiki/Semantic_view_of_theories\" title=\"Semantic view of theories\">Semantic view of theories</a></li>\n<li><a href=\"/wiki/Scientific_realism\" title=\"Scientific realism\">Scientific realism</a> / <a href=\"/wiki/Anti-realism\" title=\"Anti-realism\">Anti-realism</a></li>\n<li><a href=\"/wiki/Scientific_essentialism\" title=\"Scientific essentialism\">Scientific essentialism</a></li>\n<li><a href=\"/wiki/Scientific_formalism\" title=\"Scientific formalism\">Scientific formalism</a></li>\n<li><a href=\"/wiki/Scientific_skepticism\" title=\"Scientific skepticism\">Scientific skepticism</a></li>\n<li><a href=\"/wiki/Scientism\" title=\"Scientism\">Scientism</a></li>\n<li><a href=\"/wiki/Structuralism_(philosophy_of_science)\" title=\"Structuralism (philosophy of science)\">Structuralism</a></li>\n<li><a href=\"/wiki/Uniformitarianism\" title=\"Uniformitarianism\">Uniformitarianism</a></li>\n<li><a href=\"/wiki/Vitalism\" title=\"Vitalism\">Vitalism</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:7.5em\">Philosophy of</th><td class=\"navbox-list-with-group navbox-list navbox-odd\" style=\"padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Philosophy_of_physics\" title=\"Philosophy of physics\">Physics</a>\n<ul><li><a href=\"/wiki/Philosophy_of_thermal_and_statistical_physics\" title=\"Philosophy of thermal and statistical physics\">thermal and statistical</a></li>\n<li><a href=\"/wiki/Philosophy_of_motion\" title=\"Philosophy of motion\">Motion</a></li></ul></li>\n<li><a href=\"/wiki/Philosophy_of_chemistry\" title=\"Philosophy of chemistry\">Chemistry</a></li>\n<li><a href=\"/wiki/Philosophy_of_biology\" title=\"Philosophy of biology\">Biology</a></li>\n<li><a href=\"/wiki/Philosophy_of_geography\" title=\"Philosophy of geography\">Geography</a></li>\n<li><a href=\"/wiki/Philosophy_of_social_science\" title=\"Philosophy of social science\">Social science</a></li>\n<li><a href=\"/wiki/Philosophy_of_technology\" title=\"Philosophy of technology\">Technology</a>\n<ul><li><a href=\"/wiki/Philosophy_of_engineering\" title=\"Philosophy of engineering\">Engineering</a></li>\n<li><a href=\"/wiki/Philosophy_of_artificial_intelligence\" title=\"Philosophy of artificial intelligence\">Artificial intelligence</a></li>\n<li><a href=\"/wiki/Philosophy_of_computer_science\" title=\"Philosophy of computer science\">Computer science</a></li></ul></li>\n<li><a href=\"/wiki/Philosophy_of_information\" title=\"Philosophy of information\">Information</a></li>\n<li><a href=\"/wiki/Philosophy_of_mind\" title=\"Philosophy of mind\">Mind</a></li>\n<li><a href=\"/wiki/Philosophy_of_psychiatry\" title=\"Philosophy of psychiatry\">Psychiatry</a></li>\n<li><a href=\"/wiki/Philosophy_of_psychology\" title=\"Philosophy of psychology\">Psychology</a></li>\n<li><a href=\"/wiki/Philosophy_of_perception\" title=\"Philosophy of perception\">Perception</a></li>\n<li><a href=\"/wiki/Philosophy_of_space_and_time\" title=\"Philosophy of space and time\">Space and time</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:7.5em\"><a href=\"/wiki/Index_of_philosophy_of_science_articles\" title=\"Index of philosophy of science articles\">Related topics</a></th><td class=\"navbox-list-with-group navbox-list navbox-even\" style=\"padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Alchemy\" title=\"Alchemy\">Alchemy</a></li>\n<li><a href=\"/wiki/Criticism_of_science\" title=\"Criticism of science\">Criticism of science</a></li>\n<li><a href=\"/wiki/Descriptive_research\" title=\"Descriptive research\">Descriptive science</a></li>\n<li><a href=\"/wiki/Epistemology\" title=\"Epistemology\">Epistemology</a></li>\n<li><a href=\"/wiki/Faith_and_rationality\" title=\"Faith and rationality\">Faith and rationality</a></li>\n<li><a href=\"/wiki/Hard_and_soft_science\" title=\"Hard and soft science\">Hard and soft science</a></li>\n<li><a href=\"/wiki/History_and_philosophy_of_science\" title=\"History and philosophy of science\">History and philosophy of science</a></li>\n<li><a href=\"/wiki/History_of_science\" title=\"History of science\">History of science</a></li>\n<li><a href=\"/wiki/History_of_evolutionary_thought\" title=\"History of evolutionary thought\">History of evolutionary thought</a></li>\n<li><a href=\"/wiki/Logic\" title=\"Logic\">Logic</a></li>\n<li><a href=\"/wiki/Metaphysics\" title=\"Metaphysics\">Metaphysics</a></li>\n<li><a href=\"/wiki/Normative_science\" title=\"Normative science\">Normative science</a></li>\n<li><a href=\"/wiki/Pseudoscience\" title=\"Pseudoscience\">Pseudoscience</a></li>\n<li><a href=\"/wiki/Relationship_between_religion_and_science\" title=\"Relationship between religion and science\">Relationship between religion and science</a></li>\n<li><a href=\"/wiki/Rhetoric_of_science\" title=\"Rhetoric of science\">Rhetoric of science</a></li>\n<li><a href=\"/wiki/Science_studies\" title=\"Science studies\">Science studies</a></li>\n<li><a href=\"/wiki/Sociology_of_scientific_knowledge\" title=\"Sociology of scientific knowledge\">Sociology of scientific knowledge</a></li>\n<li><a href=\"/wiki/Sociology_of_scientific_ignorance\" title=\"Sociology of scientific ignorance\">Sociology of scientific ignorance</a></li></ul>\n</div></td></tr></tbody></table><div></div></td></tr><tr><td class=\"navbox-list navbox-odd\" colspan=\"2\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\"></div><table class=\"nowraplinks mw-collapsible mw-collapsed navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th class=\"navbox-title\" colspan=\"2\" scope=\"col\"><div id=\"Philosophers_of_science_by_era\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/List_of_philosophers_of_science\" title=\"List of philosophers of science\">Philosophers of science</a> by era</div></th></tr><tr><td class=\"navbox-list navbox-odd\" colspan=\"2\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\"></div><table class=\"nowraplinks navbox-subgroup\" style=\"border-spacing:0\"><tbody><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:7.5em\">Ancient</th><td class=\"navbox-list-with-group navbox-list navbox-odd\" style=\"padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Plato\" title=\"Plato\">Plato</a></li>\n<li><a href=\"/wiki/Aristotle\" title=\"Aristotle\">Aristotle</a></li>\n<li><a href=\"/wiki/Stoicism\" title=\"Stoicism\">Stoicism</a></li>\n<li><a href=\"/wiki/Epicureanism\" title=\"Epicureanism\">Epicureans</a>\n<ul><li><a href=\"/wiki/Epicurus\" title=\"Epicurus\">Epicurus</a></li></ul></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:7.5em\">Medieval</th><td class=\"navbox-list-with-group navbox-list navbox-even\" style=\"padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Averroes\" title=\"Averroes\">Averroes</a></li>\n<li><a href=\"/wiki/Avicenna\" title=\"Avicenna\">Avicenna</a></li>\n<li><a href=\"/wiki/Roger_Bacon\" title=\"Roger Bacon\">Roger Bacon</a></li>\n<li><a href=\"/wiki/William_of_Ockham\" title=\"William of Ockham\">William of Ockham</a></li>\n<li><a href=\"/wiki/Hugh_of_Saint_Victor\" title=\"Hugh of Saint Victor\">Hugh of Saint Victor</a></li>\n<li><a href=\"/wiki/Dominicus_Gundissalinus\" title=\"Dominicus Gundissalinus\">Dominicus Gundissalinus</a></li>\n<li><a href=\"/wiki/Robert_Kilwardby\" title=\"Robert Kilwardby\">Robert Kilwardby</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:7.5em\">Early modern</th><td class=\"navbox-list-with-group navbox-list navbox-odd\" style=\"padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Francis_Bacon\" title=\"Francis Bacon\">Francis Bacon</a></li>\n<li><a href=\"/wiki/Thomas_Hobbes\" title=\"Thomas Hobbes\">Thomas Hobbes</a></li>\n<li><a href=\"/wiki/Ren%C3%A9_Descartes\" title=\"René Descartes\">René Descartes</a></li>\n<li><a href=\"/wiki/Galileo_Galilei\" title=\"Galileo Galilei\">Galileo Galilei</a></li>\n<li><a href=\"/wiki/Pierre_Gassendi\" title=\"Pierre Gassendi\">Pierre Gassendi</a></li>\n<li><a href=\"/wiki/Isaac_Newton\" title=\"Isaac Newton\">Isaac Newton</a></li>\n<li><a href=\"/wiki/David_Hume\" title=\"David Hume\">David Hume</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:7.5em\">Late modern</th><td class=\"navbox-list-with-group navbox-list navbox-even\" style=\"padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Immanuel_Kant\" title=\"Immanuel Kant\">Immanuel Kant</a></li>\n<li><a href=\"/wiki/Friedrich_Wilhelm_Joseph_Schelling\" title=\"Friedrich Wilhelm Joseph Schelling\">Friedrich Schelling</a></li>\n<li><a href=\"/wiki/William_Whewell\" title=\"William Whewell\">William Whewell</a></li>\n<li><a href=\"/wiki/Auguste_Comte\" title=\"Auguste Comte\">Auguste Comte</a></li>\n<li><a href=\"/wiki/John_Stuart_Mill\" title=\"John Stuart Mill\">John Stuart Mill</a></li>\n<li><a href=\"/wiki/Herbert_Spencer\" title=\"Herbert Spencer\">Herbert Spencer</a></li>\n<li><a href=\"/wiki/Wilhelm_Wundt\" title=\"Wilhelm Wundt\">Wilhelm Wundt</a></li>\n<li><a href=\"/wiki/Charles_Sanders_Peirce\" title=\"Charles Sanders Peirce\">Charles Sanders Peirce</a></li>\n<li><a href=\"/wiki/Wilhelm_Windelband\" title=\"Wilhelm Windelband\">Wilhelm Windelband</a></li>\n<li><a href=\"/wiki/Henri_Poincar%C3%A9\" title=\"Henri Poincaré\">Henri Poincaré</a></li>\n<li><a href=\"/wiki/Pierre_Duhem\" title=\"Pierre Duhem\">Pierre Duhem</a></li>\n<li><a href=\"/wiki/Rudolf_Steiner\" title=\"Rudolf Steiner\">Rudolf Steiner</a></li>\n<li><a href=\"/wiki/Karl_Pearson\" title=\"Karl Pearson\">Karl Pearson</a></li></ul>\n</div></td></tr><tr><th class=\"navbox-group\" scope=\"row\" style=\"width:7.5em\">Contemporary</th><td class=\"navbox-list-with-group navbox-list navbox-odd\" style=\"padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Alfred_North_Whitehead\" title=\"Alfred North Whitehead\">Alfred North Whitehead</a></li>\n<li><a href=\"/wiki/Bertrand_Russell\" title=\"Bertrand Russell\">Bertrand Russell</a></li>\n<li><a href=\"/wiki/Albert_Einstein\" title=\"Albert Einstein\">Albert Einstein</a></li>\n<li><a href=\"/wiki/Otto_Neurath\" title=\"Otto Neurath\">Otto Neurath</a></li>\n<li><a href=\"/wiki/C._D._Broad\" title=\"C. D. Broad\">C. D. Broad</a></li>\n<li><a href=\"/wiki/Michael_Polanyi\" title=\"Michael Polanyi\">Michael Polanyi</a></li>\n<li><a href=\"/wiki/Hans_Reichenbach\" title=\"Hans Reichenbach\">Hans Reichenbach</a></li>\n<li><a href=\"/wiki/Rudolf_Carnap\" title=\"Rudolf Carnap\">Rudolf Carnap</a></li>\n<li><a href=\"/wiki/Karl_Popper\" title=\"Karl Popper\">Karl Popper</a></li>\n<li><a href=\"/wiki/Carl_Gustav_Hempel\" title=\"Carl Gustav Hempel\">Carl Gustav Hempel</a></li>\n<li><a href=\"/wiki/Willard_Van_Orman_Quine\" title=\"Willard Van Orman Quine\">W. V. O. Quine</a></li>\n<li><a href=\"/wiki/Thomas_Kuhn\" title=\"Thomas Kuhn\">Thomas Kuhn</a></li>\n<li><a href=\"/wiki/Imre_Lakatos\" title=\"Imre Lakatos\">Imre Lakatos</a></li>\n<li><a href=\"/wiki/Paul_Feyerabend\" title=\"Paul Feyerabend\">Paul Feyerabend</a></li>\n<li><a href=\"/wiki/J%C3%BCrgen_Habermas\" title=\"Jürgen Habermas\">Jürgen Habermas</a></li>\n<li><a href=\"/wiki/Ian_Hacking\" title=\"Ian Hacking\">Ian Hacking</a></li>\n<li><a href=\"/wiki/Bas_van_Fraassen\" title=\"Bas van Fraassen\">Bas van Fraassen</a></li>\n<li><a href=\"/wiki/Larry_Laudan\" title=\"Larry Laudan\">Larry Laudan</a></li>\n<li><a href=\"/wiki/Daniel_Dennett\" title=\"Daniel Dennett\">Daniel Dennett</a></li></ul>\n</div></td></tr></tbody></table><div></div></td></tr></tbody></table><div></div></td></tr><tr><td class=\"navbox-abovebelow\" colspan=\"2\"><div>\n<ul><li><a href=\"/wiki/Category:Philosophy_of_science\" title=\"Category:Philosophy of science\">Category</a></li>\n<li><img alt=\"\" class=\"noviewer\" data-file-height=\"500\" data-file-width=\"326\" decoding=\"async\" height=\"28\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/18px-Socrates.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/27px-Socrates.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Socrates.png/36px-Socrates.png 2x\" width=\"18\"/> <a href=\"/wiki/Portal:Philosophy\" title=\"Portal:Philosophy\">Philosophy portal</a></li>\n<li><a class=\"image\" href=\"/wiki/File:Nuvola_apps_kalzium.svg\"><img alt=\"icon\" class=\"noviewer\" data-file-height=\"128\" data-file-width=\"128\" decoding=\"async\" height=\"28\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Nuvola_apps_kalzium.svg/28px-Nuvola_apps_kalzium.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Nuvola_apps_kalzium.svg/42px-Nuvola_apps_kalzium.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Nuvola_apps_kalzium.svg/56px-Nuvola_apps_kalzium.svg.png 2x\" width=\"28\"/></a> <a href=\"/wiki/Portal:Science\" title=\"Portal:Science\">Science portal</a></li></ul>\n</div></td></tr></tbody></table></div>\n<!-- \nNewPP limit report\nParsed by mw2380\nCached time: 20221114200543\nCache expiry: 1814400\nReduced expiry: false\nComplications: [vary‐revision‐sha1, show‐toc]\nCPU time usage: 1.200 seconds\nReal time usage: 1.396 seconds\nPreprocessor visited node count: 6938/1000000\nPost‐expand include size: 331500/2097152 bytes\nTemplate argument size: 6671/2097152 bytes\nHighest expansion depth: 12/100\nExpensive parser function count: 14/500\nUnstrip recursion depth: 1/20\nUnstrip post‐expand size: 388042/5000000 bytes\nLua time usage: 0.799/10.000 seconds\nLua memory usage: 25951690/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00% 1184.272      1 -total\n 72.67%  860.610      1 Template:Reflist\n 21.71%  257.084     50 Template:Cite_web\n 12.04%  142.554     28 Template:Cite_journal\n  9.38%  111.121      1 Template:Harvnb\n  8.70%  103.058      1 Template:In_lang\n  4.35%   51.524      1 Template:Short_description\n  4.18%   49.463     12 Template:Cite_news\n  4.14%   49.075     11 Template:Cite_book\n  3.82%   45.247      1 Template:Artificial_intelligence\n-->\n<!-- Saved in parser cache with key enwiki:pcache:idhash:13659583-0!canonical and timestamp 20221114200541 and revision id 1117062413.\n -->\n</div><noscript><img alt=\"\" height=\"1\" src=\"//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\" style=\"border: none; position: absolute;\" title=\"\" width=\"1\"/></noscript>\n<div class=\"printfooter\" data-nosnippet=\"\">Retrieved from \"<a dir=\"ltr\" href=\"https://en.wikipedia.org/w/index.php?title=Ethics_of_artificial_intelligence&amp;oldid=1117062413\">https://en.wikipedia.org/w/index.php?title=Ethics_of_artificial_intelligence&amp;oldid=1117062413</a>\"</div></div>\n<div class=\"catlinks\" data-mw=\"interface\" id=\"catlinks\"><div class=\"mw-normal-catlinks\" id=\"mw-normal-catlinks\"><a href=\"/wiki/Help:Category\" title=\"Help:Category\">Categories</a>: <ul><li><a href=\"/wiki/Category:Philosophy_of_artificial_intelligence\" title=\"Category:Philosophy of artificial intelligence\">Philosophy of artificial intelligence</a></li><li><a href=\"/wiki/Category:Ethics_of_science_and_technology\" title=\"Category:Ethics of science and technology\">Ethics of science and technology</a></li><li><a href=\"/wiki/Category:Regulation_of_robots\" title=\"Category:Regulation of robots\">Regulation of robots</a></li></ul></div><div class=\"mw-hidden-catlinks mw-hidden-cats-hidden\" id=\"mw-hidden-catlinks\">Hidden categories: <ul><li><a href=\"/wiki/Category:Webarchive_template_wayback_links\" title=\"Category:Webarchive template wayback links\">Webarchive template wayback links</a></li><li><a href=\"/wiki/Category:CS1_errors:_generic_name\" title=\"Category:CS1 errors: generic name\">CS1 errors: generic name</a></li><li><a href=\"/wiki/Category:Articles_with_Russian-language_sources_(ru)\" title=\"Category:Articles with Russian-language sources (ru)\">Articles with Russian-language sources (ru)</a></li><li><a href=\"/wiki/Category:Articles_with_short_description\" title=\"Category:Articles with short description\">Articles with short description</a></li><li><a href=\"/wiki/Category:Short_description_is_different_from_Wikidata\" title=\"Category:Short description is different from Wikidata\">Short description is different from Wikidata</a></li><li><a href=\"/wiki/Category:All_articles_with_vague_or_ambiguous_time\" title=\"Category:All articles with vague or ambiguous time\">All articles with vague or ambiguous time</a></li><li><a href=\"/wiki/Category:Vague_or_ambiguous_time_from_November_2020\" title=\"Category:Vague or ambiguous time from November 2020\">Vague or ambiguous time from November 2020</a></li><li><a href=\"/wiki/Category:All_articles_with_failed_verification\" title=\"Category:All articles with failed verification\">All articles with failed verification</a></li><li><a href=\"/wiki/Category:Articles_with_failed_verification_from_November_2020\" title=\"Category:Articles with failed verification from November 2020\">Articles with failed verification from November 2020</a></li></ul></div></div>\n</div>\n</div>\n<div id=\"mw-navigation\">\n<h2>Navigation menu</h2>\n<div id=\"mw-head\">\n<nav aria-labelledby=\"p-personal-label\" class=\"vector-menu mw-portlet mw-portlet-personal vector-user-menu-legacy\" id=\"p-personal\" role=\"navigation\">\n<h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n<span class=\"vector-menu-heading-label\">Personal tools</span>\n</h3>\n<div class=\"vector-menu-content\">\n<ul class=\"vector-menu-content-list\"><li class=\"mw-list-item\" id=\"pt-anonuserpage\"><span title=\"The user page for the IP address you are editing as\">Not logged in</span></li><li class=\"mw-list-item\" id=\"pt-anontalk\"><a accesskey=\"n\" href=\"/wiki/Special:MyTalk\" title=\"Discussion about edits from this IP address [n]\"><span>Talk</span></a></li><li class=\"mw-list-item\" id=\"pt-anoncontribs\"><a accesskey=\"y\" href=\"/wiki/Special:MyContributions\" title=\"A list of edits made from this IP address [y]\"><span>Contributions</span></a></li><li class=\"mw-list-item\" id=\"pt-createaccount\"><a href=\"/w/index.php?title=Special:CreateAccount&amp;returnto=Ethics+of+artificial+intelligence\" title=\"You are encouraged to create an account and log in; however, it is not mandatory\"><span>Create account</span></a></li><li class=\"mw-list-item\" id=\"pt-login\"><a accesskey=\"o\" href=\"/w/index.php?title=Special:UserLogin&amp;returnto=Ethics+of+artificial+intelligence\" title=\"You're encouraged to log in; however, it's not mandatory. [o]\"><span>Log in</span></a></li></ul>\n</div>\n</nav>\n<div id=\"left-navigation\">\n<nav aria-labelledby=\"p-namespaces-label\" class=\"vector-menu mw-portlet mw-portlet-namespaces vector-menu-tabs vector-menu-tabs-legacy\" id=\"p-namespaces\" role=\"navigation\">\n<h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n<span class=\"vector-menu-heading-label\">Namespaces</span>\n</h3>\n<div class=\"vector-menu-content\">\n<ul class=\"vector-menu-content-list\"><li class=\"selected mw-list-item\" id=\"ca-nstab-main\"><a accesskey=\"c\" href=\"/wiki/Ethics_of_artificial_intelligence\" title=\"View the content page [c]\"><span>Article</span></a></li><li class=\"mw-list-item\" id=\"ca-talk\"><a accesskey=\"t\" href=\"/wiki/Talk:Ethics_of_artificial_intelligence\" rel=\"discussion\" title=\"Discuss improvements to the content page [t]\"><span>Talk</span></a></li></ul>\n</div>\n</nav>\n<nav aria-labelledby=\"p-variants-label\" class=\"vector-menu mw-portlet mw-portlet-variants emptyPortlet vector-menu-dropdown-noicon vector-menu-dropdown\" id=\"p-variants\" role=\"navigation\">\n<input aria-haspopup=\"true\" aria-labelledby=\"p-variants-label\" class=\"vector-menu-checkbox\" data-event-name=\"ui.dropdown-p-variants\" id=\"p-variants-checkbox\" role=\"button\" type=\"checkbox\"/>\n<label aria-label=\"Change language variant\" class=\"vector-menu-heading\" id=\"p-variants-label\">\n<span class=\"vector-menu-heading-label\">English</span>\n</label>\n<div class=\"vector-menu-content\">\n<ul class=\"vector-menu-content-list\"></ul>\n</div>\n</nav>\n</div>\n<div id=\"right-navigation\">\n<nav aria-labelledby=\"p-views-label\" class=\"vector-menu mw-portlet mw-portlet-views vector-menu-tabs vector-menu-tabs-legacy\" id=\"p-views\" role=\"navigation\">\n<h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n<span class=\"vector-menu-heading-label\">Views</span>\n</h3>\n<div class=\"vector-menu-content\">\n<ul class=\"vector-menu-content-list\"><li class=\"selected mw-list-item\" id=\"ca-view\"><a href=\"/wiki/Ethics_of_artificial_intelligence\"><span>Read</span></a></li><li class=\"mw-list-item\" id=\"ca-edit\"><a accesskey=\"e\" href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=edit\" title=\"Edit this page [e]\"><span>Edit</span></a></li><li class=\"mw-list-item\" id=\"ca-history\"><a accesskey=\"h\" href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=history\" title=\"Past revisions of this page [h]\"><span>View history</span></a></li></ul>\n</div>\n</nav>\n<nav aria-labelledby=\"p-cactions-label\" class=\"vector-menu mw-portlet mw-portlet-cactions emptyPortlet vector-menu-dropdown-noicon vector-menu-dropdown\" id=\"p-cactions\" role=\"navigation\" title=\"More options\">\n<input aria-haspopup=\"true\" aria-labelledby=\"p-cactions-label\" class=\"vector-menu-checkbox\" data-event-name=\"ui.dropdown-p-cactions\" id=\"p-cactions-checkbox\" role=\"button\" type=\"checkbox\"/>\n<label class=\"vector-menu-heading\" id=\"p-cactions-label\">\n<span class=\"vector-menu-heading-label\">More</span>\n</label>\n<div class=\"vector-menu-content\">\n<ul class=\"vector-menu-content-list\"></ul>\n</div>\n</nav>\n<div class=\"vector-search-box-vue vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box\" id=\"p-search\" role=\"search\">\n<div>\n<h3>\n<label for=\"searchInput\">Search</label>\n</h3>\n<form action=\"/w/index.php\" class=\"vector-search-box-form\" id=\"searchform\">\n<div class=\"vector-search-box-inner\" data-search-loc=\"header-navigation\" id=\"simpleSearch\">\n<input accesskey=\"f\" aria-label=\"Search Wikipedia\" autocapitalize=\"sentences\" class=\"vector-search-box-input\" id=\"searchInput\" name=\"search\" placeholder=\"Search Wikipedia\" title=\"Search Wikipedia [f]\" type=\"search\"/>\n<input name=\"title\" type=\"hidden\" value=\"Special:Search\"/>\n<input class=\"searchButton mw-fallbackSearchButton\" id=\"mw-searchButton\" name=\"fulltext\" title=\"Search Wikipedia for this text\" type=\"submit\" value=\"Search\"/>\n<input class=\"searchButton\" id=\"searchButton\" name=\"go\" title=\"Go to a page with this exact name if it exists\" type=\"submit\" value=\"Go\"/>\n</div>\n</form>\n</div>\n</div>\n</div>\n</div>\n<div id=\"mw-panel\">\n<div id=\"p-logo\" role=\"banner\">\n<a class=\"mw-wiki-logo\" href=\"/wiki/Main_Page\" title=\"Visit the main page\"></a>\n</div>\n<nav aria-labelledby=\"p-navigation-label\" class=\"vector-menu mw-portlet mw-portlet-navigation vector-menu-portal portal\" id=\"p-navigation\" role=\"navigation\">\n<h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n<span class=\"vector-menu-heading-label\">Navigation</span>\n</h3>\n<div class=\"vector-menu-content\">\n<ul class=\"vector-menu-content-list\"><li class=\"mw-list-item\" id=\"n-mainpage-description\"><a accesskey=\"z\" href=\"/wiki/Main_Page\" title=\"Visit the main page [z]\"><span>Main page</span></a></li><li class=\"mw-list-item\" id=\"n-contents\"><a href=\"/wiki/Wikipedia:Contents\" title=\"Guides to browsing Wikipedia\"><span>Contents</span></a></li><li class=\"mw-list-item\" id=\"n-currentevents\"><a href=\"/wiki/Portal:Current_events\" title=\"Articles related to current events\"><span>Current events</span></a></li><li class=\"mw-list-item\" id=\"n-randompage\"><a accesskey=\"x\" href=\"/wiki/Special:Random\" title=\"Visit a randomly selected article [x]\"><span>Random article</span></a></li><li class=\"mw-list-item\" id=\"n-aboutsite\"><a href=\"/wiki/Wikipedia:About\" title=\"Learn about Wikipedia and how it works\"><span>About Wikipedia</span></a></li><li class=\"mw-list-item\" id=\"n-contactpage\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\" title=\"How to contact Wikipedia\"><span>Contact us</span></a></li><li class=\"mw-list-item\" id=\"n-sitesupport\"><a href=\"https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en\" title=\"Support us by donating to the Wikimedia Foundation\"><span>Donate</span></a></li></ul>\n</div>\n</nav>\n<nav aria-labelledby=\"p-interaction-label\" class=\"vector-menu mw-portlet mw-portlet-interaction vector-menu-portal portal\" id=\"p-interaction\" role=\"navigation\">\n<h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n<span class=\"vector-menu-heading-label\">Contribute</span>\n</h3>\n<div class=\"vector-menu-content\">\n<ul class=\"vector-menu-content-list\"><li class=\"mw-list-item\" id=\"n-help\"><a href=\"/wiki/Help:Contents\" title=\"Guidance on how to use and edit Wikipedia\"><span>Help</span></a></li><li class=\"mw-list-item\" id=\"n-introduction\"><a href=\"/wiki/Help:Introduction\" title=\"Learn how to edit Wikipedia\"><span>Learn to edit</span></a></li><li class=\"mw-list-item\" id=\"n-portal\"><a href=\"/wiki/Wikipedia:Community_portal\" title=\"The hub for editors\"><span>Community portal</span></a></li><li class=\"mw-list-item\" id=\"n-recentchanges\"><a accesskey=\"r\" href=\"/wiki/Special:RecentChanges\" title=\"A list of recent changes to Wikipedia [r]\"><span>Recent changes</span></a></li><li class=\"mw-list-item\" id=\"n-upload\"><a href=\"/wiki/Wikipedia:File_Upload_Wizard\" title=\"Add images or other media for use on Wikipedia\"><span>Upload file</span></a></li></ul>\n</div>\n</nav>\n<nav aria-labelledby=\"p-tb-label\" class=\"vector-menu mw-portlet mw-portlet-tb vector-menu-portal portal\" id=\"p-tb\" role=\"navigation\">\n<h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n<span class=\"vector-menu-heading-label\">Tools</span>\n</h3>\n<div class=\"vector-menu-content\">\n<ul class=\"vector-menu-content-list\"><li class=\"mw-list-item\" id=\"t-whatlinkshere\"><a accesskey=\"j\" href=\"/wiki/Special:WhatLinksHere/Ethics_of_artificial_intelligence\" title=\"List of all English Wikipedia pages containing links to this page [j]\"><span>What links here</span></a></li><li class=\"mw-list-item\" id=\"t-recentchangeslinked\"><a accesskey=\"k\" href=\"/wiki/Special:RecentChangesLinked/Ethics_of_artificial_intelligence\" rel=\"nofollow\" title=\"Recent changes in pages linked from this page [k]\"><span>Related changes</span></a></li><li class=\"mw-list-item\" id=\"t-upload\"><a accesskey=\"u\" href=\"/wiki/Wikipedia:File_Upload_Wizard\" title=\"Upload files [u]\"><span>Upload file</span></a></li><li class=\"mw-list-item\" id=\"t-specialpages\"><a accesskey=\"q\" href=\"/wiki/Special:SpecialPages\" title=\"A list of all special pages [q]\"><span>Special pages</span></a></li><li class=\"mw-list-item\" id=\"t-permalink\"><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;oldid=1117062413\" title=\"Permanent link to this revision of this page\"><span>Permanent link</span></a></li><li class=\"mw-list-item\" id=\"t-info\"><a href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;action=info\" title=\"More information about this page\"><span>Page information</span></a></li><li class=\"mw-list-item\" id=\"t-cite\"><a href=\"/w/index.php?title=Special:CiteThisPage&amp;page=Ethics_of_artificial_intelligence&amp;id=1117062413&amp;wpFormIdentifier=titleform\" title=\"Information on how to cite this page\"><span>Cite this page</span></a></li><li class=\"mw-list-item\" id=\"t-wikibase\"><a accesskey=\"g\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q12727779\" title=\"Structured data on this page hosted by Wikidata [g]\"><span>Wikidata item</span></a></li></ul>\n</div>\n</nav>\n<nav aria-labelledby=\"p-coll-print_export-label\" class=\"vector-menu mw-portlet mw-portlet-coll-print_export vector-menu-portal portal\" id=\"p-coll-print_export\" role=\"navigation\">\n<h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n<span class=\"vector-menu-heading-label\">Print/export</span>\n</h3>\n<div class=\"vector-menu-content\">\n<ul class=\"vector-menu-content-list\"><li class=\"mw-list-item\" id=\"coll-download-as-rl\"><a href=\"/w/index.php?title=Special:DownloadAsPdf&amp;page=Ethics_of_artificial_intelligence&amp;action=show-download-screen\" title=\"Download this page as a PDF file\"><span>Download as PDF</span></a></li><li class=\"mw-list-item\" id=\"t-print\"><a accesskey=\"p\" href=\"/w/index.php?title=Ethics_of_artificial_intelligence&amp;printable=yes\" title=\"Printable version of this page [p]\"><span>Printable version</span></a></li></ul>\n</div>\n</nav>\n<nav aria-labelledby=\"p-lang-label\" class=\"vector-menu mw-portlet mw-portlet-lang vector-menu-portal portal\" id=\"p-lang\" role=\"navigation\">\n<h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n<span class=\"vector-menu-heading-label\">Languages</span>\n</h3>\n<div class=\"vector-menu-content\">\n<ul class=\"vector-menu-content-list\"><li class=\"interlanguage-link interwiki-ar mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://ar.wikipedia.org/wiki/%D8%A3%D8%AE%D9%84%D8%A7%D9%82%D9%8A%D8%A7%D8%AA_%D8%A7%D9%84%D8%B0%D9%83%D8%A7%D8%A1_%D8%A7%D9%84%D8%A7%D8%B5%D8%B7%D9%86%D8%A7%D8%B9%D9%8A\" hreflang=\"ar\" lang=\"ar\" title=\"أخلاقيات الذكاء الاصطناعي – Arabic\"><span>العربية</span></a></li><li class=\"interlanguage-link interwiki-az mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://az.wikipedia.org/wiki/S%C3%BCni_intellekt_etikas%C4%B1\" hreflang=\"az\" lang=\"az\" title=\"Süni intellekt etikası – Azerbaijani\"><span>Azərbaycanca</span></a></li><li class=\"interlanguage-link interwiki-ca mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://ca.wikipedia.org/wiki/%C3%88tica_de_la_intel%C2%B7lig%C3%A8ncia_artificial\" hreflang=\"ca\" lang=\"ca\" title=\"Ètica de la intel·ligència artificial – Catalan\"><span>Català</span></a></li><li class=\"interlanguage-link interwiki-el mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://el.wikipedia.org/wiki/%CE%97%CE%B8%CE%B9%CE%BA%CE%AE_%CF%84%CE%B7%CF%82_%CF%84%CE%B5%CF%87%CE%BD%CE%B7%CF%84%CE%AE%CF%82_%CE%BD%CE%BF%CE%B7%CE%BC%CE%BF%CF%83%CF%8D%CE%BD%CE%B7%CF%82\" hreflang=\"el\" lang=\"el\" title=\"Ηθική της τεχνητής νοημοσύνης – Greek\"><span>Ελληνικά</span></a></li><li class=\"interlanguage-link interwiki-es mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://es.wikipedia.org/wiki/%C3%89tica_en_la_inteligencia_artificial\" hreflang=\"es\" lang=\"es\" title=\"Ética en la inteligencia artificial – Spanish\"><span>Español</span></a></li><li class=\"interlanguage-link interwiki-fa mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://fa.wikipedia.org/wiki/%D8%A7%D8%AE%D9%84%D8%A7%D9%82_%D9%87%D9%88%D8%B4_%D9%85%D8%B5%D9%86%D9%88%D8%B9%DB%8C\" hreflang=\"fa\" lang=\"fa\" title=\"اخلاق هوش مصنوعی – Persian\"><span>فارسی</span></a></li><li class=\"interlanguage-link interwiki-fr mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://fr.wikipedia.org/wiki/%C3%89thique_de_l%27intelligence_artificielle\" hreflang=\"fr\" lang=\"fr\" title=\"Éthique de l'intelligence artificielle – French\"><span>Français</span></a></li><li class=\"interlanguage-link interwiki-it mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://it.wikipedia.org/wiki/Etica_dell%27intelligenza_artificiale\" hreflang=\"it\" lang=\"it\" title=\"Etica dell'intelligenza artificiale – Italian\"><span>Italiano</span></a></li><li class=\"interlanguage-link interwiki-he mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://he.wikipedia.org/wiki/%D7%90%D7%AA%D7%99%D7%A7%D7%94_%D7%A9%D7%9C_%D7%91%D7%99%D7%A0%D7%94_%D7%9E%D7%9C%D7%90%D7%9B%D7%95%D7%AA%D7%99%D7%AA\" hreflang=\"he\" lang=\"he\" title=\"אתיקה של בינה מלאכותית – Hebrew\"><span>עברית</span></a></li><li class=\"interlanguage-link interwiki-uz mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://uz.wikipedia.org/wiki/Sun%27iy_intellekt_etikasi\" hreflang=\"uz\" lang=\"uz\" title=\"Sun'iy intellekt etikasi – Uzbek\"><span>Oʻzbekcha/ўзбекча</span></a></li><li class=\"interlanguage-link interwiki-pt mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://pt.wikipedia.org/wiki/%C3%89tica_na_intelig%C3%AAncia_artificial\" hreflang=\"pt\" lang=\"pt\" title=\"Ética na inteligência artificial – Portuguese\"><span>Português</span></a></li><li class=\"interlanguage-link interwiki-ro mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://ro.wikipedia.org/wiki/Etica_privind_inteligen%C8%9Ba_artificial%C4%83\" hreflang=\"ro\" lang=\"ro\" title=\"Etica privind inteligența artificială – Romanian\"><span>Română</span></a></li><li class=\"interlanguage-link interwiki-ru mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://ru.wikipedia.org/wiki/%D0%AD%D1%82%D0%B8%D0%BA%D0%B0_%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D0%B0\" hreflang=\"ru\" lang=\"ru\" title=\"Этика искусственного интеллекта – Russian\"><span>Русский</span></a></li><li class=\"interlanguage-link interwiki-sr mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://sr.wikipedia.org/wiki/Etika_ve%C5%A1ta%C4%8Dke_inteligencije\" hreflang=\"sr\" lang=\"sr\" title=\"Etika veštačke inteligencije – Serbian\"><span>Српски / srpski</span></a></li><li class=\"interlanguage-link interwiki-fi mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://fi.wikipedia.org/wiki/Teko%C3%A4lyn_etiikka\" hreflang=\"fi\" lang=\"fi\" title=\"Tekoälyn etiikka – Finnish\"><span>Suomi</span></a></li><li class=\"interlanguage-link interwiki-sv mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://sv.wikipedia.org/wiki/Etiken_kring_artificiell_intelligens\" hreflang=\"sv\" lang=\"sv\" title=\"Etiken kring artificiell intelligens – Swedish\"><span>Svenska</span></a></li><li class=\"interlanguage-link interwiki-tr mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://tr.wikipedia.org/wiki/Yapay_zek%C3%A2_eti%C4%9Fi\" hreflang=\"tr\" lang=\"tr\" title=\"Yapay zekâ etiği – Turkish\"><span>Türkçe</span></a></li><li class=\"interlanguage-link interwiki-uk mw-list-item\"><a class=\"interlanguage-link-target\" href=\"https://uk.wikipedia.org/wiki/%D0%95%D1%82%D0%B8%D0%BA%D0%B0_%D1%88%D1%82%D1%83%D1%87%D0%BD%D0%BE%D0%B3%D0%BE_%D1%96%D0%BD%D1%82%D0%B5%D0%BB%D0%B5%D0%BA%D1%82%D1%83\" hreflang=\"uk\" lang=\"uk\" title=\"Етика штучного інтелекту – Ukrainian\"><span>Українська</span></a></li></ul>\n<div class=\"after-portlet after-portlet-lang\"><span class=\"wb-langlinks-edit wb-langlinks-link\"><a class=\"wbc-editpage\" href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q12727779#sitelinks-wikipedia\" title=\"Edit interlanguage links\">Edit links</a></span></div>\n</div>\n</nav>\n</div>\n</div>\n<footer class=\"mw-footer\" id=\"footer\" role=\"contentinfo\">\n<ul id=\"footer-info\">\n<li id=\"footer-info-lastmod\"> This page was last edited on 19 October 2022, at 18:54<span class=\"anonymous-show\"> (UTC)</span>.</li>\n<li id=\"footer-info-copyright\">Text is available under the <a href=\"//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\" rel=\"license\">Creative Commons Attribution-ShareAlike License 3.0</a><a href=\"//creativecommons.org/licenses/by-sa/3.0/\" rel=\"license\" style=\"display:none;\"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href=\"//foundation.wikimedia.org/wiki/Terms_of_Use\">Terms of Use</a> and <a href=\"//foundation.wikimedia.org/wiki/Privacy_policy\">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href=\"//www.wikimediafoundation.org/\">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n</ul>\n<ul id=\"footer-places\">\n<li id=\"footer-places-privacy\"><a href=\"https://foundation.wikimedia.org/wiki/Privacy_policy\">Privacy policy</a></li>\n<li id=\"footer-places-about\"><a href=\"/wiki/Wikipedia:About\">About Wikipedia</a></li>\n<li id=\"footer-places-disclaimers\"><a href=\"/wiki/Wikipedia:General_disclaimer\">Disclaimers</a></li>\n<li id=\"footer-places-contact\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\">Contact Wikipedia</a></li>\n<li id=\"footer-places-mobileview\"><a class=\"noprint stopMobileRedirectToggle\" href=\"//en.m.wikipedia.org/w/index.php?title=Ethics_of_artificial_intelligence&amp;mobileaction=toggle_view_mobile\">Mobile view</a></li>\n<li id=\"footer-places-developers\"><a href=\"https://developer.wikimedia.org\">Developers</a></li>\n<li id=\"footer-places-statslink\"><a href=\"https://stats.wikimedia.org/#/en.wikipedia.org\">Statistics</a></li>\n<li id=\"footer-places-cookiestatement\"><a href=\"https://foundation.wikimedia.org/wiki/Cookie_statement\">Cookie statement</a></li>\n</ul>\n<ul class=\"noprint\" id=\"footer-icons\">\n<li id=\"footer-copyrightico\"><a href=\"https://wikimediafoundation.org/\"><img alt=\"Wikimedia Foundation\" height=\"31\" loading=\"lazy\" src=\"/static/images/footer/wikimedia-button.png\" srcset=\"/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x\" width=\"88\"/></a></li>\n<li id=\"footer-poweredbyico\"><a href=\"https://www.mediawiki.org/\"><img alt=\"Powered by MediaWiki\" height=\"31\" loading=\"lazy\" src=\"/static/images/footer/poweredby_mediawiki_88x31.png\" srcset=\"/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x\" width=\"88\"/></a></li>\n</ul>\n</footer>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgPageParseReport\":{\"limitreport\":{\"cputime\":\"1.200\",\"walltime\":\"1.396\",\"ppvisitednodes\":{\"value\":6938,\"limit\":1000000},\"postexpandincludesize\":{\"value\":331500,\"limit\":2097152},\"templateargumentsize\":{\"value\":6671,\"limit\":2097152},\"expansiondepth\":{\"value\":12,\"limit\":100},\"expensivefunctioncount\":{\"value\":14,\"limit\":500},\"unstrip-depth\":{\"value\":1,\"limit\":20},\"unstrip-size\":{\"value\":388042,\"limit\":5000000},\"entityaccesscount\":{\"value\":0,\"limit\":400},\"timingprofile\":[\"100.00% 1184.272      1 -total\",\" 72.67%  860.610      1 Template:Reflist\",\" 21.71%  257.084     50 Template:Cite_web\",\" 12.04%  142.554     28 Template:Cite_journal\",\"  9.38%  111.121      1 Template:Harvnb\",\"  8.70%  103.058      1 Template:In_lang\",\"  4.35%   51.524      1 Template:Short_description\",\"  4.18%   49.463     12 Template:Cite_news\",\"  4.14%   49.075     11 Template:Cite_book\",\"  3.82%   45.247      1 Template:Artificial_intelligence\"]},\"scribunto\":{\"limitreport-timeusage\":{\"value\":\"0.799\",\"limit\":\"10.000\"},\"limitreport-memusage\":{\"value\":25951690,\"limit\":52428800},\"limitreport-logs\":\"anchor_id_list = table#1 {\\n    [\\\"CITEREFAl-Rodhan2015\\\"] = 1,\\n    [\\\"CITEREFAnderson\\\"] = 1,\\n    [\\\"CITEREFAndersonAnderson2006\\\"] = 1,\\n    [\\\"CITEREFAndersonAnderson2007\\\"] = 1,\\n    [\\\"CITEREFAndersonAnderson2011\\\"] = 1,\\n    [\\\"CITEREFAnonymous2018\\\"] = 1,\\n    [\\\"CITEREFAsimov2008\\\"] = 1,\\n    [\\\"CITEREFBenderFriedman2018\\\"] = 1,\\n    [\\\"CITEREFBostromYudkowsky2011\\\"] = 1,\\n    [\\\"CITEREFBoyles2017\\\"] = 1,\\n    [\\\"CITEREFCat_Zakrzewski2015\\\"] = 1,\\n    [\\\"CITEREFCave,_StephenDihal,_KantaDillon,_Sarah2020\\\"] = 1,\\n    [\\\"CITEREFCaveDihal2020\\\"] = 1,\\n    [\\\"CITEREFCerquiWarwick2008\\\"] = 1,\\n    [\\\"CITEREFCurtisGillespieLockey2022\\\"] = 1,\\n    [\\\"CITEREFDanaher,_John2019\\\"] = 1,\\n    [\\\"CITEREFDavies2016\\\"] = 1,\\n    [\\\"CITEREFDelbridge\\\"] = 1,\\n    [\\\"CITEREFEuropean_Commission_High-Level_Expert_Group_on_AI2019\\\"] = 1,\\n    [\\\"CITEREFEvans2015\\\"] = 1,\\n    [\\\"CITEREFFiegerman2016\\\"] = 1,\\n    [\\\"CITEREFFloridiCowls2019\\\"] = 1,\\n    [\\\"CITEREFFloridiCowlsBeltramettiChatila2018\\\"] = 1,\\n    [\\\"CITEREFFloridiCowlsKingTaddeo2020\\\"] = 1,\\n    [\\\"CITEREFFriedmanNissenbaum1996\\\"] = 1,\\n    [\\\"CITEREFGabriel2018\\\"] = 1,\\n    [\\\"CITEREFGebruMorgensternVecchioneVaughan2018\\\"] = 1,\\n    [\\\"CITEREFGiveWell2015\\\"] = 1,\\n    [\\\"CITEREFGraceSalvatierDafoeZhang2018\\\"] = 1,\\n    [\\\"CITEREFHagendorff2020\\\"] = 1,\\n    [\\\"CITEREFHellström2013\\\"] = 1,\\n    [\\\"CITEREFHenderson2007\\\"] = 1,\\n    [\\\"CITEREFHibbard2015\\\"] = 1,\\n    [\\\"CITEREFHoward\\\"] = 1,\\n    [\\\"CITEREFHughes,_James_J.LaGrandeur,_Kevin2017\\\"] = 1,\\n    [\\\"CITEREFJerreat-Poole2020\\\"] = 1,\\n    [\\\"CITEREFJobinIencaVayena2020\\\"] = 1,\\n    [\\\"CITEREFKaplanHaenlein2019\\\"] = 1,\\n    [\\\"CITEREFKnight\\\"] = 2,\\n    [\\\"CITEREFKoeneckeNamLakeNudell2020\\\"] = 1,\\n    [\\\"CITEREFKurzweil2005\\\"] = 1,\\n    [\\\"CITEREFLee2020\\\"] = 1,\\n    [\\\"CITEREFLevinWong2018\\\"] = 1,\\n    [\\\"CITEREFLohr2018\\\"] = 1,\\n    [\\\"CITEREFMarkoff2009\\\"] = 1,\\n    [\\\"CITEREFMaxmen2018\\\"] = 1,\\n    [\\\"CITEREFMcGee\\\"] = 1,\\n    [\\\"CITEREFMitra2018\\\"] = 1,\\n    [\\\"CITEREFMüller2020\\\"] = 2,\\n    [\\\"CITEREFOlson\\\"] = 1,\\n    [\\\"CITEREFPery2021\\\"] = 1,\\n    [\\\"CITEREFRadioPolicyPodcastsAmerica\\\"] = 1,\\n    [\\\"CITEREFRoose2020\\\"] = 1,\\n    [\\\"CITEREFRussell2019\\\"] = 1,\\n    [\\\"CITEREFRussellHauertAltmanVeloso2015\\\"] = 1,\\n    [\\\"CITEREFSantos-Lang2002\\\"] = 1,\\n    [\\\"CITEREFSheliazhenko2017\\\"] = 1,\\n    [\\\"CITEREFStilgoe2020\\\"] = 1,\\n    [\\\"CITEREFUmbrello2019\\\"] = 1,\\n    [\\\"CITEREFUmbrelloBaum2018\\\"] = 1,\\n    [\\\"CITEREFUmbrelloTorresDe_Bellis2020\\\"] = 1,\\n    [\\\"CITEREFUnited_States._Defense_Innovation_Board\\\"] = 1,\\n    [\\\"CITEREFVeruggio,_Gianmarco2011\\\"] = 1,\\n    [\\\"CITEREFVillasenor2019\\\"] = 1,\\n    [\\\"CITEREFWallachAllen2008\\\"] = 1,\\n    [\\\"CITEREFWallachVallor2020\\\"] = 1,\\n    [\\\"CITEREFWilks,_Yorick2010\\\"] = 1,\\n    [\\\"CITEREFWinfieldMichaelPittEvers2019\\\"] = 1,\\n    [\\\"CITEREFYampolskiy2020\\\"] = 1,\\n    [\\\"CITEREFZach_Musgrave_and_Bryan_W._Roberts2015\\\"] = 1,\\n    [\\\"DeloitteGDPR\\\"] = 1,\\n    [\\\"WiredMS\\\"] = 1,\\n    [\\\"bs\\\"] = 1,\\n    [\\\"lacuna\\\"] = 1,\\n    [\\\"p7001\\\"] = 1,\\n    [\\\"principles\\\"] = 1,\\n}\\ntemplate_list = table#1 {\\n    [\\\"!\\\"] = 3,\\n    [\\\"Artificial intelligence\\\"] = 1,\\n    [\\\"Citation\\\"] = 4,\\n    [\\\"Cite arXiv\\\"] = 3,\\n    [\\\"Cite book\\\"] = 11,\\n    [\\\"Cite journal\\\"] = 28,\\n    [\\\"Cite magazine\\\"] = 1,\\n    [\\\"Cite news\\\"] = 12,\\n    [\\\"Cite report\\\"] = 1,\\n    [\\\"Cite web\\\"] = 50,\\n    [\\\"Columns-list\\\"] = 1,\\n    [\\\"Ethics\\\"] = 1,\\n    [\\\"Existential risk from artificial intelligence\\\"] = 1,\\n    [\\\"Failed verification\\\"] = 1,\\n    [\\\"Further\\\"] = 1,\\n    [\\\"Harvnb\\\"] = 1,\\n    [\\\"In lang\\\"] = 1,\\n    [\\\"Main\\\"] = 7,\\n    [\\\"McCorduck 2004\\\"] = 1,\\n    [\\\"Philosophy of science\\\"] = 1,\\n    [\\\"ProQuest\\\"] = 1,\\n    [\\\"Reflist\\\"] = 1,\\n    [\\\"Short description\\\"] = 1,\\n    [\\\"Webarchive\\\"] = 17,\\n    [\\\"When\\\"] = 1,\\n}\\narticle_whitelist = table#1 {\\n}\\ntable#1 {\\n}\\ntable#1 {\\n}\\n\"},\"cachereport\":{\"origin\":\"mw2380\",\"timestamp\":\"20221114200543\",\"ttl\":1814400,\"transientcontent\":false}}});});</script>\n<script type=\"application/ld+json\">{\"@context\":\"https:\\/\\/schema.org\",\"@type\":\"Article\",\"name\":\"Ethics of artificial intelligence\",\"url\":\"https:\\/\\/en.wikipedia.org\\/wiki\\/Ethics_of_artificial_intelligence\",\"sameAs\":\"http:\\/\\/www.wikidata.org\\/entity\\/Q12727779\",\"mainEntity\":\"http:\\/\\/www.wikidata.org\\/entity\\/Q12727779\",\"author\":{\"@type\":\"Organization\",\"name\":\"Contributors to Wikimedia projects\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Wikimedia Foundation, Inc.\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png\"}},\"datePublished\":\"2007-10-10T08:24:29Z\",\"dateModified\":\"2022-10-19T18:54:47Z\",\"headline\":\"ethics of technology specific to robots and other artificially intelligent beings\"}</script><script type=\"application/ld+json\">{\"@context\":\"https:\\/\\/schema.org\",\"@type\":\"Article\",\"name\":\"Ethics of artificial intelligence\",\"url\":\"https:\\/\\/en.wikipedia.org\\/wiki\\/Ethics_of_artificial_intelligence\",\"sameAs\":\"http:\\/\\/www.wikidata.org\\/entity\\/Q12727779\",\"mainEntity\":\"http:\\/\\/www.wikidata.org\\/entity\\/Q12727779\",\"author\":{\"@type\":\"Organization\",\"name\":\"Contributors to Wikimedia projects\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Wikimedia Foundation, Inc.\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png\"}},\"datePublished\":\"2007-10-10T08:24:29Z\",\"dateModified\":\"2022-10-19T18:54:47Z\",\"headline\":\"ethics of technology specific to robots and other artificially intelligent beings\"}</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgBackendResponseTime\":104,\"wgHostname\":\"mw2335\"});});</script>\n</body>\n</html>",
    "table_of_contents": [
        "1 Ethics fields' approaches",
        "1.1 Robot ethics",
        "1.2 Machine ethics",
        "1.3 Ethics principles of artificial intelligence",
        "1.3.1 Transparency, accountability, and open source",
        "2 Ethical challenges",
        "2.1 Biases in AI systems",
        "2.2 Robot rights",
        "2.3 Threat to human dignity",
        "2.4 Liability for self-driving cars",
        "2.5 Weaponization of artificial intelligence",
        "2.6 Opaque algorithms",
        "3 Singularity",
        "4 Actors in AI ethics",
        "4.1 Intergovernmental initiatives",
        "4.2 Governmental initiatives",
        "4.3 Academic initiatives",
        "4.4 Private organizations",
        "5 Role and impact of fiction",
        "5.1 History",
        "5.2 Impact on technological development",
        "5.3 TV series",
        "5.4 Future visions in fiction and games",
        "6 See also",
        "7 Notes",
        "8 External links"
    ],
    "graphics": [
        {
            "url": "",
            "caption": "Then-US Senator Kamala Harris speaking about racial bias in artificial intelligence in 2020"
        }
    ],
    "paragraphs": [
        {
            "title": "",
            "text": "The ethics of artificial intelligence is the branch of the ethics of technology specific to artificially intelligent systems.[1] It is sometimes divided into a concern with the moral behavior of humans as they design, make, use and treat artificially intelligent systems, and a concern with the behavior of machines, in machine ethics. It also includes the issue of a possible singularity due to superintelligent AI.\n\n"
        },
        {
            "title": "",
            "text": "The term \"robot ethics\" (sometimes \"roboethics\") refers to the morality of how humans design, construct, use and treat robots.[2] Robot ethics intersect with the ethics of AI. Robots are physical machines whereas AI can be only software.[3] Not all robots function through AI systems and not all AI systems are robots. Robot ethics considers how machines may be used to harm or benefit humans, their impact on individual autonomy, and their effects on social justice.\n\nMachine ethics (or machine morality) is the field of research concerned with designing Artificial Moral Agents (AMAs), robots or artificially intelligent computers that behave morally or as though moral.[4][5][6][7] To account for the nature of these agents, it has been suggested to consider certain philosophical ideas, like the standard characterizations of agency, rational agency, moral agency, and artificial agency, which are related to the concept of AMAs.[8]\n\nIsaac Asimov considered the issue in the 1950s in his I, Robot.  At the insistence of his editor John W. Campbell Jr., he proposed the Three Laws of Robotics to govern artificially intelligent systems.  Much of his work was then spent testing the boundaries of his three laws to see where they would break down, or where they would create paradoxical or unanticipated behavior. His work suggests that no set of fixed laws can sufficiently anticipate all possible circumstances.[9] More recently, academics and many governments have challenged the idea that AI can itself be held accountable.[10] A panel convened by the United Kingdom in 2010 revised Asimov's laws to clarify that AI is the responsibility either of its manufacturers, or of its owner/operator.[11]\n\nIn 2009, during an experiment at the Laboratory of Intelligent Systems in the Ecole Polytechnique Fédérale of Lausanne, Switzerland, robots that were programmed to cooperate with each other (in searching out a beneficial resource and avoiding a poisonous one) eventually learned to lie to each other in an attempt to hoard the beneficial resource.[12]\n\nSome experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomous functions.[13] The US Navy has funded a report which indicates that as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions.[14][15] The President of the Association for the Advancement of Artificial Intelligence has commissioned a study to look at this issue.[16] They point to programs like the Language Acquisition Device which can emulate human interaction.\n\nVernor Vinge has suggested that a moment may come when some computers are smarter than humans. He calls this \"the Singularity\".[17]  He suggests that it may be somewhat or possibly very dangerous for humans.[18] This is discussed by a philosophy called Singularitarianism. The Machine Intelligence Research Institute has suggested a need to build \"Friendly AI\", meaning that the advances which are already occurring with AI should also include an effort to make AI intrinsically friendly and humane.[19]\n\nThere are discussion on creating tests to see if an AI is capable of making ethical decisions. Alan Winfield concludes that the Turing test is flawed and the requirement for an AI to pass the test is too low.[20] A proposed alternative test is one called the Ethical Turing Test, which would improve on the current test by having multiple judges decide if the AI's decision is ethical or unethical.[20]\n\nIn 2009, academics and technical experts attended a conference organized by the Association for the Advancement of Artificial Intelligence to discuss the potential impact of robots and computers and the impact of the hypothetical possibility that they could become self-sufficient and able to make their own decisions. They discussed the possibility and the extent to which computers and robots might be able to acquire any level of autonomy, and to what degree they could use such abilities to possibly pose any threat or hazard. They noted that some machines have acquired various forms of semi-autonomy, including being able to find power sources on their own and being able to independently choose targets to attack with weapons. They also noted that some computer viruses can evade elimination and have achieved \"cockroach intelligence\". They noted that self-awareness as depicted in science-fiction is probably unlikely, but that there were other potential hazards and pitfalls.[17]\n\nHowever, there is one technology in particular that could truly bring the possibility of robots with moral competence to reality. In a paper on the acquisition of moral values by robots, Nayef Al-Rodhan mentions the case of neuromorphic chips, which aim to process information similarly to humans, nonlinearly and with millions of interconnected artificial neurons.[21] Robots embedded with neuromorphic technology could learn and develop knowledge in a uniquely humanlike way. Inevitably, this raises the question of the environment in which such robots would learn about the world and whose morality they would inherit – or if they end up developing human 'weaknesses' as well: selfishness, a pro-survival attitude, hesitation etc.\n\nIn Moral Machines: Teaching Robots Right from Wrong,[22] Wendell Wallach and Colin Allen conclude that attempts to teach robots right from wrong will likely advance understanding of human ethics by motivating humans to address gaps in modern normative theory and by providing a platform for experimental investigation. As one example, it has introduced normative ethicists to the controversial issue of which specific learning algorithms to use in machines. Nick Bostrom and Eliezer Yudkowsky have argued for decision trees (such as ID3) over neural networks and genetic algorithms on the grounds that decision trees obey modern social norms of transparency and predictability (e.g. stare decisis),[23] while Chris Santos-Lang argued in the opposite direction on the grounds that the norms of any age must be allowed to change and that natural failure to fully satisfy these particular norms has been essential in making humans less vulnerable to criminal \"hackers\".[24]\n\nAccording to a 2019 report from the Center for the Governance of AI at the University of Oxford, 82% of Americans believe that robots and AI should be carefully managed. Concerns cited ranged from how AI is used in surveillance and in spreading fake content online (known as deep fakes when they include doctored video images and audio generated with help from AI) to cyberattacks, infringements on data privacy, hiring bias, autonomous vehicles, and drones that do not require a human controller.[25]\n\nIn the review of 84[26] ethics guidelines for AI 11 clusters of principles were found: transparency, justice and fairness, non-maleficence, responsibility, privacy, beneficence, freedom and autonomy, trust, sustainability, dignity, solidarity.[26]\n\nLuciano Floridi and Josh Cowls created an ethical framework of AI principles set by four principles of bioethics (beneficence, non-maleficence, autonomy and justice) and an additional AI enabling principle – explicability.[27]\n\nBill Hibbard argues that because AI will have such a profound effect on humanity, AI developers are representatives of future humanity and thus have an ethical obligation to be transparent in their efforts.[28] Ben Goertzel and David Hart created OpenCog as an open source framework for AI development.[29] OpenAI is a non-profit AI research company created by Elon Musk, Sam Altman and others to develop open-source AI beneficial to humanity.[30] There are numerous other open-source AI developments.\n\nUnfortunately, making code open source does not make it comprehensible, which by many definitions means that the AI code is not transparent. The IEEE has a standardisation effort on AI transparency.[31] The IEEE effort identifies multiple scales of transparency for different users. Further, there is concern that releasing the full capacity of contemporary AI to some organizations may be a public bad, that is, do more damage than good. For example, Microsoft has expressed concern about allowing universal access to its face recognition software, even for those who can pay for it. Microsoft posted an extraordinary blog on this topic, asking for government regulation to help determine the right thing to do.[32]\n\nNot only companies, but many other researchers and citizen advocates recommend government regulation as a means of ensuring transparency, and through it, human accountability. This strategy has proven controversial, as some worry that it will slow the rate of innovation. Others argue that regulation leads to systemic stability more able to support innovation in the long term.[33] The OECD, UN, EU, and many countries are presently working on strategies for regulating AI, and finding appropriate legal frameworks.[34][35][36]\n\nOn June 26, 2019, the European Commission High-Level Expert Group on Artificial Intelligence (AI HLEG) published its \"Policy and investment recommendations for trustworthy Artificial Intelligence\".[37] This is the AI HLEG's second deliverable, after the April 2019 publication of the \"Ethics Guidelines for Trustworthy AI\". The June AI HLEG recommendations cover four principal subjects: humans and society at large, research and academia, the private sector, and the public sector. The European Commission claims that \"HLEG's recommendations reflect an appreciation of both the opportunities for AI technologies to drive economic growth, prosperity and innovation, as well as the potential risks involved\" and states that the EU aims to lead on the framing of policies governing AI internationally.[38] To prevent harm, in addition to regulation, AI-deploying organizations need to play a central role in creating and deploying trustworthy AI in line with the principles of trustworthy AI, and take accountability to mitigate the risks.[39]\n\n"
        },
        {
            "title": "Ethical challenges",
            "text": "AI has become increasingly inherent in facial and voice recognition systems. Some of these systems have real business applications and directly impact people. These systems are vulnerable to biases and errors introduced by its human creators. Also, the data used to train these AI systems itself can have biases.[40][41][42][43] For instance, facial recognition algorithms made by Microsoft, IBM and Face++ all had biases when it came to detecting people's gender;[44] these AI systems were able to detect gender of white men more accurately than gender of darker skin men. Further, a 2020 study reviewed voice recognition systems from Amazon, Apple, Google, IBM, and Microsoft found that they have higher error rates when transcribing black people's voices than white people's.[45] Furthermore, Amazon terminated their use of AI hiring and recruitment because the algorithm favored male candidates over female ones. This was because Amazon's system was trained with data collected over 10-year period that came mostly from male candidates.[46]\n\nBias can creep into algorithms in many ways. The most predominant view on how bias is introduced into AI systems is that it is embedded within the historical data used to train the system. For instance, Amazon's AI-powered recruitment tool was trained with its own recruitment data accumulated over the years, during which time the candidates that successfully got the job were mostly white males. Consequently, the algorithms learned the (biased) pattern from the historical data and generated predictions for the present/future that these types of candidates are mostly like to succeed in getting the job. Therefore, the recruitment decisions made by the AI system turn out to be biased against female and minority candidates. Friedman and Nissenbaum identify three categories of bias in computer systems: existing bias, technical bias, and emergent bias.[47] In natural language processing, problems can arise from the text corpus — the source material the algorithm uses to learn about the relationships between different words.[48]\n\nLarge companies such as IBM, Google, etc. have made efforts to research and address these biases.[49][50][51] One solution for addressing bias is to create documentation for the data used to train AI systems.[52][53] Process mining can be an important tool for organizations to achieve compliance with proposed AI regulations by identifying errors, monitoring processes, identifying potential root causes for improper execution, and other functions.[54]\n\nThe problem of bias in machine learning is likely to become more significant as the technology spreads to critical areas like medicine and law, and as more people without a deep technical understanding are tasked with deploying it. Some experts warn that algorithmic bias is already pervasive in many industries and that almost no one is making an effort to identify or correct it.[55] There are some open-sourced tools [56] by civil societies that are looking to bring more awareness to biased AI.\n\n\"Robot rights\" is the concept that people should have moral obligations towards their machines, akin to human rights or animal rights.[57] It has been suggested that robot rights (such as a right to exist and perform its own mission) could be linked to robot duty to serve humanity, analogous to linking human rights with human duties before society.[58] These could include the right to life and liberty, freedom of thought and expression, and equality before the law.[59] The issue has been considered by the Institute for the Future[60] and by the U.K. Department of Trade and Industry.[61]\n\nExperts disagree on how soon specific and detailed laws on the subject will be necessary.[61] Glenn McGee reported that sufficiently humanoid robots might appear by 2020,[62] while Ray Kurzweil sets the date at 2029.[63] Another group of scientists meeting in 2007 supposed that at least 50 years had to pass before any sufficiently advanced system would exist.[64]\n\nThe rules for the 2003 Loebner Prize competition envisioned the possibility of robots having rights of their own:\n\nIn October 2017, the android Sophia was granted \"honorary\" citizenship in Saudi Arabia, though some considered this to be more of a publicity stunt than a meaningful legal recognition.[66] Some saw this gesture as openly denigrating of human rights and the rule of law.[67]\n\nThe philosophy of Sentientism grants degrees of moral consideration to all sentient beings, primarily humans and most non-human animals. If artificial or alien intelligence show evidence of being sentient, this philosophy holds that they should be shown compassion and granted rights.\n\nJoanna Bryson has argued that creating AI that requires rights is both avoidable, and would in itself be unethical, both as a burden to the AI agents and to human society.[68]\n\nJoseph Weizenbaum[69] argued in 1976 that AI technology should not be used to replace people in positions that require respect and care, such as:\n\nWeizenbaum explains that we require authentic feelings of empathy from people in these positions. If machines replace them, we will find ourselves alienated, devalued and frustrated, for the artificially intelligent system would not be able to simulate empathy. Artificial intelligence, if used in this way, represents a threat to human dignity. Weizenbaum argues that the fact that we are entertaining the possibility of machines in these positions suggests that we have experienced an \"atrophy of the human spirit that comes from thinking of ourselves as computers.\"[70]\n\nPamela McCorduck counters that, speaking for women and minorities \"I'd rather take my chances with an impartial computer\", pointing out that there are conditions where we would prefer to have automated judges and police that have no personal agenda at all.[70] However, Kaplan and Haenlein stress that AI systems are only as smart as the data used to train them since they are, in their essence, nothing more than fancy curve-fitting machines; Using AI to support a court ruling can be highly problematic if past rulings show bias toward certain groups since those biases get formalized and engrained, which makes them even more difficult to spot and fight against.[71]\n\nWeizenbaum was also bothered that AI researchers (and some philosophers) were willing to view the human mind as nothing more than a computer program (a position now known as computationalism). To Weizenbaum, these points suggest that AI research devalues human life.[69]\n\nAI founder John McCarthy objects to the moralizing tone of Weizenbaum's critique. \"When moralizing is both vehement and vague, it invites authoritarian abuse,\" he writes. Bill Hibbard[72] writes that \"Human dignity requires that we strive to remove our ignorance of the nature of existence, and AI is necessary for that striving.\"\n\nAs the widespread use of autonomous cars becomes increasingly imminent, new challenges raised by fully autonomous vehicles must be addressed.[73][74] Recently,[when?] there has been debate as to the legal liability of the responsible party if these cars get into accidents.[75][76] In one report where a driverless car hit a pedestrian, the driver was inside the car but the controls were fully in the hand of computers. This led to a dilemma over who was at fault for the accident.[77]\n\nIn another incident on March 18, 2018, Elaine Herzberg was struck and killed by a self-driving Uber in Arizona. In this case, the automated car was capable of detecting cars and certain obstacles in order to autonomously navigate the roadway, but it could not anticipate a pedestrian in the middle of the road. This raised the question of whether the driver, pedestrian, the car company, or the government should be held responsible for her death.[78]\n\nCurrently, self-driving cars are considered semi-autonomous, requiring the driver to pay attention and be prepared to take control if necessary.[79][failed verification] Thus, it falls on governments to regulate the driver who over-relies on autonomous features. as well educate them that these are just technologies that, while convenient, are not a complete substitute. Before autonomous cars become widely used, these issues need to be tackled through new policies.[80][81][82]\n\nSome experts and academics have questioned the use of robots for military combat, especially when such robots are given some degree of autonomy.[13][83] On October 31, 2019, the United States Department of Defense's Defense Innovation Board published the draft of a report recommending principles for the ethical use of artificial intelligence by the Department of Defense that would ensure a human operator would always be able to look into the 'black box' and understand the kill-chain process. However, a major concern is how the report will be implemented.[84] The US Navy has funded a report which indicates that as military robots become more complex, there should be greater attention to implications of their ability to make autonomous decisions.[85][15] Some researchers state that autonomous robots might be more humane, as they could make decisions more effectively.[86]\n\nWithin this last decade, there has been intensive research in autonomous power with the ability to learn using assigned moral responsibilities. \"The results may be used when designing future military robots, to control unwanted tendencies to assign responsibility to the robots.\"[87] From a consequentialist view, there is a chance that robots will develop the ability to make their own logical decisions on whom to kill and that is why there should be a set moral framework that the AI cannot override.[88]\n\nThere has been a recent outcry with regard to the engineering of artificial intelligence weapons that have included ideas of a robot takeover of mankind. AI weapons do present a type of danger different from that of human-controlled weapons. Many governments have begun to fund programs to develop AI weaponry. The United States Navy recently announced plans to develop autonomous drone weapons, paralleling similar announcements by Russia and Korea respectively. Due to the potential of AI weapons becoming more dangerous than human-operated weapons, Stephen Hawking and Max Tegmark signed a \"Future of Life\" petition[89] to ban AI weapons. The message posted by Hawking and Tegmark states that AI weapons pose an immediate danger and that action is required to avoid catastrophic disasters in the near future.[90]\n\n\"If any major military power pushes ahead with the AI weapon development, a global arms race is virtually inevitable, and the endpoint of this technological trajectory is obvious: autonomous weapons will become the Kalashnikovs of tomorrow\", says the petition, which includes Skype co-founder Jaan Tallinn and MIT professor of linguistics Noam Chomsky as additional supporters against AI weaponry.[91]\n\nPhysicist and Astronomer Royal Sir Martin Rees has warned of catastrophic instances like \"dumb robots going rogue or a network that develops a mind of its own.\" Huw Price, a colleague of Rees at Cambridge, has voiced a similar warning that humans might not survive when intelligence \"escapes the constraints of biology\". These two professors created the Centre for the Study of Existential Risk at Cambridge University in the hope of avoiding this threat to human existence.[90]\n\nRegarding the potential for smarter-than-human systems to be employed militarily, the Open Philanthropy Project writes that these scenarios \"seem potentially as important as the risks related to loss of control\", but research investigating AI's long-run social impact have spent relatively little time on this concern: \"this class of scenarios has not been a major focus for the organizations that have been most active in this space, such as the Machine Intelligence Research Institute (MIRI) and the Future of Humanity Institute (FHI), and there seems to have been less analysis and debate regarding them\".[92]\n\nApproaches like machine learning with neural networks can result in computers making decisions that they and the humans who programmed them cannot explain. It is difficult for people to determine if such decisions are fair and trustworthy, leading potentially to bias in AI systems going undetected, or people rejecting the use of such systems. This has led to advocacy and in some jurisdictions legal requirements for explainable artificial intelligence.[93]\n\n"
        },
        {
            "title": "Singularity",
            "text": "Many researchers have argued that, by way of an \"intelligence explosion\", a self-improving AI could become so powerful that humans would not be able to stop it from achieving its goals.[94] In his paper \"Ethical Issues in Advanced Artificial Intelligence\" and subsequent book Superintelligence: Paths, Dangers, Strategies, philosopher Nick Bostrom argues that artificial intelligence has the capability to bring about human extinction. He claims that general superintelligence would be capable of independent initiative and of making its own plans, and may therefore be more appropriately thought of as an autonomous agent. Since artificial intellects need not share our human motivational tendencies, it would be up to the designers of the superintelligence to specify its original motivations. Because a superintelligent AI would be able to bring about almost any possible outcome and to thwart any attempt to prevent the implementation of its goals, many uncontrolled unintended consequences could arise. It could kill off all other agents, persuade them to change their behavior, or block their attempts at interference.[95]\n\nHowever, instead of overwhelming the human race and leading to our destruction, Bostrom has also asserted that superintelligence can help us solve many difficult problems such as disease, poverty, and environmental destruction, and could help us to \"enhance\" ourselves.[96]\n\nThe sheer complexity of human value systems makes it very difficult to make AI's motivations human-friendly.[94][95] Unless moral philosophy provides us with a flawless ethical theory, an AI's utility function could allow for many potentially harmful scenarios that conform with a given ethical framework but not \"common sense\". According to Eliezer Yudkowsky, there is little reason to suppose that an artificially designed mind would have such an adaptation.[97] AI researchers such as Stuart J. Russell,[98] Bill Hibbard,[72] Roman Yampolskiy,[99] Shannon Vallor,[100] Steven Umbrello[101] and Luciano Floridi[102] have proposed design strategies for developing beneficial machines.\n\n"
        },
        {
            "title": "Actors in AI ethics",
            "text": "There are many organisations concerned with AI ethics and policy, public and governmental as well as corporate and societal.\n\nAmazon, Google, Facebook, IBM, and Microsoft have established a non-profit, The Partnership on AI to Benefit People and Society, to formulate best practices on artificial intelligence technologies, advance the public's understanding, and to serve as a platform about artificial intelligence. Apple joined in January 2017. The corporate members will make financial and research contributions to the group, while engaging with the scientific community to bring academics onto the board.[103]\n\nThe IEEE put together a Global Initiative on Ethics of Autonomous and Intelligent Systems which has been creating and revising guidelines with the help of public input, and accepts as members many professionals from within and without its organization.\n\nTraditionally, government has been used by societies to ensure ethics are observed through legislation and policing. There are now many efforts by national governments, as well as transnational government and non-government organizations to ensure AI is ethically applied.\n\n"
        },
        {
            "title": "Role and impact of fiction",
            "text": "The role of fiction with regards to AI ethics has been a complex one. One can distinguish three levels at which fiction has impacted the development of artificial intelligence and robotics: Historically, fiction has been prefiguring common tropes that have not only influenced goals and visions for AI, but also outlined ethical questions and common fears associated with it. During the second half of the twentieth and the first decades of the twenty-first century, popular culture, in particular movies, TV series and video games have frequently echoed preoccupations and dystopian projections around ethical questions concerning AI and robotics. Recently, these themes have also been increasingly treated in literature beyond the realm of science fiction. And, as Carme Torras, research professor at the Institut de Robòtica i Informàtica Industrial (Institute of robotics and industrial computing) at the Technical University of Catalonia notes,[124] in higher education, science fiction is also increasingly used for teaching technology-related ethical issues in technological degrees.\n\nHistorically speaking, the investigation of moral and ethical implications of \"thinking machines\" goes back at least to the Enlightenment: Leibniz already poses the question if we might attribute intelligence to a mechanism that behaves as if it were a sentient being,[125] and so does Descartes, who describes what could be considered an early version of the Turing Test.[126]\n\nThe romantic period has several times envisioned artificial creatures that escape the control of their creator with dire consequences, most famously in Mary Shelley's Frankenstein. The widespread preoccupation with industrialization and mechanization in the 19th and early 20th century, however, brought ethical implications of unhinged technical developments to the forefront of fiction: R.U.R – Rossum's Universal Robots, Karel Čapek's play of sentient robots endowed with emotions used as slave labor is not only credited with the invention of the term 'robot' (derived from the Czech word for forced labor, robota) but was also an international success after it premiered in 1921. George Bernard Shaw's play Back to Methuselah, published in 1921, questions at one point the validity of thinking machines that act like humans; Fritz Lang's 1927 film Metropolis shows an android leading the uprising of the exploited masses against the oppressive regime of a technocratic society.\n\nWhile the anticipation of a future dominated by potentially indomitable technology has fueled the imagination of writers and film makers for a long time, one question has been less frequently analyzed, namely, to what extent fiction has played a role in providing inspiration for technological development. It has been documented, for instance, that the young Alan Turing saw and appreciated G.B. Shaw's play Back to Methuselah in 1933[127] (just 3 years before the publication of his first seminal paper[128] which laid the groundwork for the digital computer), and he would likely have been at least aware of plays like R.U.R., which was an international success and translated into many languages.\n\nOne might also ask the question which role science fiction played in establishing the tenets and ethical implications of AI development: Isaac Asimov conceptualized his Three Laws of Robotics in the 1942 short story  \"Runaround\", part of the short story collection  I, Robot; Arthur C. Clarke's short \"The Sentinel\", on which Stanley Kubrick's film 2001: A Space Odyssey  is based, was written in 1948 and published in 1952. Another example (among many others) would be Philip K. Dicks numerous short stories and novels – in particular Do Androids Dream of Electric Sheep?, published in 1968, and featuring its own version of a Turing Test, the Voight-Kampff Test, to gauge emotional responses of androids indistinguishable from humans. The novel later became the basis of the influential 1982 movie Blade Runner by Ridley Scott.\n\nScience fiction has been grappling with ethical implications of AI developments for decades, and thus provided a blueprint for ethical issues that might emerge once something akin to general artificial intelligence has been achieved: Spike Jonze's 2013 film Her shows what can happen if a user falls in love with the seductive voice of his smartphone operating system; Ex Machina, on the other hand, asks a more difficult question: if confronted with a clearly recognizable machine, made only human by a face and an empathetic and sensual voice, would we still be able to establish an emotional connection, still be seduced by it?  (The film echoes a theme already present two centuries earlier, in the 1817 short story \"The Sandmann\" by E.T.A. Hoffmann.)\n\nThe theme of coexistence with artificial sentient beings is also the theme of two recent novels: Machines like me by Ian McEwan, published in 2019, involves (among many other things) a love-triangle involving an artificial person as well as a human couple. Klara and the Sun by Nobel Prize winner Kazuo Ishiguro, published in 2021, is the first-person account of Klara, an 'AF' (artificial friend), who is trying, in her own way, to help the girl she is living with, who, after having been 'lifted' (i.e. having been subjected to genetic enhancements), is suffering from a strange illness.\n\nWhile ethical questions linked to AI have been featured in science fiction literature and feature films for decades, the emergence of the TV series as a genre allowing for longer and more complex story lines and character development has led to some significant contributions that deal with ethical implications of technology. The Swedish series Real Humans (2012–2013) tackled the complex ethical and social consequences linked to the integration of artificial sentient beings in society. The British dystopian science fiction anthology series Black Mirror (2013–2019) was particularly notable for experimenting with dystopian fictional developments linked to a wide variety of recent technology developments. Both the French series Osmosis (2020) and British series The One deal with the question of what can happen if technology tries to find the ideal partner for a person. Several episodes of the Netflix series Love, Death+Robots have imagined scenes of robots and humans living together. The most representative one of them is S02 E01, it shows how bad the consequences can be when robots get out of control if humans rely too much on them in their lives.[129]\n\nThe movie The Thirteenth Floor suggests a future where simulated worlds with sentient inhabitants are created by computer game consoles for the purpose of entertainment. The movie The Matrix suggests a future where the dominant species on planet Earth are sentient machines and humanity is treated with utmost speciesism. The short story \"The Planck Dive\" suggests a future where humanity has turned itself into software that can be duplicated and optimized and the relevant distinction between types of software is sentient and non-sentient. The same idea can be found in the Emergency Medical Hologram of Starship Voyager, which is an apparently sentient copy of a reduced subset of the consciousness of its creator, Dr. Zimmerman, who, for the best motives, has created the system to give medical assistance in case of emergencies. The movies Bicentennial Man and A.I. deal with the possibility of sentient robots that could love. I, Robot explored some aspects of Asimov's three laws. All these scenarios try to foresee possibly unethical consequences of the creation of sentient computers.[130]\n\nThe ethics of artificial intelligence is one of several core themes in BioWare's Mass Effect series of games.[131] It explores the scenario of a civilization accidentally creating AI through a rapid increase in computational power through a global scale neural network. This event caused an ethical schism between those who felt bestowing organic rights upon the newly sentient Geth was appropriate and those who continued to see them as disposable machinery and fought to destroy them. Beyond the initial conflict, the complexity of the relationship between the machines and their creators is another ongoing theme throughout the story.\n\nDetroit: Become Human is one of the most famous video games which discusses the ethics of artificial intelligence recently. Quantic Dream designed the chapters of the game using interactive storylines to give players a more immersive gaming experience. Players manipulate three different awakened bionic men in the face of different events to make different choices to achieve the purpose of changing the human view of the bionic group and different choices will result in different endings. This is one of the few games that puts players in the bionic perspective, which allows them to better consider the rights and interests of robots once a true artificial intelligence is created.[132]\n\nOver time, debates have tended to focus less and less on possibility and more on desirability,[133] as emphasized in the \"Cosmist\" and \"Terran\" debates initiated by Hugo de Garis and Kevin Warwick. A Cosmist, according to Hugo de Garis, is actually seeking to build more intelligent successors to the human species.\n\nExperts at the University of Cambridge have argued that AI is portrayed in fiction and nonfiction overwhelmingly as racially White, in ways that distort perceptions of its risks and benefits.[134]\n\n"
        }
    ],
    "links": [
        "https://en.wikipedia.org/wiki/Outline_of_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Artificial_general_intelligence",
        "https://en.wikipedia.org/wiki/Automated_planning_and_scheduling",
        "https://en.wikipedia.org/wiki/Computer_vision",
        "https://en.wikipedia.org/wiki/General_game_playing",
        "https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning",
        "https://en.wikipedia.org/wiki/Machine_learning",
        "https://en.wikipedia.org/wiki/Natural_language_processing",
        "https://en.wikipedia.org/wiki/Robotics",
        "https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Deep_learning",
        "https://en.wikipedia.org/wiki/Bayesian_network",
        "https://en.wikipedia.org/wiki/Evolutionary_algorithm",
        "https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Chinese_room",
        "https://en.wikipedia.org/wiki/Friendly_artificial_intelligence",
        "https://en.wikipedia.org/wiki/AI_control_problem",
        "https://en.wikipedia.org/wiki/AI_takeover",
        "https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence",
        "https://en.wikipedia.org/wiki/Turing_test",
        "https://en.wikipedia.org/wiki/History_of_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Progress_in_artificial_intelligence",
        "https://en.wikipedia.org/wiki/AI_winter",
        "https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence",
        "https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects",
        "https://en.wikipedia.org/wiki/List_of_programming_languages_for_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Ethics_of_technology",
        "https://en.wikipedia.org/wiki/Artificial_intelligence",
        "https://en.wikipedia.org/wiki/Machine_ethics",
        "https://en.wikipedia.org/wiki/Technological_singularity",
        "https://en.wikipedia.org/wiki/Superintelligence",
        "https://en.wikipedia.org/wiki/Robot_ethics",
        "https://en.wikipedia.org/wiki/Machine_ethics",
        "https://en.wikipedia.org/wiki/Rational_agent",
        "https://en.wikipedia.org/wiki/Moral_agency",
        "https://en.wikipedia.org/wiki/Isaac_Asimov",
        "https://en.wikipedia.org/wiki/Three_Laws_of_Robotics",
        "https://en.wikipedia.org/wiki/United_Kingdom",
        "https://en.wikipedia.org/wiki/Lausanne",
        "https://en.wikipedia.org/wiki/Association_for_the_Advancement_of_Artificial_Intelligence",
        "https://en.wikipedia.org/wiki/Vernor_Vinge",
        "https://en.wikipedia.org/wiki/Technological_singularity",
        "https://en.wikipedia.org/wiki/Singularitarianism",
        "https://en.wikipedia.org/wiki/Machine_Intelligence_Research_Institute",
        "https://en.wikipedia.org/wiki/Friendly_AI",
        "https://en.wikipedia.org/wiki/Ethical_decision",
        "https://en.wikipedia.org/wiki/Turing_test",
        "https://en.wikipedia.org/wiki/Association_for_the_Advancement_of_Artificial_Intelligence",
        "https://en.wikipedia.org/wiki/Neuromorphic_engineering",
        "https://en.wikipedia.org/wiki/Normative_ethics",
        "https://en.wikipedia.org/wiki/List_of_machine_learning_algorithms",
        "https://en.wikipedia.org/wiki/Nick_Bostrom",
        "https://en.wikipedia.org/wiki/Eliezer_Yudkowsky",
        "https://en.wikipedia.org/wiki/Decision_tree",
        "https://en.wikipedia.org/wiki/ID3_algorithm",
        "https://en.wikipedia.org/wiki/Artificial_neural_network",
        "https://en.wikipedia.org/wiki/Genetic_algorithm",
        "https://en.wikipedia.org/wiki/Stare_decisis",
        "https://en.wikipedia.org/wiki/Hacker_culture",
        "https://en.wikipedia.org/wiki/Luciano_Floridi",
        "https://en.wikipedia.org/wiki/Bioethics",
        "https://en.wikipedia.org/wiki/Autonomy",
        "https://en.wikipedia.org/wiki/Justice",
        "https://en.wikipedia.org/wiki/Bill_Hibbard",
        "https://en.wikipedia.org/wiki/Ben_Goertzel",
        "https://en.wikipedia.org/wiki/OpenCog",
        "https://en.wikipedia.org/wiki/OpenAI",
        "https://en.wikipedia.org/wiki/Elon_Musk",
        "https://en.wikipedia.org/wiki/Sam_Altman",
        "https://en.wikipedia.org/wiki/IEEE",
        "https://en.wikipedia.org/wiki/Technical_standards",
        "https://en.wikipedia.org/wiki/OECD",
        "https://en.wikipedia.org/wiki/UN",
        "https://en.wikipedia.org/wiki/EU",
        "https://en.wikipedia.org/wiki/Algorithmic_bias",
        "https://en.wikipedia.org/wiki/Kamala_Harris",
        "https://en.wikipedia.org/wiki/Speech_recognition",
        "https://en.wikipedia.org/wiki/Facial_recognition_system",
        "https://en.wikipedia.org/wiki/Artificial_intelligence_in_hiring",
        "https://en.wikipedia.org/wiki/Natural_language_processing",
        "https://en.wikipedia.org/wiki/Text_corpus",
        "https://en.wikipedia.org/wiki/Process_mining",
        "https://en.wikipedia.org/wiki/Algorithmic_bias",
        "https://en.wikipedia.org/wiki/Human_rights",
        "https://en.wikipedia.org/wiki/Animal_rights",
        "https://en.wikipedia.org/wiki/Institute_for_the_Future",
        "https://en.wikipedia.org/wiki/Ray_Kurzweil",
        "https://en.wikipedia.org/wiki/Loebner_Prize",
        "https://en.wikipedia.org/wiki/Saudi_Arabia",
        "https://en.wikipedia.org/wiki/Human_rights",
        "https://en.wikipedia.org/wiki/Rule_of_law",
        "https://en.wikipedia.org/wiki/Sentientism",
        "https://en.wikipedia.org/wiki/Sentience",
        "https://en.wikipedia.org/wiki/Joanna_Bryson",
        "https://en.wikipedia.org/wiki/Computer_Power_and_Human_Reason",
        "https://en.wikipedia.org/wiki/Joseph_Weizenbaum",
        "https://en.wikipedia.org/wiki/Interactive_voice_response",
        "https://en.wikipedia.org/wiki/Pamela_McCorduck",
        "https://en.wikipedia.org/wiki/Kenneth_Colby",
        "https://en.wikipedia.org/wiki/Empathy",
        "https://en.wikipedia.org/wiki/Pamela_McCorduck",
        "https://en.wikipedia.org/wiki/Andreas_Kaplan",
        "https://en.wikipedia.org/wiki/Computationalism",
        "https://en.wikipedia.org/wiki/Bill_Hibbard",
        "https://en.wikipedia.org/wiki/Elaine_Herzberg",
        "https://en.wikipedia.org/wiki/Uber",
        "https://en.wikipedia.org/wiki/Lethal_autonomous_weapon",
        "https://en.wikipedia.org/wiki/Military_robots",
        "https://en.wikipedia.org/wiki/Autonomous_robot",
        "https://en.wikipedia.org/wiki/Consequentialism",
        "https://en.wikipedia.org/wiki/Morality",
        "https://en.wikipedia.org/wiki/Unmanned_combat_aerial_vehicle",
        "https://en.wikipedia.org/wiki/Stephen_Hawking",
        "https://en.wikipedia.org/wiki/Max_Tegmark",
        "https://en.wikipedia.org/wiki/Arms_race",
        "https://en.wikipedia.org/wiki/Skype",
        "https://en.wikipedia.org/wiki/Jaan_Tallinn",
        "https://en.wikipedia.org/wiki/Noam_Chomsky",
        "https://en.wikipedia.org/wiki/Sir_Martin_Rees",
        "https://en.wikipedia.org/wiki/Huw_Price",
        "https://en.wikipedia.org/wiki/Centre_for_the_Study_of_Existential_Risk",
        "https://en.wikipedia.org/wiki/Open_Philanthropy_Project",
        "https://en.wikipedia.org/wiki/Machine_Intelligence_Research_Institute",
        "https://en.wikipedia.org/wiki/Future_of_Humanity_Institute",
        "https://en.wikipedia.org/wiki/Neural_network",
        "https://en.wikipedia.org/wiki/Explainable_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence",
        "https://en.wikipedia.org/wiki/Superintelligence",
        "https://en.wikipedia.org/wiki/Technological_singularity",
        "https://en.wikipedia.org/wiki/Nick_Bostrom",
        "https://en.wikipedia.org/wiki/Superintelligence",
        "https://en.wikipedia.org/wiki/Unintended_consequences",
        "https://en.wikipedia.org/wiki/Eliezer_Yudkowsky",
        "https://en.wikipedia.org/wiki/Bill_Hibbard",
        "https://en.wikipedia.org/wiki/Roman_Yampolskiy",
        "https://en.wikipedia.org/wiki/Shannon_Vallor",
        "https://en.wikipedia.org/wiki/Luciano_Floridi",
        "https://en.wikipedia.org/wiki/Google",
        "https://en.wikipedia.org/wiki/Facebook",
        "https://en.wikipedia.org/wiki/IBM",
        "https://en.wikipedia.org/wiki/Microsoft",
        "https://en.wikipedia.org/wiki/IEEE",
        "https://en.wikipedia.org/wiki/Government",
        "https://en.wikipedia.org/wiki/NGO",
        "https://en.wikipedia.org/wiki/European_Commission",
        "https://en.wikipedia.org/wiki/OECD",
        "https://en.wikipedia.org/wiki/United_States",
        "https://en.wikipedia.org/wiki/Obama",
        "https://en.wikipedia.org/wiki/White_papers",
        "https://en.wikipedia.org/wiki/Trump_administration",
        "https://en.wikipedia.org/wiki/Computing_Community_Consortium",
        "https://en.wikipedia.org/wiki/Center_for_Security_and_Emerging_Technology",
        "https://en.wikipedia.org/wiki/New_South_Wales",
        "https://en.wikipedia.org/wiki/Analytical_Center_for_the_Government_of_the_Russian_Federation",
        "https://en.wikipedia.org/wiki/Sberbank",
        "https://en.wikipedia.org/wiki/Yandex",
        "https://en.wikipedia.org/wiki/Rosatom",
        "https://en.wikipedia.org/wiki/Higher_School_of_Economics",
        "https://en.wikipedia.org/wiki/Moscow_Institute_of_Physics_and_Technology",
        "https://en.wikipedia.org/wiki/ITMO_University",
        "https://en.wikipedia.org/wiki/Nanosemantics",
        "https://en.wikipedia.org/wiki/Rostelecom",
        "https://en.wikipedia.org/wiki/CIAN",
        "https://en.wikipedia.org/wiki/University_of_Oxford",
        "https://en.wikipedia.org/wiki/Future_of_Humanity_Institute",
        "https://en.wikipedia.org/wiki/John_Tasioulas",
        "https://en.wikipedia.org/wiki/Oxford_Internet_Institute",
        "https://en.wikipedia.org/wiki/Luciano_Floridi",
        "https://en.wikipedia.org/wiki/AI_Now_Institute",
        "https://en.wikipedia.org/wiki/NYU",
        "https://en.wikipedia.org/wiki/Institute_for_Ethics_and_Emerging_Technologies",
        "https://en.wikipedia.org/wiki/Institute_for_Ethics_in_Artificial_Intelligence",
        "https://en.wikipedia.org/wiki/Technical_University_of_Munich",
        "https://en.wikipedia.org/wiki/Algorithmic_Justice_League",
        "https://en.wikipedia.org/wiki/Black_in_AI",
        "https://en.wikipedia.org/wiki/Data_for_Black_Lives",
        "https://en.wikipedia.org/wiki/Artificial_intelligence_in_fiction",
        "https://en.wikipedia.org/wiki/Gottfried_Wilhelm_Leibniz",
        "https://en.wikipedia.org/wiki/Mary_Shelley",
        "https://en.wikipedia.org/wiki/Frankenstein",
        "https://en.wikipedia.org/wiki/Back_to_Methuselah",
        "https://en.wikipedia.org/wiki/Three_Laws_of_Robotics",
        "https://en.wikipedia.org/wiki/Blade_Runner",
        "https://en.wikipedia.org/wiki/Machines_Like_Me",
        "https://en.wikipedia.org/wiki/Ian_McEwan",
        "https://en.wikipedia.org/wiki/Klara_and_the_Sun",
        "https://en.wikipedia.org/wiki/Nobel_Prize_in_Literature",
        "https://en.wikipedia.org/wiki/Kazuo_Ishiguro",
        "https://en.wikipedia.org/wiki/List_of_artificial_intelligence_films",
        "https://en.wikipedia.org/wiki/Real_Humans",
        "https://en.wikipedia.org/wiki/Black_Mirror",
        "https://en.wikipedia.org/wiki/The_Thirteenth_Floor",
        "https://en.wikipedia.org/wiki/Simulated_reality",
        "https://en.wikipedia.org/wiki/Game_console",
        "https://en.wikipedia.org/wiki/The_Matrix",
        "https://en.wikipedia.org/wiki/Speciesism",
        "https://en.wikipedia.org/wiki/The_Planck_Dive",
        "https://en.wikipedia.org/wiki/Emergency_Medical_Hologram",
        "https://en.wikipedia.org/wiki/Lewis_Zimmerman",
        "https://en.wikipedia.org/wiki/Mass_Effect",
        "https://en.wikipedia.org/wiki/Neural_network",
        "https://en.wikipedia.org/wiki/Hugo_de_Garis",
        "https://en.wikipedia.org/wiki/Kevin_Warwick",
        "https://en.wikipedia.org/wiki/AI_takeover",
        "https://en.wikipedia.org/wiki/Artificial_consciousness",
        "https://en.wikipedia.org/wiki/Artificial_general_intelligence",
        "https://en.wikipedia.org/wiki/Computer_ethics",
        "https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence",
        "https://en.wikipedia.org/wiki/Human_Compatible",
        "https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Robotic_governance",
        "https://en.wikipedia.org/wiki/Timnit_Gebru",
        "https://en.wikipedia.org/wiki/Joy_Buolamwini",
        "https://en.wikipedia.org/wiki/Deb_Raji",
        "https://en.wikipedia.org/wiki/Ruha_Benjamin",
        "https://en.wikipedia.org/wiki/Safiya_Noble",
        "https://en.wikipedia.org/wiki/Meredith_Whittaker",
        "https://en.wikipedia.org/wiki/Alison_Adam",
        "https://en.wikipedia.org/wiki/Seth_Baum",
        "https://en.wikipedia.org/wiki/Nick_Bostrom",
        "https://en.wikipedia.org/wiki/Joanna_Bryson",
        "https://en.wikipedia.org/wiki/Kate_Crawford",
        "https://en.wikipedia.org/wiki/Kate_Darling",
        "https://en.wikipedia.org/wiki/Luciano_Floridi",
        "https://en.wikipedia.org/wiki/Anja_Kaspersen",
        "https://en.wikipedia.org/wiki/Ray_Kurzweil",
        "https://en.wikipedia.org/wiki/Catherine_Malabou",
        "https://en.wikipedia.org/wiki/Ajung_Moon",
        "https://en.wikipedia.org/wiki/Peter_Norvig",
        "https://en.wikipedia.org/wiki/Steve_Omohundro",
        "https://en.wikipedia.org/wiki/Anders_Sandberg",
        "https://en.wikipedia.org/wiki/Mariarosaria_Taddeo",
        "https://en.wikipedia.org/wiki/John_Tasioulas",
        "https://en.wikipedia.org/wiki/Roman_Yampolskiy",
        "https://en.wikipedia.org/wiki/Eliezer_Yudkowsky",
        "https://en.wikipedia.org/wiki/Center_for_Security_and_Emerging_Technology",
        "https://en.wikipedia.org/wiki/Centre_for_the_Study_of_Existential_Risk",
        "https://en.wikipedia.org/wiki/Future_of_Humanity_Institute",
        "https://en.wikipedia.org/wiki/Future_of_Life_Institute",
        "https://en.wikipedia.org/wiki/Machine_Intelligence_Research_Institute",
        "https://en.wikipedia.org/wiki/Partnership_on_AI",
        "https://en.wikipedia.org/wiki/Leverhulme_Centre_for_the_Future_of_Intelligence",
        "https://en.wikipedia.org/wiki/Institute_for_Ethics_and_Emerging_Technologies",
        "https://en.wikipedia.org/wiki/Oxford_Internet_Institute",
        "https://en.wikipedia.org/wiki/Cambridge_University_Press",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Oxford_University_Press",
        "https://en.wikipedia.org/wiki/Nick_Bostrom",
        "https://en.wikipedia.org/wiki/Eliezer_Yudkowsky",
        "https://en.wikipedia.org/wiki/Cambridge_Press",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Hanna_Wallach",
        "https://en.wikipedia.org/wiki/Woody_Evans",
        "https://en.wikipedia.org/wiki/Ray_Kurzweil",
        "https://en.wikipedia.org/wiki/The_Singularity_is_Near",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/David_Hamill",
        "https://en.wikipedia.org/wiki/Joseph_Weizenbaum",
        "https://en.wikipedia.org/wiki/Computer_Power_and_Human_Reason",
        "https://en.wikipedia.org/wiki/Pamela_McCorduck",
        "https://en.wikipedia.org/wiki/Joseph_Weizenbaum",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/GiveWell",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Human_Compatible",
        "https://en.wikipedia.org/wiki/Kommersant",
        "https://en.wikipedia.org/wiki/Internet_Encyclopedia_of_Philosophy",
        "https://en.wikipedia.org/wiki/Stanford_Encyclopedia_of_Philosophy",
        "https://en.wikipedia.org/wiki/Wayback_Machine",
        "https://en.wikipedia.org/wiki/Ethics",
        "https://en.wikipedia.org/wiki/Normative_ethics",
        "https://en.wikipedia.org/wiki/Consequentialism",
        "https://en.wikipedia.org/wiki/Utilitarianism",
        "https://en.wikipedia.org/wiki/Deontological_ethics",
        "https://en.wikipedia.org/wiki/Kantian_ethics",
        "https://en.wikipedia.org/wiki/Ethics_of_care",
        "https://en.wikipedia.org/wiki/Existentialism",
        "https://en.wikipedia.org/wiki/Moral_particularism",
        "https://en.wikipedia.org/wiki/Pragmatic_ethics",
        "https://en.wikipedia.org/wiki/Role_ethics",
        "https://en.wikipedia.org/wiki/Virtue_ethics",
        "https://en.wikipedia.org/wiki/Eudaimonia",
        "https://en.wikipedia.org/wiki/Applied_ethics",
        "https://en.wikipedia.org/wiki/Animal_ethics",
        "https://en.wikipedia.org/wiki/Bioethics",
        "https://en.wikipedia.org/wiki/Business_ethics",
        "https://en.wikipedia.org/wiki/Discourse_ethics",
        "https://en.wikipedia.org/wiki/Engineering_ethics",
        "https://en.wikipedia.org/wiki/Environmental_ethics",
        "https://en.wikipedia.org/wiki/Legal_ethics",
        "https://en.wikipedia.org/wiki/Machine_ethics",
        "https://en.wikipedia.org/wiki/Media_ethics",
        "https://en.wikipedia.org/wiki/Medical_ethics",
        "https://en.wikipedia.org/wiki/Nursing_ethics",
        "https://en.wikipedia.org/wiki/Professional_ethics",
        "https://en.wikipedia.org/wiki/Sexual_ethics",
        "https://en.wikipedia.org/wiki/Ethics_of_eating_meat",
        "https://en.wikipedia.org/wiki/Ethics_of_technology",
        "https://en.wikipedia.org/wiki/Ethics_of_terraforming",
        "https://en.wikipedia.org/wiki/Ethics_of_uncertain_sentience",
        "https://en.wikipedia.org/wiki/Moral_realism",
        "https://en.wikipedia.org/wiki/Ethical_naturalism",
        "https://en.wikipedia.org/wiki/Ethical_subjectivism",
        "https://en.wikipedia.org/wiki/Ideal_observer_theory",
        "https://en.wikipedia.org/wiki/Divine_command_theory",
        "https://en.wikipedia.org/wiki/Error_theory",
        "https://en.wikipedia.org/wiki/Emotivism",
        "https://en.wikipedia.org/wiki/Expressivism",
        "https://en.wikipedia.org/wiki/Universal_prescriptivism",
        "https://en.wikipedia.org/wiki/Moral_universalism",
        "https://en.wikipedia.org/wiki/Value_pluralism",
        "https://en.wikipedia.org/wiki/Moral_constructivism",
        "https://en.wikipedia.org/wiki/Moral_relativism",
        "https://en.wikipedia.org/wiki/Moral_nihilism",
        "https://en.wikipedia.org/wiki/Moral_rationalism",
        "https://en.wikipedia.org/wiki/Ethical_intuitionism",
        "https://en.wikipedia.org/wiki/Moral_skepticism",
        "https://en.wikipedia.org/wiki/Index_of_ethics_articles",
        "https://en.wikipedia.org/wiki/Autonomy",
        "https://en.wikipedia.org/wiki/Axiology",
        "https://en.wikipedia.org/wiki/Conscience",
        "https://en.wikipedia.org/wiki/Consent",
        "https://en.wikipedia.org/wiki/Egalitarianism",
        "https://en.wikipedia.org/wiki/Free_will",
        "https://en.wikipedia.org/wiki/Good_and_evil",
        "https://en.wikipedia.org/wiki/Good",
        "https://en.wikipedia.org/wiki/Evil",
        "https://en.wikipedia.org/wiki/Happiness",
        "https://en.wikipedia.org/wiki/Immorality",
        "https://en.wikipedia.org/wiki/Justice",
        "https://en.wikipedia.org/wiki/Liberty",
        "https://en.wikipedia.org/wiki/Morality",
        "https://en.wikipedia.org/wiki/Political_freedom",
        "https://en.wikipedia.org/wiki/Suffering",
        "https://en.wikipedia.org/wiki/Stewardship",
        "https://en.wikipedia.org/wiki/Sympathy",
        "https://en.wikipedia.org/wiki/Virtue",
        "https://en.wikipedia.org/wiki/Wrongdoing",
        "https://en.wikipedia.org/wiki/List_of_ethicists",
        "https://en.wikipedia.org/wiki/Laozi",
        "https://en.wikipedia.org/wiki/Socrates",
        "https://en.wikipedia.org/wiki/Plato",
        "https://en.wikipedia.org/wiki/Aristotle",
        "https://en.wikipedia.org/wiki/Diogenes",
        "https://en.wikipedia.org/wiki/Thiruvalluvar",
        "https://en.wikipedia.org/wiki/Cicero",
        "https://en.wikipedia.org/wiki/Confucius",
        "https://en.wikipedia.org/wiki/Augustine_of_Hippo",
        "https://en.wikipedia.org/wiki/Mencius",
        "https://en.wikipedia.org/wiki/Mozi",
        "https://en.wikipedia.org/wiki/Xun_Kuang",
        "https://en.wikipedia.org/wiki/Thomas_Aquinas",
        "https://en.wikipedia.org/wiki/Baruch_Spinoza",
        "https://en.wikipedia.org/wiki/David_Hume",
        "https://en.wikipedia.org/wiki/Immanuel_Kant",
        "https://en.wikipedia.org/wiki/Georg_Wilhelm_Friedrich_Hegel",
        "https://en.wikipedia.org/wiki/Arthur_Schopenhauer",
        "https://en.wikipedia.org/wiki/Jeremy_Bentham",
        "https://en.wikipedia.org/wiki/John_Stuart_Mill",
        "https://en.wikipedia.org/wiki/Henry_Sidgwick",
        "https://en.wikipedia.org/wiki/Friedrich_Nietzsche",
        "https://en.wikipedia.org/wiki/Karl_Barth",
        "https://en.wikipedia.org/wiki/Paul_Tillich",
        "https://en.wikipedia.org/wiki/Dietrich_Bonhoeffer",
        "https://en.wikipedia.org/wiki/Philippa_Foot",
        "https://en.wikipedia.org/wiki/John_Rawls",
        "https://en.wikipedia.org/wiki/John_Dewey",
        "https://en.wikipedia.org/wiki/Bernard_Williams",
        "https://en.wikipedia.org/wiki/William_Frankena",
        "https://en.wikipedia.org/wiki/Alasdair_MacIntyre",
        "https://en.wikipedia.org/wiki/Peter_Singer",
        "https://en.wikipedia.org/wiki/Derek_Parfit",
        "https://en.wikipedia.org/wiki/Thomas_Nagel",
        "https://en.wikipedia.org/wiki/Robert_Merrihew_Adams",
        "https://en.wikipedia.org/wiki/Joxe_Azurmendi",
        "https://en.wikipedia.org/wiki/Christine_Korsgaard",
        "https://en.wikipedia.org/wiki/Martha_Nussbaum",
        "https://en.wikipedia.org/wiki/Casuistry",
        "https://en.wikipedia.org/wiki/Christian_ethics",
        "https://en.wikipedia.org/wiki/Descriptive_ethics",
        "https://en.wikipedia.org/wiki/Ethics_in_religion",
        "https://en.wikipedia.org/wiki/Evolutionary_ethics",
        "https://en.wikipedia.org/wiki/Feminist_ethics",
        "https://en.wikipedia.org/wiki/History_of_ethics",
        "https://en.wikipedia.org/wiki/Ideology",
        "https://en.wikipedia.org/wiki/Islamic_ethics",
        "https://en.wikipedia.org/wiki/Jewish_ethics",
        "https://en.wikipedia.org/wiki/Moral_psychology",
        "https://en.wikipedia.org/wiki/Philosophy_of_law",
        "https://en.wikipedia.org/wiki/Political_philosophy",
        "https://en.wikipedia.org/wiki/Population_ethics",
        "https://en.wikipedia.org/wiki/Social_philosophy",
        "https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence",
        "https://en.wikipedia.org/wiki/Artificial_intelligence",
        "https://en.wikipedia.org/wiki/AI_alignment",
        "https://en.wikipedia.org/wiki/AI_capability_control",
        "https://en.wikipedia.org/wiki/AI_takeover",
        "https://en.wikipedia.org/wiki/Accelerating_change",
        "https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence",
        "https://en.wikipedia.org/wiki/Friendly_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Instrumental_convergence",
        "https://en.wikipedia.org/wiki/Intelligence_explosion",
        "https://en.wikipedia.org/wiki/Machine_ethics",
        "https://en.wikipedia.org/wiki/Superintelligence",
        "https://en.wikipedia.org/wiki/Technological_singularity",
        "https://en.wikipedia.org/wiki/Allen_Institute_for_AI",
        "https://en.wikipedia.org/wiki/Center_for_Applied_Rationality",
        "https://en.wikipedia.org/wiki/Centre_for_the_Study_of_Existential_Risk",
        "https://en.wikipedia.org/wiki/DeepMind",
        "https://en.wikipedia.org/wiki/Foundational_Questions_Institute",
        "https://en.wikipedia.org/wiki/Future_of_Humanity_Institute",
        "https://en.wikipedia.org/wiki/Future_of_Life_Institute",
        "https://en.wikipedia.org/wiki/Institute_for_Ethics_and_Emerging_Technologies",
        "https://en.wikipedia.org/wiki/Leverhulme_Centre_for_the_Future_of_Intelligence",
        "https://en.wikipedia.org/wiki/Machine_Intelligence_Research_Institute",
        "https://en.wikipedia.org/wiki/OpenAI",
        "https://en.wikipedia.org/wiki/Slate_Star_Codex",
        "https://en.wikipedia.org/wiki/Nick_Bostrom",
        "https://en.wikipedia.org/wiki/Sam_Harris",
        "https://en.wikipedia.org/wiki/Stephen_Hawking",
        "https://en.wikipedia.org/wiki/Bill_Hibbard",
        "https://en.wikipedia.org/wiki/Bill_Joy",
        "https://en.wikipedia.org/wiki/Elon_Musk",
        "https://en.wikipedia.org/wiki/Steve_Omohundro",
        "https://en.wikipedia.org/wiki/Huw_Price",
        "https://en.wikipedia.org/wiki/Martin_Rees",
        "https://en.wikipedia.org/wiki/Jaan_Tallinn",
        "https://en.wikipedia.org/wiki/Max_Tegmark",
        "https://en.wikipedia.org/wiki/Frank_Wilczek",
        "https://en.wikipedia.org/wiki/Roman_Yampolskiy",
        "https://en.wikipedia.org/wiki/Andrew_Yang",
        "https://en.wikipedia.org/wiki/Eliezer_Yudkowsky",
        "https://en.wikipedia.org/wiki/Suffering_risks",
        "https://en.wikipedia.org/wiki/Human_Compatible",
        "https://en.wikipedia.org/wiki/Open_Letter_on_Artificial_Intelligence",
        "https://en.wikipedia.org/wiki/Our_Final_Invention",
        "https://en.wikipedia.org/wiki/Philosophy_of_science",
        "https://en.wikipedia.org/wiki/Philosophical_analysis",
        "https://en.wikipedia.org/wiki/A_priori_and_a_posteriori",
        "https://en.wikipedia.org/wiki/Causality",
        "https://en.wikipedia.org/wiki/Consilience",
        "https://en.wikipedia.org/wiki/Creative_synthesis",
        "https://en.wikipedia.org/wiki/Demarcation_problem",
        "https://en.wikipedia.org/wiki/Empirical_evidence",
        "https://en.wikipedia.org/wiki/Explanatory_power",
        "https://en.wikipedia.org/wiki/Fact",
        "https://en.wikipedia.org/wiki/Falsifiability",
        "https://en.wikipedia.org/wiki/Feminist_method",
        "https://en.wikipedia.org/wiki/Functional_contextualism",
        "https://en.wikipedia.org/wiki/Ignoramus_et_ignorabimus",
        "https://en.wikipedia.org/wiki/Inductive_reasoning",
        "https://en.wikipedia.org/wiki/Intertheoretic_reduction",
        "https://en.wikipedia.org/wiki/Inquiry",
        "https://en.wikipedia.org/wiki/Observation",
        "https://en.wikipedia.org/wiki/Paradigm",
        "https://en.wikipedia.org/wiki/Problem_of_induction",
        "https://en.wikipedia.org/wiki/Scientific_law",
        "https://en.wikipedia.org/wiki/Scientific_method",
        "https://en.wikipedia.org/wiki/Scientific_pluralism",
        "https://en.wikipedia.org/wiki/Scientific_revolution",
        "https://en.wikipedia.org/wiki/Scientific_theory",
        "https://en.wikipedia.org/wiki/Testability",
        "https://en.wikipedia.org/wiki/Theory_choice",
        "https://en.wikipedia.org/wiki/Underdetermination",
        "https://en.wikipedia.org/wiki/Unity_of_science",
        "https://en.wikipedia.org/wiki/Coherentism",
        "https://en.wikipedia.org/wiki/Confirmation_holism",
        "https://en.wikipedia.org/wiki/Constructive_empiricism",
        "https://en.wikipedia.org/wiki/Constructive_realism",
        "https://en.wikipedia.org/wiki/Constructivist_epistemology",
        "https://en.wikipedia.org/wiki/Contextualism",
        "https://en.wikipedia.org/wiki/Conventionalism",
        "https://en.wikipedia.org/wiki/Inductionism",
        "https://en.wikipedia.org/wiki/Epistemological_anarchism",
        "https://en.wikipedia.org/wiki/Evolutionism",
        "https://en.wikipedia.org/wiki/Fallibilism",
        "https://en.wikipedia.org/wiki/Foundationalism",
        "https://en.wikipedia.org/wiki/Instrumentalism",
        "https://en.wikipedia.org/wiki/Pragmatism",
        "https://en.wikipedia.org/wiki/Physicalism",
        "https://en.wikipedia.org/wiki/Positivism",
        "https://en.wikipedia.org/wiki/Reductionism",
        "https://en.wikipedia.org/wiki/Determinism",
        "https://en.wikipedia.org/wiki/Rationalism",
        "https://en.wikipedia.org/wiki/Empiricism",
        "https://en.wikipedia.org/wiki/Received_view_of_theories",
        "https://en.wikipedia.org/wiki/Semantic_view_of_theories",
        "https://en.wikipedia.org/wiki/Scientific_realism",
        "https://en.wikipedia.org/wiki/Scientific_essentialism",
        "https://en.wikipedia.org/wiki/Scientific_formalism",
        "https://en.wikipedia.org/wiki/Scientific_skepticism",
        "https://en.wikipedia.org/wiki/Scientism",
        "https://en.wikipedia.org/wiki/Uniformitarianism",
        "https://en.wikipedia.org/wiki/Vitalism",
        "https://en.wikipedia.org/wiki/Philosophy_of_physics",
        "https://en.wikipedia.org/wiki/Philosophy_of_thermal_and_statistical_physics",
        "https://en.wikipedia.org/wiki/Philosophy_of_motion",
        "https://en.wikipedia.org/wiki/Philosophy_of_chemistry",
        "https://en.wikipedia.org/wiki/Philosophy_of_biology",
        "https://en.wikipedia.org/wiki/Philosophy_of_geography",
        "https://en.wikipedia.org/wiki/Philosophy_of_social_science",
        "https://en.wikipedia.org/wiki/Philosophy_of_technology",
        "https://en.wikipedia.org/wiki/Philosophy_of_engineering",
        "https://en.wikipedia.org/wiki/Philosophy_of_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Philosophy_of_computer_science",
        "https://en.wikipedia.org/wiki/Philosophy_of_information",
        "https://en.wikipedia.org/wiki/Philosophy_of_mind",
        "https://en.wikipedia.org/wiki/Philosophy_of_psychiatry",
        "https://en.wikipedia.org/wiki/Philosophy_of_psychology",
        "https://en.wikipedia.org/wiki/Philosophy_of_perception",
        "https://en.wikipedia.org/wiki/Philosophy_of_space_and_time",
        "https://en.wikipedia.org/wiki/Index_of_philosophy_of_science_articles",
        "https://en.wikipedia.org/wiki/Alchemy",
        "https://en.wikipedia.org/wiki/Criticism_of_science",
        "https://en.wikipedia.org/wiki/Descriptive_research",
        "https://en.wikipedia.org/wiki/Epistemology",
        "https://en.wikipedia.org/wiki/Faith_and_rationality",
        "https://en.wikipedia.org/wiki/Hard_and_soft_science",
        "https://en.wikipedia.org/wiki/History_and_philosophy_of_science",
        "https://en.wikipedia.org/wiki/History_of_science",
        "https://en.wikipedia.org/wiki/History_of_evolutionary_thought",
        "https://en.wikipedia.org/wiki/Logic",
        "https://en.wikipedia.org/wiki/Metaphysics",
        "https://en.wikipedia.org/wiki/Normative_science",
        "https://en.wikipedia.org/wiki/Pseudoscience",
        "https://en.wikipedia.org/wiki/Relationship_between_religion_and_science",
        "https://en.wikipedia.org/wiki/Rhetoric_of_science",
        "https://en.wikipedia.org/wiki/Science_studies",
        "https://en.wikipedia.org/wiki/Sociology_of_scientific_knowledge",
        "https://en.wikipedia.org/wiki/Sociology_of_scientific_ignorance",
        "https://en.wikipedia.org/wiki/List_of_philosophers_of_science",
        "https://en.wikipedia.org/wiki/Plato",
        "https://en.wikipedia.org/wiki/Aristotle",
        "https://en.wikipedia.org/wiki/Stoicism",
        "https://en.wikipedia.org/wiki/Epicureanism",
        "https://en.wikipedia.org/wiki/Epicurus",
        "https://en.wikipedia.org/wiki/Averroes",
        "https://en.wikipedia.org/wiki/Avicenna",
        "https://en.wikipedia.org/wiki/Roger_Bacon",
        "https://en.wikipedia.org/wiki/William_of_Ockham",
        "https://en.wikipedia.org/wiki/Hugh_of_Saint_Victor",
        "https://en.wikipedia.org/wiki/Dominicus_Gundissalinus",
        "https://en.wikipedia.org/wiki/Robert_Kilwardby",
        "https://en.wikipedia.org/wiki/Francis_Bacon",
        "https://en.wikipedia.org/wiki/Thomas_Hobbes",
        "https://en.wikipedia.org/wiki/Galileo_Galilei",
        "https://en.wikipedia.org/wiki/Pierre_Gassendi",
        "https://en.wikipedia.org/wiki/Isaac_Newton",
        "https://en.wikipedia.org/wiki/David_Hume",
        "https://en.wikipedia.org/wiki/Immanuel_Kant",
        "https://en.wikipedia.org/wiki/Friedrich_Wilhelm_Joseph_Schelling",
        "https://en.wikipedia.org/wiki/William_Whewell",
        "https://en.wikipedia.org/wiki/Auguste_Comte",
        "https://en.wikipedia.org/wiki/John_Stuart_Mill",
        "https://en.wikipedia.org/wiki/Herbert_Spencer",
        "https://en.wikipedia.org/wiki/Wilhelm_Wundt",
        "https://en.wikipedia.org/wiki/Charles_Sanders_Peirce",
        "https://en.wikipedia.org/wiki/Wilhelm_Windelband",
        "https://en.wikipedia.org/wiki/Pierre_Duhem",
        "https://en.wikipedia.org/wiki/Rudolf_Steiner",
        "https://en.wikipedia.org/wiki/Karl_Pearson",
        "https://en.wikipedia.org/wiki/Alfred_North_Whitehead",
        "https://en.wikipedia.org/wiki/Bertrand_Russell",
        "https://en.wikipedia.org/wiki/Albert_Einstein",
        "https://en.wikipedia.org/wiki/Otto_Neurath",
        "https://en.wikipedia.org/wiki/Michael_Polanyi",
        "https://en.wikipedia.org/wiki/Hans_Reichenbach",
        "https://en.wikipedia.org/wiki/Rudolf_Carnap",
        "https://en.wikipedia.org/wiki/Karl_Popper",
        "https://en.wikipedia.org/wiki/Carl_Gustav_Hempel",
        "https://en.wikipedia.org/wiki/Willard_Van_Orman_Quine",
        "https://en.wikipedia.org/wiki/Thomas_Kuhn",
        "https://en.wikipedia.org/wiki/Imre_Lakatos",
        "https://en.wikipedia.org/wiki/Paul_Feyerabend",
        "https://en.wikipedia.org/wiki/Ian_Hacking",
        "https://en.wikipedia.org/wiki/Bas_van_Fraassen",
        "https://en.wikipedia.org/wiki/Larry_Laudan",
        "https://en.wikipedia.org/wiki/Daniel_Dennett",
        "https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence",
        "https://en.wikipedia.org/wiki/Main_Page",
        "https://en.wikipedia.org/wiki/Main_Page"
    ]
}