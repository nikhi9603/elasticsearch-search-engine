{
    "url": "https://en.wikipedia.org/wiki/Usenet",
    "title": "Usenet",
    "table_of_contents": [
        "1 Introduction",
        "2 ISPs, news servers, and newsfeeds",
        "2.1 Newsreaders",
        "2.2 Moderated and unmoderated newsgroups",
        "2.3 Technical details",
        "2.4 Organization",
        "2.5 Binary content",
        "2.5.1 Binary retention time",
        "2.5.2 Legal issues",
        "3 History",
        "3.1 Network",
        "3.2 Software",
        "3.3 Public venue",
        "3.4 Internet jargon and history",
        "3.5 Decline",
        "4 Usenet traffic changes",
        "5 Archives",
        "5.1 Archives by Google Groups and Deja News",
        "6 See also",
        "6.1 Usenet newsreaders",
        "6.2 Usenet/newsgroup service providers",
        "6.3 Usenet history",
        "6.4 Usenet administrators",
        "7 References",
        "8 Further reading",
        "9 External links"
    ],
    "paragraphs": [
        {
            "title": "",
            "text": "\n\nUsenet (/ˈjuːznɛt/) is a worldwide distributed discussion system available on computers. It was developed from the general-purpose Unix-to-Unix Copy (UUCP) dial-up network architecture. Tom Truscott and Jim Ellis conceived the idea in 1979, and it was established in 1980.[1] Users read and post messages (called articles or posts, and collectively termed news) to one or more topic categories, known as newsgroups. Usenet resembles a bulletin board system (BBS) in many respects and is the precursor to the Internet forums that have become widely used. Discussions are threaded, as with web forums and BBSs, though posts are stored on the server sequentially.[2][3]\n\nA major difference between a BBS or web message board and Usenet is the absence of a central server and dedicated administrator or hosting provider. Usenet is distributed among a large, constantly changing set of news servers that store and forward messages to one another via \"news feeds\". Individual users may read messages from and post to a local (or simply preferred) news server, which can be operated by anyone, and those posts will automatically be forwarded to any other news servers peered with the local one, while the local server will receive any news its peers have that it currently lacks. This results in the automatic proliferation of content posted by any user on any server to any other user subscribed to the same newsgroups on other servers.\n\nAs with BBSs and message boards, individual news servers or service providers are under no obligation to carry any specific content, and may refuse to do so for many reasons: a news server might attempt to control the spread of spam by refusing to accept or forward any posts that trigger spam filters, or a server without high-capacity data storage may refuse to carry any newsgroups used primarily for file sharing, limiting itself to discussion-oriented groups. However, unlike BBSs and web forums, the dispersed nature of Usenet usually permits users who are interested in receiving some content to access it simply by choosing to connect to news servers that carry the feeds they want.\n\nUsenet is culturally and historically significant in the networked world, having given rise to, or popularized, many widely recognized concepts and terms such as \"FAQ\", \"flame\", sockpuppet, and \"spam\".[4]  In the early 1990s, shortly before access to the Internet became commonly affordable, Usenet connections via Fidonet's dial-up BBS networks made long-distance or worldwide discussions and other communication widespread, not needing a server, just (local) telephone service.[5]\n\nThe name Usenet comes from the term \"users' network\".[2] The first Usenet group was NET.general, which quickly became net.general.[6] The first commercial spam on Usenet was from immigration attorneys Canter and Siegel advertising green card services.[6]\n\nOn the Internet, Usenet is transported via the Network News Transfer Protocol (NNTP) on TCP Port 119 for standard, unprotected connections and on TCP port 563 for SSL encrypted connections.\n\n"
        },
        {
            "title": "Introduction",
            "text": "Usenet was conceived in 1979 and publicly established in 1980, at the University of North Carolina at Chapel Hill and Duke University,[7][1] over a decade before the World Wide Web went online (and thus before the general public received access to the Internet), making it one of the oldest computer network communications systems still in widespread use. It was originally built on the \"poor man's ARPANET\", employing UUCP as its transport protocol to offer mail and file transfers, as well as announcements through the newly developed news software such as A News. The name \"Usenet\" emphasizes its creators' hope that the USENIX organization would take an active role in its operation.[8]\n\nThe articles that users post to Usenet are organized into topical categories known as newsgroups, which are themselves logically organized into hierarchies of subjects. For instance, sci.math and sci.physics are within the sci.* hierarchy. Or, talk.origins and talk.atheism are in the talk.* hierarchy. When a user subscribes to a newsgroup, the news client software keeps track of which articles that user has read.[9]\n\nIn most newsgroups, the majority of the articles are responses to some other article. The set of articles that can be traced to one single non-reply article is called a thread. Most modern newsreaders display the articles arranged into threads and subthreads.  For example, in the wine-making newsgroup rec.crafts.winemaking, someone might start a thread called; \"What's the best yeast?\" and that thread or conversation might grow into dozens of replies long, by perhaps six or eight different authors. Over several days, that conversation about different wine yeasts might branch into several sub-threads in a tree-like form.\n\nWhen a user posts an article, it is initially only available on that user's news server. Each news server talks to one or more other servers (its \"newsfeeds\") and exchanges articles with them. In this fashion, the article is copied from server to server and should eventually reach every server in the network. The later peer-to-peer networks operate on a similar principle, but for Usenet it is normally the sender, rather than the receiver, who initiates transfers. Usenet was designed under conditions when networks were much slower and not always available. Many sites on the original Usenet network would connect only once or twice a day to batch-transfer messages in and out.[10] This is largely because the POTS network was typically used for transfers, and phone charges were lower at night.\n\nThe format and transmission of Usenet articles is similar to that of Internet e-mail messages. The difference between the two is that Usenet articles can be read by any user whose news server carries the group to which the message was posted, as opposed to email messages, which have one or more specific recipients.[11]\n\nToday, Usenet has diminished in importance with respect to Internet forums, blogs, mailing lists and social media. Usenet differs from such media in several ways: Usenet requires no personal registration with the group concerned; information need not be stored on a remote server; archives are always available; and reading the messages does not require a mail or web client, but a news client. However, it is now possible to read and participate in Usenet newsgroups to a large degree using ordinary web browsers since most newsgroups are now copied to several web sites.[12]  The groups in alt.binaries are still widely used for data transfer.\n\n"
        },
        {
            "title": "",
            "text": "Many Internet service providers, and many other Internet sites, operate news servers for their users to access. ISPs that do not operate their own servers directly will often offer their users an account from another provider that specifically operates newsfeeds. In early news implementations, the server and newsreader were a single program suite, running on the same system. Today, one uses separate newsreader client software, a program that resembles an email client but accesses Usenet servers instead.[13]\n\nNot all ISPs run news servers. A news server is one of the most difficult Internet services to administer because of the large amount of data involved, small customer base (compared to mainstream Internet service), and a disproportionately high volume of customer support incidents (frequently complaining of missing news articles). Some ISPs outsource news operations to specialist sites, which will usually appear to a user as though the ISP itself runs the server. Many of these sites carry a restricted newsfeed, with a limited number of newsgroups. Commonly omitted from such a newsfeed are foreign-language newsgroups and the alt.binaries hierarchy which largely carries software, music, videos and images, and accounts for over 99 percent of article data.\n\nThere are also Usenet providers that offer a full unrestricted service to users whose ISPs do not carry news, or that carry a restricted feed.\n\nNewsgroups are typically accessed with newsreaders: applications that allow users to read and reply to postings in newsgroups. These applications act as clients to one or more news servers. Historically, Usenet was associated with the Unix operating system developed at AT&T, but newsreaders were soon available for all major operating systems.[14] Email client programs and Internet suites of the late 1990s and 2000s often included an integrated newsreader. Newsgroup enthusiasts often criticized these as inferior to standalone newsreaders that made correct use of Usenet protocols, standards and conventions.[15]\n\nWith the rise of the World Wide Web (WWW), web front-ends (web2news) have become more common. Web front ends have lowered the technical entry barrier requirements to that of one application and no Usenet NNTP server account. There are numerous websites now offering web based gateways to Usenet groups, although some people have begun filtering messages made by some of the web interfaces for one reason or another.[16][17] Google Groups[18] is one such web based front end and some web browsers can access Google Groups via news: protocol links directly.[19]\n\nA minority of newsgroups are moderated, meaning that messages submitted by readers are not distributed directly to Usenet, but instead are emailed to the moderators of the newsgroup for approval. The moderator is to receive submitted articles, review them, and inject approved articles so that they can be properly propagated worldwide. Articles approved by a moderator must bear the Approved: header line. Moderators ensure that the messages that readers see in the newsgroup conform to the charter of the newsgroup, though they are not required to follow any such rules or guidelines.[20] Typically, moderators are appointed in the proposal for the newsgroup, and changes of moderators follow a succession plan.[21]\n\nHistorically, a mod.* hierarchy existed before Usenet reorganization.[22] Now, moderated newsgroups may appear in any hierarchy, typically with .moderated added to the group name.\n\nUsenet newsgroups in the Big-8 hierarchy are created by proposals called a Request for Discussion, or RFD. The RFD is required to have the following information: newsgroup name, checkgroups file entry, and moderated or unmoderated status. If the group is to be moderated, then at least one moderator with a valid email address must be provided. Other information which is beneficial but not required includes: a charter, a rationale, and a moderation policy if the group is to be moderated.[23] Discussion of the new newsgroup proposal follows, and is finished with the members of the Big-8 Management Board making the decision, by vote, to either approve or disapprove the new newsgroup.\n\nUnmoderated newsgroups form the majority of Usenet newsgroups, and messages submitted by readers for unmoderated newsgroups are immediately propagated for everyone to see. Minimal editorial content filtering vs propagation speed form one crux of the Usenet community. One little cited defense of propagation is canceling a propagated message, but few Usenet users use this command and some news readers do not offer cancellation commands, in part because article storage expires in relatively short order anyway. Almost all unmoderated Usenet groups tend to receive large amounts of spam.[24][25][26]\n\nUsenet is a set of protocols for generating, storing and retrieving news \"articles\" (which resemble Internet mail messages) and for exchanging them among a readership which is potentially widely distributed. These protocols most commonly use a flooding algorithm which propagates copies throughout a network of participating servers. Whenever a message reaches a server, that server forwards the message to all its network neighbors that haven't yet seen the article. Only one copy of a message is stored per server, and each server makes it available on demand to the (typically local) readers able to access that server. The collection of Usenet servers has thus a certain peer-to-peer character in that they share resources by exchanging them, the granularity of exchange however is on a different scale than a modern peer-to-peer system and this characteristic excludes the actual users of the system who connect to the news servers with a typical client-server application, much like an email reader.\n\nRFC 850 was the first formal specification of the messages exchanged by Usenet servers. It was superseded by RFC 1036 and subsequently by RFC 5536 and RFC 5537.\n\nIn cases where unsuitable content has been posted, Usenet has support for automated removal of a posting from the whole network by creating a cancel message, although due to a lack of authentication and resultant abuse, this capability is frequently disabled. Copyright holders may still request the manual deletion of infringing material using the provisions of World Intellectual Property Organization treaty implementations, such as the United States Online Copyright Infringement Liability Limitation Act, but this would require giving notice to each individual news server administrator.\n\nOn the Internet, Usenet is transported via the Network News Transfer Protocol (NNTP) on TCP Port 119 for standard, unprotected connections and on TCP port 563 for SSL encrypted connections.\n\nThe major set of worldwide newsgroups is contained within nine hierarchies, eight of which are operated under consensual guidelines that govern their administration and naming. The current Big Eight are:\n\nSee also the Great Renaming.\n\nThe alt.* hierarchy is not subject to the procedures controlling groups in the Big Eight, and it is as a result less organized. Groups in the alt.* hierarchy tend to be more specialized or specific—for example, there might be a newsgroup under the Big Eight which contains discussions about children's books, but a group in the alt hierarchy may be dedicated to one specific author of children's books. Binaries are posted in alt.binaries.*, making it the largest of all the hierarchies.\n\nMany other hierarchies of newsgroups are distributed alongside these. Regional and language-specific hierarchies such as japan.*, malta.* and ne.* serve specific countries and regions such as Japan, Malta and New England. Companies and projects administer their own hierarchies to discuss their products and offer community technical support, such as the historical gnu.* hierarchy from the Free Software Foundation. Microsoft closed its newsserver in June 2010, providing support for its products over forums now.[27] Some users prefer to use the term \"Usenet\" to refer only to the Big Eight hierarchies; others include alt.* as well. The more general term \"netnews\" incorporates the entire medium, including private organizational news systems.\n\nInformal sub-hierarchy conventions also exist. *.answers are typically moderated cross-post groups for FAQs. An FAQ would be posted within one group and a cross post to the *.answers group at the head of the hierarchy seen by some as a refining of information in that news group. Some subgroups are recursive—to the point of some silliness in alt.*[citation needed].\n\nUsenet was originally created to distribute text content encoded in the 7-bit ASCII character set. With the help of programs that encode 8-bit values into ASCII, it became practical to distribute binary files as content. Binary posts, due to their size and often-dubious copyright status, were in time restricted to specific newsgroups, making it easier for administrators to allow or disallow the traffic.\n\nThe oldest widely used encoding method for binary content is uuencode, from the Unix UUCP package. In the late 1980s, Usenet articles were often limited to 60,000 characters, and larger hard limits exist today. Files are therefore commonly split into sections that require reassembly by the reader.\n\nWith the header extensions and the Base64 and Quoted-Printable MIME encodings, there was a new generation of binary transport. In practice, MIME has seen increased adoption in text messages, but it is avoided for most binary attachments. Some operating systems with metadata attached to files use specialized encoding formats. For Mac OS, both BinHex and special MIME types are used. Other lesser known encoding systems that may have been used at one time were BTOA, XX encoding, BOO, and USR encoding.\n\nIn an attempt to reduce file transfer times, an informal file encoding known as yEnc was introduced in 2001. It achieves about a 30% reduction in data transferred by assuming that most 8-bit characters can safely be transferred across the network without first encoding into the 7-bit ASCII space. The most common method of uploading large binary posts to Usenet is to convert the files into RAR archives and create Parchive files for them. Parity files are used to recreate missing data when not every part of the files reaches a server.\n\nEach news server allocates a certain amount of storage space for content in each newsgroup. When this storage has been filled, each time a new post arrives, old posts are deleted to make room for the new content. If the network bandwidth available to a server is high but the storage allocation is small, it is possible for a huge flood of incoming content to overflow the allocation and push out everything that was in the group before it. The average length of time that posts are able to stay on the server before being deleted is commonly called the retention time.\n\nBinary newsgroups are only able to function reliably if there is sufficient storage allocated to handle the amount of articles being added. Without sufficient retention time, a reader will be unable to download all parts of the binary before it is flushed out of the group's storage allocation. This was at one time how posting undesired content was countered; the newsgroup would be flooded with random garbage data posts, of sufficient quantity to push out all the content to be suppressed. This has been compensated by service providers allocating enough storage to retain everything posted each day, including spam floods, without deleting anything.\n\nModern Usenet news servers have enough capacity to archive years of binary content even when flooded with new data at the maximum daily speed available.  \n\nIn part because of such long retention times, as well as growing Internet upload speeds, Usenet is also used by individual users to store backup data.[29] While commercial providers offer easier to use online backup services, storing data on Usenet is free of charge (although access to Usenet itself may not be). The method requires the uploader to cede control over the distribution of the data; the files are automatically disseminated to all Usenet providers exchanging data for the news group it is posted to. In general the user must  manually select, prepare and upload the data. The data is typically encrypted because it is available to anyone to download the backup files. After the files are uploaded, having multiple copies spread to different geographical regions around the world on different news servers decreases the chances of data loss.\n\nMajor Usenet service providers have a retention time of more than 12 years.[30]\nThis results in more than 60 petabytes (60000 terabytes) of storage (see image). When using Usenet for data storage, providers that offer longer retention time are preferred to ensure the data will survive for longer periods of time compared to services with lower retention time.\n\nWhile binary newsgroups can be used to distribute completely legal user-created works, Free software, and public domain material, some binary groups are used to illegally distribute Proprietary software, copyrighted media, and pornographic material.\n\nISP-operated Usenet servers frequently block access to all alt.binaries.* groups to both reduce network traffic and to avoid related legal issues. Commercial Usenet service providers claim to operate as a telecommunications service, and assert that they are not responsible for the user-posted binary content transferred via their equipment. In the United States, Usenet providers can qualify for protection under the DMCA Safe Harbor regulations, provided that they establish a mechanism to comply with and respond to takedown notices from copyright holders.[31]\n\nRemoval of copyrighted content from the entire Usenet network is a nearly impossible task, due to the rapid propagation between servers and the retention done by each server. Petitioning a Usenet provider for removal only removes it from that one server's retention cache, but not any others. It is possible for a special post cancellation message to be distributed to remove it from all servers, but many providers ignore cancel messages by standard policy, because they can be easily falsified and submitted by anyone.[32][33] For a takedown petition to be most effective across the whole network, it would have to be issued to the origin server to which the content has been posted, before it has been propagated to other servers. Removal of the content at this early stage would prevent further propagation, but with modern high speed links, content can be propagated as fast as it arrives, allowing no time for content review and takedown issuance by copyright holders.[34]\n\nEstablishing the identity of the person posting illegal content is equally difficult due to the trust-based design of the network. Like SMTP email, servers generally assume the header and origin information in a post is true and accurate. However, as in SMTP email, Usenet post headers are easily falsified so as to obscure the true identity and location of the message source.[35] In this manner, Usenet is significantly different from modern P2P services; most P2P users distributing content are typically immediately identifiable to all other users by their network address, but the origin information for a Usenet posting can be completely obscured and unobtainable once it has propagated past the original server.[36]\n\nAlso unlike modern P2P services, the identity of the downloaders is hidden from view. On P2P services a downloader is identifiable to all others by their network address. On Usenet, the downloader connects directly to a server, and only the server knows the address of who is connecting to it. Some Usenet providers do keep usage logs, but not all make this logged information casually available to outside parties such as the Recording Industry Association of America.[37][38][39] The existence of anonymising gateways to USENET also complicates the tracing of a postings true origin.\n\n"
        },
        {
            "title": "History",
            "text": "Newsgroup experiments first occurred in 1979. Tom Truscott and Jim Ellis of Duke University came up with the idea as a replacement for a local announcement program, and established a link with nearby University of North Carolina using Bourne shell scripts written by Steve Bellovin. The public release of news was in the form of conventional compiled software, written by Steve Daniel and Truscott.[7][41] In 1980, Usenet was connected to ARPANET through  UC Berkeley, which had connections to both Usenet and ARPANET. Mark Horton, the graduate student who set up the connection, began \"feeding mailing lists from the ARPANET into Usenet\" with the \"fa\" (\"From ARPANET\"[42]) identifier.[43] Usenet gained 50 member sites in its first year, including Reed College, University of Oklahoma, and Bell Labs,[7] and the number of people using the network increased dramatically; however, it was still a while longer before Usenet users could contribute to ARPANET.[44]\n\nUUCP networks spread quickly due to the lower costs involved, and the ability to use existing leased lines, X.25 links or even ARPANET connections. By 1983, thousands of people participated from more than 500 hosts, mostly universities and Bell Labs sites but also a growing number of Unix-related companies; the number of hosts nearly doubled to 940 in 1984. More than 100 newsgroups existed, more than 20 devoted to Unix and other computer-related topics, and at least a third to recreation.[45][7] As the mesh of UUCP hosts rapidly expanded, it became desirable to distinguish the Usenet subset from the overall network. A vote was taken at the 1982 USENIX conference to choose a new name. The name Usenet was retained, but it was established that it only applied to news.[46] The name UUCPNET became the common name for the overall network.\n\nIn addition to UUCP, early Usenet traffic was also exchanged with Fidonet and other dial-up BBS networks.  By the mid-1990s there were almost 40,000 FidoNet systems in operation, and it was possible to communicate with millions of users around the world, with only local telephone service. Widespread use of Usenet by the BBS community was facilitated by the introduction of UUCP feeds made possible by MS-DOS implementations of UUCP, such as UFGATE (UUCP to FidoNet Gateway), FSUUCP and UUPC. In 1986, RFC 977 provided the Network News Transfer Protocol (NNTP) specification for distribution of Usenet articles over TCP/IP as a more flexible alternative to informal Internet transfers of UUCP traffic. Since the Internet boom of the 1990s, almost all Usenet distribution is over NNTP.[47]\n\nEarly versions of Usenet used Duke's A News software, designed for one or two articles a day. Matt Glickman and Horton at Berkeley produced an improved version called B News that could handle the rising traffic (about 50 articles a day as of late 1983).[7] With a message format that offered compatibility with Internet mail and improved performance, it became the dominant server software. C News, developed by Geoff Collyer and Henry Spencer at the University of Toronto, was comparable to B News in features but offered considerably faster processing. In the early 1990s, InterNetNews by Rich Salz was developed to take advantage of the continuous message flow made possible by NNTP versus the batched store-and-forward design of UUCP. Since that time INN development has continued, and other news server software has also been developed.[48]\n\nUsenet was the first Internet community and the place for many of the most important public developments in the pre-commercial Internet. It was the place where Tim Berners-Lee announced the launch of the World Wide Web,[49] where Linus Torvalds announced the Linux project,[50] and where Marc Andreessen announced the creation of the Mosaic browser and the introduction of the image tag,[51] which revolutionized the World Wide Web by turning it into a graphical medium. Activist Amy Goodloe used the platform to maintain an email list for LGBT activism.\n\n\nMany jargon terms now in common use on the Internet originated or were popularized on Usenet.[52] Likewise, many conflicts which later spread to the rest of the Internet, such as the ongoing difficulties over spamming, began on Usenet.[53]\nSascha Segan of PC Magazine said in 2008 that \"Usenet has been dying for years\".[54] Segan said that some people pointed to the Eternal September in 1993 as the beginning of Usenet's decline, when AOL began offering Usenet access. He argues that when users began putting large (non-text) files on Usenet by the late 1990s, Usenet disk space and traffic increased correspondingly. Internet service providers questioned why they needed to host space for binary articles.\n\nAOL discontinued Usenet access in 2005. In May 2010, Duke University, whose implementation had started Usenet more than 30 years earlier, decommissioned its Usenet server, citing low usage and rising costs.[55][56] On February 4, 2011, the Usenet news service link at the University of North Carolina at Chapel Hill (news.unc.edu) was retired after 32 years.[citation needed]\n\nIn response, John Biggs of TechCrunch said \"As long as there are folks who think a command line is better than a mouse, the original text-only social network will live on\".[57] While there are still some active text newsgroups on Usenet, the system is now primarily used to share large files between users, and the underlying technology of Usenet remains unchanged.[58]\n\n"
        },
        {
            "title": "Usenet traffic changes",
            "text": "Over time, the amount of Usenet traffic has steadily increased. As of 2010[update] the number of all text posts made in all Big-8 newsgroups averaged 1,800 new messages every hour, with an average of 25,000 messages per day.[59] However, these averages are minuscule in comparison to the traffic in the binary groups.[60] Much of this traffic increase reflects not an increase in discrete users or newsgroup discussions, but instead the combination of massive automated spamming and an increase in the use of .binaries newsgroups[59] in which large files are often posted publicly. A small sampling of the change (measured in feed size per day) follows:\n\nIn 2008, Verizon Communications, Time Warner Cable and Sprint Nextel signed an agreement with Attorney General of New York Andrew Cuomo to shut down access to sources of child pornography.[61] Time Warner Cable stopped offering access to Usenet. Verizon reduced its access to the \"Big 8\" hierarchies. Sprint stopped access to the alt.* hierarchies. AT&T stopped access to the alt.binaries.* hierarchies. Cuomo never specifically named Usenet in his anti-child pornography campaign. David DeJean of PC World said that some worry that the ISPs used Cuomo's campaign as an excuse to end portions of Usenet access, as it is costly for the Internet service providers and not in high demand by customers. In 2008 AOL, which no longer offered Usenet access, and the four providers that responded to the Cuomo campaign were the five largest Internet service providers in the United States; they had more than 50% of the U.S. ISP market share.[62] On June 8, 2009, AT&T announced that it would no longer provide access to the Usenet service as of July 15, 2009.[63]\n\nAOL announced that it would discontinue its integrated Usenet service in early 2005, citing the growing popularity of weblogs, chat forums and on-line conferencing.[64] The AOL community had a tremendous role in popularizing Usenet some 11 years earlier.[65]\n\nIn August 2009, Verizon announced that it would discontinue access to Usenet on September 30, 2009.[66][67] JANET announced it would discontinue Usenet service, effective July 31, 2010, citing Google Groups as an alternative.[68]\nMicrosoft announced that it would discontinue support for its public newsgroups (msnews.microsoft.com) from June 1, 2010, offering web forums as an alternative.[69]\n\nPrimary reasons cited for the discontinuance of Usenet service by general ISPs include the decline in volume of actual readers due to competition from blogs, along with cost and liability concerns of increasing proportion of traffic devoted to file-sharing and spam on unused or discontinued groups.[70][71]\n\nSome ISPs did not include pressure from Cuomo's campaign against child pornography as one of their reasons for dropping Usenet feeds as part of their services.[72] ISPs Cox and Atlantic Communications resisted the 2008 trend but both did eventually drop their respective Usenet feeds in 2010.[73][74][75]\n\n"
        },
        {
            "title": "Archives",
            "text": "Public archives of Usenet articles have existed since the early days of Usenet, such as the system created by Kenneth Almquist in late 1982.[76][77] Distributed archiving of Usenet posts was suggested in November 1982 by Scott Orshan, who proposed that \"Every site should keep all the articles it posted, forever.\"[78] Also in November of that year, Rick Adams responded to a post asking \"Has anyone archived netnews, or does anyone plan to?\"[79] by stating that he was, \"afraid to admit it, but I started archiving most 'useful' newsgroups as of September 18.\"[80] In June 1982, Gregory G. Woodbury proposed an \"automatic access to archives\" system that consisted of \"automatic answering of fixed-format messages to a special mail recipient on specified machines.\"[81]\n\nIn 1985, two news archiving systems and one RFC were posted to the Internet. The first system, called keepnews, by Mark M. Swenson of the University of Arizona, was described as \"a program that attempts to provide a sane way of extracting and keeping information that comes over Usenet.\" The main advantage of this system was to allow users to mark articles as worthwhile to retain.[82] The second system, YA News Archiver by Chuq Von Rospach, was similar to keepnews, but was \"designed to work with much larger archives where the wonderful quadratic search time feature of the Unix ... becomes a real problem.\"[83] Von Rospach in early 1985 posted a detailed RFC for \"archiving and accessing usenet articles with keyword lookup.\" This RFC described a program that could \"generate and\nmaintain an archive of Usenet articles and allow looking up articles based on the article-id, subject lines, or keywords pulled out of the article itself.\" Also included was C code for the internal data structure of the system.[84]\n\nThe desire to have a fulltext search index of archived news articles is not new either, one such request having been made in April 1991 by Alex Martelli who sought to \"build\nsome sort of keyword index for [the news archive].\"[85] In early May, Mr. Martelli posted a summary of his responses to Usenet, noting that the \"most popular suggestion award must definitely go to 'lq-text' package, by Liam Quin, recently posted in alt.sources.\"[86]\n\nThe Alt Sex Stories Text Repository (ASSTR) site archives and indexes erotic and pornographic stories posted to the Usenet group alt.sex.stories.[87]\n\nThe archiving of Usenet has led to fears of loss of privacy.[88] An archive simplifies ways to profile people. This has partly been countered with the introduction of the  X-No-Archive: Yes header, which is itself controversial.[89]\n\nWeb-based archiving of Usenet posts began in 1995 at Deja News with a very large, searchable database. In 2001, this database was acquired by Google.[90]\n\nGoogle Groups hosts an archive of Usenet posts dating back to May 1981. The earliest posts, which date from May 1981 to June 1991, were donated to Google by the University of Western Ontario with the help of David Wiseman and others,[91] and were originally archived by Henry Spencer at the University of Toronto's Zoology department.[92] The archives for late 1991 through early 1995 were provided by Kent Landfield from the NetNews CD series[93] and Jürgen Christoffel from GMD.[94] The archive of posts from March 1995 onward was started by the company Deja News (later Deja), which was purchased by Google in February 2001. Google began archiving Usenet posts for itself starting in the second week of August 2000.\n\nGoogle has been criticized by Vice and Wired contributors as well as former employees for its stewardship of the archive and for breaking its search functionality.[95][96][97]\n\n"
        },
        {
            "title": "See also",
            "text": "Usenet as a whole has no administrators. Each server administrator is free to do what they want, as long as the end users and peer servers accept it. But there are a few famous administrators:\n\n"
        }
    ]
}