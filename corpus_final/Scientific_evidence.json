{
    "url": "https://en.wikipedia.org/wiki/Scientific_evidence",
    "title": "Scientific evidence",
    "table_of_contents": [
        "1 Principles of inference",
        "2 Utility of scientific evidence",
        "3 Philosophical versus scientific views",
        "4 Concept of scientific proof",
        "5 See also",
        "6 References"
    ],
    "paragraphs": [
        {
            "title": "",
            "text": "Scientific evidence is evidence that serves to either support or counter a scientific theory or hypothesis,[1] although scientists also use evidence in other ways, such as when applying theories to practical problems.[2] Such evidence is expected to be empirical evidence and interpretable in accordance with scientific methods. Standards for scientific evidence vary according to the field of inquiry, but the strength of scientific evidence is generally based on the results of statistical analysis and the strength of scientific controls.[citation needed]\n\n"
        },
        {
            "title": "Principles of inference",
            "text": "A person's assumptions or beliefs about the relationship between observations and a hypothesis will affect whether that person takes the observations as evidence.[3] These assumptions or beliefs will also affect how a person utilizes the observations as evidence. For example, the Earth's apparent lack of motion may be taken as evidence for a geocentric cosmology. However, after sufficient evidence is presented for heliocentric cosmology and the apparent lack of motion is explained, the initial observation is strongly discounted as evidence.\n\nWhen rational observers have different background beliefs, they may draw different conclusions from the same scientific evidence. For example, Priestley, working with phlogiston theory, explained his observations about the decomposition of mercuric oxide using phlogiston. In contrast, Lavoisier, developing the theory of elements, explained the same observations with reference to oxygen.[4] Note that a causal relationship between the observations and hypothesis does not exist to cause the observation to be taken as evidence,[3] but rather the causal relationship is provided by the person seeking to establish observations as evidence.\n\nA more formal method to characterize the effect of background beliefs is Bayesian inference.[5] In Bayesian inference, beliefs are expressed as percentages indicating one's confidence in them. One starts from an initial probability (a prior), and then updates that probability using Bayes' theorem after observing evidence.[6] As a result, two independent observers of the same event will rationally arrive at different conclusions if their priors (previous observations that are also relevant to the conclusion) differ. However, if they are allowed to communicate with each other, they will end in agreement (per Aumann's agreement theorem).\n\nThe importance of background beliefs in the determination of what observations are evidence can be illustrated using deductive reasoning, such as syllogisms.[7] If either of the propositions is not accepted as true, the conclusion will not be accepted either.\n\n"
        },
        {
            "title": "Utility of scientific evidence",
            "text": "Philosophers, such as Karl R. Popper, have provided influential theories of the scientific method within which scientific evidence plays a central role.[8] In summary, Popper provides that a scientist creatively develops a theory that may be falsified by testing the theory against evidence or known facts. Popper's theory presents an asymmetry in that evidence can prove a theory wrong, by establishing facts that are inconsistent with the theory. In contrast, evidence cannot prove a theory correct because other evidence, yet to be discovered, may exist that is inconsistent with the theory.[9]\n\n"
        },
        {
            "title": "Philosophical versus scientific views",
            "text": "In the 20th century, many philosophers investigated the logical relationship between evidence statements and hypotheses, whereas scientists tended to focus on how the data used for statistical inference are generated.[10]: S193  But according to philosopher Deborah Mayo, by the end of the 20th century philosophers had come to understand that \"there are key features of scientific practice that are overlooked or misdescribed by all such logical accounts of evidence, whether hypothetico-deductive, Bayesian, or instantiationist\".[10]: S194 \n\nThere were a variety of 20th-century philosophical approaches to decide whether an observation may be considered evidence; many of these focused on the relationship between the evidence and the hypothesis. In the 1950s, Rudolf Carnap recommended distinguishing such approaches into three categories: classificatory (whether the evidence confirms the hypothesis), comparative (whether the evidence supports a first hypothesis more than an alternative hypothesis) or quantitative (the degree to which the evidence supports a hypothesis).[11] A 1983 anthology edited by Peter Achinstein provided a concise presentation by prominent philosophers on scientific evidence, including Carl Hempel (on the logic of confirmation), R. B. Braithwaite (on the structure of a scientific system), Norwood Russell Hanson (on the logic of discovery), Nelson Goodman (of grue fame, on a theory of projection), Rudolf Carnap (on the concept of confirming evidence), Wesley C. Salmon (on confirmation and relevance), and Clark Glymour (on relevant evidence).[12] In 1990, William Bechtel provided four factors (clarity of the data, replication by others, consistency with results arrived at by alternative methods, and consistency with plausible theories of mechanisms) that biologists used to settle controversies about procedures and reliability of evidence.[13]\n\nIn 2001, Achinstein published his own book on the subject titled The Book of Evidence, in which, among other topics, he distinguished between four concepts of evidence: epistemic-situation evidence (evidence relative to a given epistemic situation), subjective evidence (considered to be evidence by a particular person at a particular time), veridical evidence (a good reason to believe that a hypothesis is true), and potential evidence (a good reason to believe that a hypothesis is highly probable).[14] Achinstein defined all his concepts of evidence in terms of potential evidence, since any other kind of evidence must at least be potential evidence, and he argued that scientists mainly seek veridical evidence but they also use the other concepts of evidence, which rely on a distinctive concept of probability, and Achinstein contrasted this concept of probability with previous probabilistic theories of evidence such as Bayesian, Carnapian, and frequentist.[14]\n\nSimplicity is one common philosophical criterion for scientific theories.[15] Based on the philosophical assumption of the strong Church-Turing thesis, a mathematical criterion for evaluation of evidence has been conjectured, with the criterion having a resemblance to the idea of Occam's razor that the simplest comprehensive description of the evidence is most likely correct.[16] It states formally, \"The ideal principle states that the prior probability associated with the hypothesis should be given by the algorithmic universal probability, and the sum of the log universal probability of the model plus the log of the probability of the data given the model should be minimized.\"[16] However, some philosophers (including Richard Boyd, Mario Bunge, John D. Norton, and Elliott Sober) have adopted a skeptical or deflationary view of the role of simplicity in science, arguing in various ways that its importance has been overemphasized.[17]\n\nEmphasis on hypothesis testing as the essence of science is prevalent among both scientists and philosophers.[18] However, philosophers have noted that testing hypotheses by confronting them with new evidence does not account for all the ways that scientists use evidence.[2] For example, when Geiger and Marsden scattered alpha particles through thin gold foil, the resulting data enabled their experimental adviser, Ernest Rutherford, to very accurately calculate the mass and size of an atomic nucleus for the first time.[19] Rutherford used the data to develop a new atomic model, not only to test an existing hypothesis; such use of evidence to produce new hypotheses is sometimes called abduction (following C. S. Peirce).[19] Social-science methodologist Donald T. Campbell, who emphasized hypothesis testing throughout his career, later increasingly emphasized that the essence of science is \"not experimentation per se\" but instead the iterative competition of \"plausible rival hypotheses\", a process that at any given phase may start from evidence or may start from hypothesis.[20] Other scientists and philosophers have emphasized the central role of questions and problems in the use of data and hypotheses.[21]\n\n"
        },
        {
            "title": "Concept of scientific proof",
            "text": "While the phrase \"scientific proof\" is often used in the popular media,[22] many scientists and philosophers have argued that there is really no such thing as infallible proof. For example, Karl Popper once wrote that \"In the empirical sciences, which alone can furnish us with information about the world we live in, proofs do not occur, if we mean by 'proof' an argument which establishes once and for ever the truth of a theory.\"[23][24] Albert Einstein said:\n\nHowever, in contrast to the ideal of infallible proof, in practice theories may be said to be proved according to some standard of proof used in a given inquiry.[26][27] In this limited sense, proof is the high degree of acceptance of a theory following a process of inquiry and critical evaluation according to the standards of a scientific community.[26][27]\n\n"
        }
    ]
}